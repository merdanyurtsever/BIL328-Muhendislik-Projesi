{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bfa6a60",
   "metadata": {},
   "source": [
    "# Müzik Türü Sınıflandırma Projesi\n",
    "\n",
    "Bu notebook, FMA (Free Music Archive) veri setini kullanarak müzik türü sınıflandırma modeli geliştirmek için veri hazırlama ve dengeleme işlemlerini içermektedir.\n",
    "\n",
    "## Gerekli Kütüphanelerin İçe Aktarılması\n",
    "Aşağıdaki hücrede, projede kullanılacak temel Python kütüphaneleri import edilmektedir:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ecc757",
   "metadata": {},
   "source": [
    "# Music Genre Classification with LSTM and BorderlineSMOTE\n",
    "\n",
    "This notebook demonstrates a robust workflow for music genre classification using deep learning (LSTM) and advanced data balancing (BorderlineSMOTE). Key steps:\n",
    "- Data loading and exploration\n",
    "- Feature selection and scaling\n",
    "- Class balancing with BorderlineSMOTE\n",
    "- LSTM model training and evaluation\n",
    "- Experiment logging, explainability, and creative enhancements\n",
    "\n",
    "---\n",
    "\n",
    "*All code and explanations are provided in both Turkish and English for clarity and accessibility.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672ed28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONFIGURATION ===\n",
    "# All key parameters and paths in one place for reproducibility and easy tuning\n",
    "DATA_DIR = 'fma_metadata'\n",
    "TRACKS_PATH = f'{DATA_DIR}/tracks.csv'\n",
    "FEATURES_PATH = f'{DATA_DIR}/features.csv'\n",
    "\n",
    "# Feature Selection\n",
    "K_BEST = 225  # Number of features to select\n",
    "\n",
    "# Data Balancing\n",
    "MIN_SAMPLES_THRESHOLD = 20  # For BorderlineSMOTE (used in RandomOverSampler step)\n",
    "\n",
    "# LSTM Model & Training\n",
    "SEQUENCE_LENGTH = 10  # Sequence length for LSTM\n",
    "HIDDEN_SIZE = 64 # Hidden size of LSTM layers\n",
    "NUM_LAYERS = 2     # Number of LSTM layers\n",
    "DROPOUT_PROB = 0.3 # Dropout probability in LSTM\n",
    "BIDIRECTIONAL = True # Whether to use a bidirectional LSTM\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 100 # Max epochs (EarlyStopping will be used)\n",
    "BATCH_SIZE = 512\n",
    "PATIENCE_EARLY_STOPPING = 5 # Patience for early stopping\n",
    "\n",
    "# General\n",
    "RANDOM_STATE = 42\n",
    "MODEL_SAVE_PATH = 'best_optimized_lstm.pth'\n",
    "SCALER_SAVE_PATH = 'scaler.pkl'\n",
    "ENCODER_SAVE_PATH = 'label_encoder.pkl'\n",
    "LOG_FILE = 'experiment_log.json'\n",
    "\n",
    "print('Configuration loaded.')\n",
    "print(f\"K_BEST: {K_BEST}, SEQUENCE_LENGTH: {SEQUENCE_LENGTH}, BATCH_SIZE: {BATCH_SIZE}\")\n",
    "print(f\"LSTM: HIDDEN_SIZE={HIDDEN_SIZE}, NUM_LAYERS={NUM_LAYERS}, DROPOUT_PROB={DROPOUT_PROB}, BIDIRECTIONAL={BIDIRECTIONAL}\")\n",
    "print(f\"TRAINING: LR={LEARNING_RATE}, EPOCHS={EPOCHS}, PATIENCE_EARLY_STOPPING={PATIENCE_EARLY_STOPPING}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c6cad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ENVIRONMENT & PACKAGE VERSIONS ===\n",
    "import sys\n",
    "import platform\n",
    "import sklearn\n",
    "import torch\n",
    "import imblearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import seaborn\n",
    "\n",
    "print('Python version:', sys.version)\n",
    "print('Platform:', platform.platform())\n",
    "print('scikit-learn:', sklearn.__version__)\n",
    "print('PyTorch:', torch.__version__)\n",
    "print('imbalanced-learn:', imblearn.__version__)\n",
    "print('pandas:', pd.__version__)\n",
    "print('numpy:', np.__version__)\n",
    "print('matplotlib:', matplotlib.__version__)\n",
    "print('seaborn:', seaborn.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44273a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === DEVICE SELECTION ===\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "if torch.cuda.is_available():\n",
    "    print('CUDA device name:', torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd9f343",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from imblearn.over_sampling import RandomOverSampler, BorderlineSMOTE\n",
    "from collections import Counter\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(style='whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98ccac1",
   "metadata": {},
   "source": [
    "# === Helper Functions ===\n",
    "# This section consolidates various utility functions used throughout the notebook\n",
    "# for plotting, seeding, saving/loading artifacts, logging, and custom metrics.\n",
    "# These functions depend on global variables defined in the Configuration cell (e.g., paths)\n",
    "# and the Device Selection cell (e.g., `device`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function imports\n",
    "import joblib\n",
    "import json\n",
    "from datetime import datetime\n",
    "import random\n",
    "from sklearn.metrics import f1_score, roc_auc_score # Added for advanced_metrics\n",
    "\n",
    "# --- Plotting ---\n",
    "def plot_class_distribution(y_numeric_labels, class_name_array, title):\n",
    "    \"\"\"Plots the distribution of classes.\n",
    "\n",
    "    Args:\n",
    "        y_numeric_labels: A pandas Series or numpy array of numeric class labels.\n",
    "        class_name_array: An array or list of class names, where the index corresponds to the numeric label.\n",
    "        title: The title for the plot.\n",
    "    \"\"\"\n",
    "    names_map = {i: class_name_array[i] for i in range(len(class_name_array))}\n",
    "    mapped_names_counts = pd.Series(y_numeric_labels).map(names_map).value_counts()\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    ax = sns.barplot(x=mapped_names_counts.index, y=mapped_names_counts.values, hue=mapped_names_counts.index, palette='viridis', legend=False)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Sınıf') # Class (Turkish)\n",
    "    ax.set_ylabel('Sayı')  # Count (Turkish)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --- PyTorch Model Training Utilities ---\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=PATIENCE_EARLY_STOPPING, verbose=False, delta=0, path=MODEL_SAVE_PATH):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model to {self.path} ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss\n",
    "\n",
    "# --- Reproducibility ---\n",
    "def set_seed(seed_value=RANDOM_STATE):\n",
    "    \"\"\"Sets the seed for reproducibility.\"\"\"\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    print(f\"Global seed set to {seed_value}\")\n",
    "\n",
    "# --- Artifact Saving/Loading ---\n",
    "def save_scaler_and_encoder(scaler_obj, encoder_obj, scaler_path_param=SCALER_SAVE_PATH, encoder_path_param=ENCODER_SAVE_PATH):\n",
    "    \"\"\"Saves scaler and label encoder objects.\"\"\"\n",
    "    joblib.dump(scaler_obj, scaler_path_param)\n",
    "    joblib.dump(encoder_obj, encoder_path_param)\n",
    "    print(f'Scaler saved to {scaler_path_param}, encoder saved to {encoder_path_param}')\n",
    "\n",
    "def save_model(model_to_save, path_param=MODEL_SAVE_PATH):\n",
    "    \"\"\"Saves a PyTorch model state_dict.\"\"\"\n",
    "    torch.save(model_to_save.state_dict(), path_param)\n",
    "    print(f\"Model saved to {path_param}\")\n",
    "\n",
    "def load_model(model_instance, path_param=MODEL_SAVE_PATH):\n",
    "    \"\"\"Loads a PyTorch model state_dict into a model instance.\"\"\"\n",
    "    model_instance.load_state_dict(torch.load(path_param, map_location=device))\n",
    "    model_instance.eval() # Set to evaluation mode\n",
    "    print(f\"Model loaded from {path_param} to {device}\")\n",
    "    return model_instance\n",
    "\n",
    "# --- Experiment Logging ---\n",
    "def log_experiment(params_dict, metrics_dict, filename_param=LOG_FILE):\n",
    "    \"\"\"Logs experiment parameters and metrics to a JSON file.\"\"\"\n",
    "    log_entry = {\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"params\": params_dict,\n",
    "        \"metrics\": metrics_dict\n",
    "    }\n",
    "    try:\n",
    "        with open(filename_param, \"a\") as f: # Append mode\n",
    "            f.write(json.dumps(log_entry) + \"\\n\")\n",
    "        print(f\"Experiment logged to {filename_param}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Logging failed: {e}\")\n",
    "\n",
    "# --- Evaluation Metrics & Plotting ---\n",
    "def plot_confusion_matrix_and_report(y_true_labels, y_pred_labels, class_names_list, title='Confusion Matrix'):\n",
    "    \"\"\"Plots confusion matrix and prints classification report.\"\"\"\n",
    "    cm = confusion_matrix(y_true_labels, y_pred_labels)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names_list, yticklabels=class_names_list)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.show()\n",
    "    print('\\nClassification Report:')\n",
    "    print(classification_report(y_true_labels, y_pred_labels, labels=np.arange(len(class_names_list)), target_names=class_names_list, zero_division=0))\n",
    "\n",
    "def advanced_metrics(y_true_labels, y_pred_labels, y_probabilities, num_classes_for_roc):\n",
    "    \"\"\"Calculates and prints weighted F1-score and ROC-AUC.\"\"\"\n",
    "    f1 = f1_score(y_true_labels, y_pred_labels, average='weighted', zero_division=0)\n",
    "    print(f'Weighted F1-score: {f1:.4f}')\n",
    "    try:\n",
    "        if y_probabilities is not None and y_probabilities.ndim == 2 and y_probabilities.shape[0] == len(y_true_labels):\n",
    "            unique_labels_in_true = np.unique(y_true_labels)\n",
    "            if len(unique_labels_in_true) > 1:\n",
    "                roc_auc = roc_auc_score(y_true_labels, y_probabilities, multi_class='ovr', average='weighted', labels=np.arange(num_classes_for_roc))\n",
    "                print(f'ROC-AUC (OvR, Weighted): {roc_auc:.4f}')\n",
    "            else:\n",
    "                print('ROC-AUC not calculated: Only one class present in y_true.')\n",
    "        else:\n",
    "            print('ROC-AUC not calculated: y_probabilities are not in the correct format or not provided.')\n",
    "    except ValueError as e:\n",
    "        print(f'ROC-AUC calculation error: {e}')\n",
    "    except Exception as e:\n",
    "        print(f'An unexpected error occurred during ROC-AUC calculation: {e}')\n",
    "\n",
    "print(\"Helper functions defined and ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968d3831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set global random seed for reproducibility using value from config\n",
    "set_seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471baca3",
   "metadata": {},
   "source": [
    "## Veri Yükleme ve Ön İşleme\n",
    "\n",
    "Bu bölümdeki fonksiyon:\n",
    "- FMA metadata dosyalarını yükler\n",
    "- Gerekli sütunları seçer\n",
    "- Eksik verileri temizler\n",
    "- Etiketleri kodlar\n",
    "- Veriyi sayısal formata dönüştürür"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6868595d",
   "metadata": {},
   "source": [
    "# 3. VERİ SETİ\n",
    "\n",
    "## 3.1. Tanım ve Temin\n",
    "\n",
    "Bu çalışmada müzik türü sınıflandırma amacıyla **FMA (Free Music Archive) Small** veri seti kullanılmıştır. FMA, telif hakkı içermeyen binlerce müzik dosyasını barındıran bir açık veri kümesidir ve farklı boyutlarda (small, medium, large, full) sunulmaktadır. Bu projede kullanılan \"FMA Small\" versiyonu, toplam **8,000 adet ses parçası** içermekte ve her biri **30 saniyelik** örneklerden oluşmaktadır. Veri seti, M. Deffayet ve arkadaşları tarafından derlenen bir çalışmanın parçasıdır [8].\n",
    "\n",
    "### Veri Seti Özellikleri:\n",
    "- **Toplam Dosya Sayısı**: 8,000 adet müzik parçası\n",
    "- **Dosya Süresi**: Her bir parça 30 saniye\n",
    "- **Öznitelik Sayısı**: 518 önceden çıkarılmış öznitelik\n",
    "- **Format**: CSV dosyaları (tracks.csv, features.csv)\n",
    "- **Lisans**: Creative Commons lisansı ile özgürce kullanılabilir\n",
    "\n",
    "## 3.2. Öznitelik Yapısı\n",
    "\n",
    "FMA Small veri seti içinde her bir müzik parçasına ait **önceden çıkarılmış 518 öznitelik (feature)** bulunmaktadır. Bu öznitelikler Python ortamında `features.csv` dosyası aracılığıyla sağlanmakta ve sesin zaman-frekans alanındaki temsilini içermektedir.\n",
    "\n",
    "Öznitelikler, içeriklerine göre aşağıdaki ana gruplara ayrılmaktadır:\n",
    "\n",
    "### 3.2.1. Chroma Öznitelikleri (`chroma_`)\n",
    "- **Amaç**: Tonalite ve akor bilgilerini temsil eder\n",
    "- **İçerik**: Müzikal armoniyi yansıtır\n",
    "- **Kullanım**: Müzik türleri arasındaki tonal farklılıkları yakalamak için kritik\n",
    "\n",
    "### 3.2.2. MFCC Öznitelikleri (`mfcc_`)\n",
    "- **Tam Adı**: Mel-Frequency Cepstral Coefficients\n",
    "- **Amaç**: Sesin mel frekans alanındaki cepstral bileşenleri\n",
    "- **Özellik**: Ses tanıma ve sınıflandırmada yaygın olarak kullanılır\n",
    "- **Avantaj**: İnsan kulağının frekans algısını taklit eder\n",
    "\n",
    "### 3.2.3. Spektral Öznitelikler (`spectral_`)\n",
    "- **İçerik**: Spektral yoğunluk, enerji ve frekans dağılımları\n",
    "- **Bilgi**: Sesin frekans alanındaki karakteristik özellikleri\n",
    "- **Kullanım**: Müzik türlerinin frekans imzalarını ayırt etmek için\n",
    "\n",
    "### 3.2.4. Tonnetz Öznitelikleri (`tonnetz_`)\n",
    "- **Amaç**: Tonal merkezler ve armonik ilişkiler\n",
    "- **İçerik**: Müzikal yapı ve harmoni bilgileri\n",
    "- **Özellik**: Soyut müzikal kavramları sayısal veriye dönüştürür\n",
    "\n",
    "## 3.3. Veri Setinin Avantajları\n",
    "\n",
    "Bu özniteliklerin genişliği sayesinde, model sadece sesin fiziksel frekans özelliklerini değil; aynı zamanda **müzikal yapı ve armoni** gibi soyut bilgileri de öğrenebilmektedir. Bu kapsamlı öznitelik seti, müzik türü sınıflandırma görevinde yüksek performans elde etmemizi sağlamaktadır.\n",
    "\n",
    "### Teknik Avantajlar:\n",
    "- **Çok boyutlu temsil**: 518 farklı öznitelik ile zengin veri temsili\n",
    "- **Önceden işlenmiş**: Manuel öznitelik çıkarımı gerektirmez\n",
    "- **Standartlaştırılmış**: Tüm örnekler aynı format ve sürede\n",
    "- **Dengeli kategorizasyon**: Farklı müzik türlerini kapsayan geniş etiket seti"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7f0c60",
   "metadata": {},
   "source": [
    "## 3.4. Veri Seti Keşfi ve İnceleme\n",
    "\n",
    "Aşağıdaki kod blokları ile FMA veri setinin yapısını, öznitelik dağılımını ve sınıf bilgilerini praktik olarak inceleyelim:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8653fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FMA veri setinin dosya yapısını kontrol et\n",
    "import os\n",
    "\n",
    "print(\"=== FMA Veri Seti Dosya Yapısı ===\")\n",
    "print(f\"Metadata klasörü mevcut: {os.path.exists('fma_metadata')}\")\n",
    "print(f\"Audio klasörü mevcut: {os.path.exists('fma_small')}\")\n",
    "\n",
    "if os.path.exists('fma_metadata'):\n",
    "    metadata_files = os.listdir('fma_metadata')\n",
    "    print(f\"\\nMetadata dosyaları ({len(metadata_files)} adet):\")\n",
    "    for file in sorted(metadata_files):\n",
    "        file_path = os.path.join('fma_metadata', file)\n",
    "        if os.path.isfile(file_path):\n",
    "            file_size = os.path.getsize(file_path) / (1024*1024)  # MB cinsinden\n",
    "            print(f\"  - {file}: {file_size:.2f} MB\")\n",
    "\n",
    "if os.path.exists('fma_small'):\n",
    "    # Ses dosyalarının sayısını hesapla\n",
    "    audio_count = 0\n",
    "    for root, dirs, files in os.walk('fma_small'):\n",
    "        audio_count += len([f for f in files if f.endswith('.mp3')])\n",
    "    print(f\"\\nToplam ses dosyası sayısı: {audio_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cea8309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features.csv dosyasının yapısını incele\n",
    "if os.path.exists('fma_metadata/features.csv'):\n",
    "    print(\"=== Features.csv Dosya Yapısı ===\")\n",
    "    \n",
    "    # İlk birkaç satırı oku (çok seviyeli başlık yapısı)\n",
    "    features_sample = pd.read_csv('fma_metadata/features.csv', nrows=5)\n",
    "    print(f\"Features dosyası boyutu: {features_sample.shape}\")\n",
    "    print(f\"Sütun sayısı: {len(features_sample.columns)}\")\n",
    "    \n",
    "    # Çok seviyeli başlık yapısını doğru şekilde oku\n",
    "    features_full = pd.read_csv('fma_metadata/features.csv', index_col=0, header=[0,1])\n",
    "    \n",
    "    print(f\"\\nToplam örneklem sayısı: {len(features_full)}\")\n",
    "    print(f\"Toplam öznitelik sayısı: {len(features_full.columns)}\")\n",
    "    \n",
    "    # Öznitelik gruplarını analiz et\n",
    "    feature_groups = {}\n",
    "    for col in features_full.columns:\n",
    "        if len(col) >= 2:\n",
    "            group = col[0]  # İlk seviye (ana grup)\n",
    "            if group not in feature_groups:\n",
    "                feature_groups[group] = 0\n",
    "            feature_groups[group] += 1\n",
    "    \n",
    "    print(\"\\n=== Öznitelik Grupları ===\")\n",
    "    for group, count in sorted(feature_groups.items()):\n",
    "        print(f\"{group}: {count} öznitelik\")\n",
    "        \n",
    "    # İlk birkaç öznitelik örneği\n",
    "    print(\"\\n=== Örnek Öznitelikler (İlk 10) ===\")\n",
    "    for i, col in enumerate(features_full.columns[:10]):\n",
    "        print(f\"{i+1}. {col}\")\n",
    "else:\n",
    "    print(\"Features.csv dosyası bulunamadı!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5d6961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracks.csv dosyasını ve tür bilgilerini incele\n",
    "if os.path.exists('fma_metadata/tracks.csv'):\n",
    "    print(\"=== Tracks.csv ve Tür Bilgileri ===\")\n",
    "    \n",
    "    # Tracks dosyasını oku\n",
    "    tracks = pd.read_csv('fma_metadata/tracks.csv', index_col=0, header=[0,1])\n",
    "    print(f\"Tracks dosyası boyutu: {tracks.shape}\")\n",
    "    \n",
    "    # Tür bilgilerini analiz et\n",
    "    if ('track', 'genre_top') in tracks.columns:\n",
    "        genres = tracks[('track', 'genre_top')].dropna()\n",
    "        print(f\"\\nTür bilgisi olan parça sayısı: {len(genres)}\")\n",
    "        \n",
    "        # Tür dağılımı\n",
    "        genre_counts = genres.value_counts()\n",
    "        print(f\"\\nToplam farklı tür sayısı: {len(genre_counts)}\")\n",
    "        \n",
    "        print(\"\\n=== Tür Dağılımı (İlk 10) ===\")\n",
    "        for genre, count in genre_counts.head(10).items():\n",
    "            percentage = (count / len(genres)) * 100\n",
    "            print(f\"{genre}: {count} parça ({percentage:.1f}%)\")\n",
    "            \n",
    "        # En az ve en çok örnekli türler\n",
    "        print(f\"\\nEn çok örnekli tür: {genre_counts.index[0]} ({genre_counts.iloc[0]} parça)\")\n",
    "        print(f\"En az örnekli tür: {genre_counts.index[-1]} ({genre_counts.iloc[-1]} parça)\")\n",
    "        \n",
    "    else:\n",
    "        print(\"Tür bilgisi sütunu bulunamadı!\")\n",
    "else:\n",
    "    print(\"Tracks.csv dosyası bulunamadı!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b18b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Öznitelik gruplarının detaylı analizi\n",
    "if os.path.exists('fma_metadata/features.csv'):\n",
    "    print(\"=== Öznitelik Grupları Detaylı Analiz ===\")\n",
    "    \n",
    "    features = pd.read_csv('fma_metadata/features.csv', index_col=0, header=[0,1])\n",
    "    \n",
    "    # Her grup için öznitelik sayısını ve örnek isimleri göster\n",
    "    detailed_groups = {}\n",
    "    for col in features.columns:\n",
    "        if len(col) >= 2:\n",
    "            group = col[0]\n",
    "            subfeature = col[1] if len(col) > 1 else 'unknown'\n",
    "            \n",
    "            if group not in detailed_groups:\n",
    "                detailed_groups[group] = []\n",
    "            detailed_groups[group].append(subfeature)\n",
    "    \n",
    "    print(\"\\n=== Her Gruptaki Öznitelik Türleri ===\")\n",
    "    for group, subfeatures in sorted(detailed_groups.items()):\n",
    "        print(f\"\\n{group.upper()} Grubu ({len(subfeatures)} öznitelik):\")\n",
    "        \n",
    "        # Benzersiz alt öznitelik türlerini göster\n",
    "        unique_subfeatures = list(set(subfeatures))\n",
    "        for subf in sorted(unique_subfeatures)[:5]:  # İlk 5 tanesi\n",
    "            count = subfeatures.count(subf)\n",
    "            print(f\"  - {subf}: {count} adet\")\n",
    "        \n",
    "        if len(unique_subfeatures) > 5:\n",
    "            print(f\"  ... ve {len(unique_subfeatures) - 5} tür daha\")\n",
    "    \n",
    "    print(\"\\n=== Veri Seti Özeti ===\")\n",
    "    print(f\"✓ Toplam müzik parçası: {len(features):,}\")\n",
    "    print(f\"✓ Toplam öznitelik sayısı: {len(features.columns):,}\")\n",
    "    print(f\"✓ Farklı öznitelik grubu: {len(detailed_groups)}\")\n",
    "    print(f\"✓ Veri boyutu: {features.memory_usage(deep=True).sum() / (1024**2):.1f} MB\")\n",
    "    \n",
    "    # Eksik veri kontrolü\n",
    "    missing_data = features.isnull().sum().sum()\n",
    "    print(f\"✓ Eksik veri: {missing_data:,} hücre ({(missing_data/(len(features)*len(features.columns)))*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89ec12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Öznitelik gruplarının görsel analizi\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "if os.path.exists('fma_metadata/features.csv') and os.path.exists('fma_metadata/tracks.csv'):\n",
    "    \n",
    "    # Features ve tracks verilerini yükle\n",
    "    features = pd.read_csv('fma_metadata/features.csv', index_col=0, header=[0,1])\n",
    "    tracks = pd.read_csv('fma_metadata/tracks.csv', index_col=0, header=[0,1])\n",
    "    \n",
    "    # Öznitelik gruplarının dağılımını görselleştir\n",
    "    feature_groups = {}\n",
    "    for col in features.columns:\n",
    "        if len(col) >= 2:\n",
    "            group = col[0]\n",
    "            if group not in feature_groups:\n",
    "                feature_groups[group] = 0\n",
    "            feature_groups[group] += 1\n",
    "    \n",
    "    # Grafik 1: Öznitelik gruplarının dağılımı\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    groups = list(feature_groups.keys())\n",
    "    counts = list(feature_groups.values())\n",
    "    colors = plt.cm.Set3(np.linspace(0, 1, len(groups)))\n",
    "    \n",
    "    bars = plt.bar(groups, counts, color=colors)\n",
    "    plt.title('Öznitelik Gruplarının Dağılımı', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Öznitelik Grubu')\n",
    "    plt.ylabel('Öznitelik Sayısı')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # Bar üzerinde değerleri göster\n",
    "    for bar, count in zip(bars, counts):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, \n",
    "                str(count), ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # Grafik 2: Tür dağılımı (eğer mevcut ise)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    if ('track', 'genre_top') in tracks.columns:\n",
    "        genres = tracks[('track', 'genre_top')].dropna()\n",
    "        top_genres = genres.value_counts().head(8)\n",
    "        \n",
    "        colors_genre = plt.cm.Paired(np.linspace(0, 1, len(top_genres)))\n",
    "        bars = plt.bar(range(len(top_genres)), top_genres.values, color=colors_genre)\n",
    "        plt.title('En Yaygın 8 Müzik Türü', fontsize=14, fontweight='bold')\n",
    "        plt.xlabel('Müzik Türü')\n",
    "        plt.ylabel('Parça Sayısı')\n",
    "        plt.xticks(range(len(top_genres)), top_genres.index, rotation=45, ha='right')\n",
    "        \n",
    "        # Bar üzerinde değerleri göster\n",
    "        for bar, count in zip(bars, top_genres.values):\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 10, \n",
    "                    str(count), ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n📊 Veri seti görselleştirme tamamlandı!\")\n",
    "else:\n",
    "    print(\"❌ Gerekli dosyalar bulunamadı - görselleştirme yapılamıyor.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f453d21",
   "metadata": {},
   "source": [
    "# 4. ÖZNİTELİK SEÇİMİ (FEATURE SELECTION)\n",
    "\n",
    "## 4.1. Öznitelik Seçiminin Gerekliliği\n",
    "\n",
    "Makine öğrenmesi projelerinde yüksek boyutlu veri setleriyle çalışmak, hem **hesaplama yükünü artırmakta** hem de modelin öğrenme sürecinde **aşırı uyum (overfitting)** riskini beraberinde getirmektedir. Bu nedenle, bu projede **öznitelik seçimi (feature selection)** işlemi uygulanarak sadece en bilgilendirici öznitelikler modele dahil edilmiştir.\n",
    "\n",
    "### Yüksek Boyutluluk Problemleri:\n",
    "- **Hesaplama Karmaşıklığı**: 518 öznitelik işlem süresini önemli ölçüde artırır\n",
    "- **Aşırı Uyum Riski**: Gereksiz öznitelikler modelin genelleme kabiliyetini azaltır\n",
    "- **Gürültü Etkisi**: İlgisiz öznitelikler sınıflandırma performansını olumsuz etkiler\n",
    "- **Bellek Kullanımı**: Yüksek boyutlu veriler daha fazla bellek gerektirir\n",
    "\n",
    "## 4.2. SelectKBest Yöntemi\n",
    "\n",
    "FMA Small veri seti, her bir müzik parçası için toplam **518 öznitelik** içermektedir. Ancak bu özniteliklerin tamamının sınıflandırma açısından eşit öneme sahip olmadığı bilinmektedir. Bu nedenle, **SelectKBest yöntemi** kullanılarak en etkili **225 öznitelik** seçilmiştir.\n",
    "\n",
    "### Yöntem Detayları:\n",
    "- **Algoritma**: SelectKBest (Scikit-learn)\n",
    "- **Skorlama Fonksiyonu**: f_classif (ANOVA F-test)\n",
    "- **Seçilen Öznitelik Sayısı**: 225 (orijinal 518'den)\n",
    "- **Boyut Azaltma Oranı**: %56.6 azaltma\n",
    "\n",
    "### f_classif Skorlama Fonksiyonu:\n",
    "Bu işlem sırasında **f_classif skorlama fonksiyonu** kullanılmış ve her özniteliğin sınıf ayrımına katkısı istatistiksel olarak ölçülmüştür. f_classif, her öznitelik için ANOVA F-test değeri hesaplayarak:\n",
    "- Sınıflar arası varyansı sınıf içi varyansa oranlar\n",
    "- Yüksek F-skoru = Daha iyi sınıf ayrım gücü\n",
    "- Düşük p-değeri = İstatistiksel olarak anlamlı öznitelik\n",
    "\n",
    "## 4.3. Beklenen Faydalar\n",
    "\n",
    "Bu süreç sonucunda oluşturulan eğitim verisi:\n",
    "- ✅ **Hesaplama açısından daha verimli** hale getirilmiş\n",
    "- ✅ **Bilgi yoğunluğu artırılmış** bir yapı kazanmış\n",
    "- ✅ **Aşırı uyum riskini azaltmış**\n",
    "- ✅ **Model genelleme kabiliyetini artırmış**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156bee0f",
   "metadata": {},
   "source": [
    "## 4.4. Öznitelik Seçimi Uygulaması\n",
    "\n",
    "Aşağıdaki kod blokları ile öznitelik seçimi işlemini gerçekleştirip, sonuçları analiz edelim:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d5d385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Öznitelik seçimi için gerekli kütüphaneler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Verinin yüklenmesi ve ön işlenmesi\n",
    "def load_and_preprocess_data():\n",
    "    \"\"\"\n",
    "    FMA veri setini yükler ve öznitelik seçimi için hazırlar.\n",
    "    Uses TRACKS_PATH and FEATURES_PATH from the global configuration.\n",
    "    \"\"\"\n",
    "    print(\"=== Veri Yükleme ve Ön İşleme (Global Config Paths) ===\")\n",
    "    \n",
    "    # Dosya varlığı kontrolü (using global config)\n",
    "    if not os.path.exists(TRACKS_PATH) or not os.path.exists(FEATURES_PATH):\n",
    "        raise FileNotFoundError(f\"Gerekli veri dosyaları bulunamadı! Paths: {TRACKS_PATH}, {FEATURES_PATH}\")\n",
    "    \n",
    "    # Tracks ve features dosyalarını yükle\n",
    "    tracks = pd.read_csv(TRACKS_PATH, index_col=0, header=[0,1])\n",
    "    features_df = pd.read_csv(FEATURES_PATH, index_col=0, header=[0,1]) # Renamed to avoid conflict\n",
    "    \n",
    "    # Statistics sütunlarını kaldır ve sayısal formata dönüştür\n",
    "    # Ensure features_df is used here\n",
    "    features_df = features_df.loc[:, features_df.columns.get_level_values(0) != 'statistics']\n",
    "    features_df = features_df.astype(np.float32)\n",
    "    \n",
    "    # İndeksleri string formatına dönüştür\n",
    "    features_df.index = features_df.index.astype(str)\n",
    "    tracks.index = tracks.index.astype(str)\n",
    "    \n",
    "    # Tür bilgilerini al\n",
    "    genre_series = tracks[('track', 'genre_top')].dropna()\n",
    "    \n",
    "    # Ortak indeksleri bul\n",
    "    common_index = features_df.index.intersection(genre_series.index)\n",
    "    \n",
    "    # Veriyi filtrele\n",
    "    X = features_df.loc[common_index]\n",
    "    y_labels = genre_series.loc[common_index]\n",
    "    \n",
    "    # Eksik ve sonsuz değerleri temizle\n",
    "    X = X.fillna(0).replace([np.inf, -np.inf], 0).astype(np.float32)\n",
    "    \n",
    "    # Etiketleri sayısallaştır\n",
    "    label_encoder = LabelEncoder()\n",
    "    y = label_encoder.fit_transform(y_labels)\n",
    "    \n",
    "    print(f\"✅ Orijinal veri boyutu (X): {X.shape}\")\n",
    "    print(f\"✅ Toplam sınıf sayısı: {len(label_encoder.classes_)}\")\n",
    "    print(f\"✅ Sınıflar: {', '.join(label_encoder.classes_)}\")\n",
    "    \n",
    "    return X, y, label_encoder, features_df.columns # Return original X, y, encoder, and original feature columns\n",
    "\n",
    "# Veriyi yükle\n",
    "X_original, y_original_labels, label_encoder_global, original_feature_columns = load_and_preprocess_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94798f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Öznitelik seçimi uygulama\n",
    "print(\"=== Öznitelik Seçimi (SelectKBest) ===\")\n",
    "\n",
    "# SelectKBest ile en iyi K_BEST özniteliği seç (K_BEST from global config)\n",
    "selector = SelectKBest(score_func=f_classif, k=K_BEST)\n",
    "\n",
    "# Öznitelik seçimini uygula (using X_original and y_original_labels from fc93bb40)\n",
    "X_selected = selector.fit_transform(X_original, y_original_labels) # Use y_original_labels (numeric) for fitting\n",
    "\n",
    "# Seçilen özniteliklerin indekslerini al\n",
    "selected_features_mask = selector.get_support()\n",
    "# Use original_feature_columns from fc93bb40\n",
    "selected_feature_names = original_feature_columns[selected_features_mask] \n",
    "\n",
    "# F-skorlarını al\n",
    "f_scores = selector.scores_\n",
    "selected_f_scores = f_scores[selected_features_mask]\n",
    "\n",
    "print(f\"\\n📊 Öznitelik Seçimi Sonuçları:\")\n",
    "print(f\"   • Orijinal öznitelik sayısı: {X_original.shape[1]}\")\n",
    "print(f\"   • Seçilen öznitelik sayısı: {X_selected.shape[1]} (K_BEST={K_BEST})\")\n",
    "print(f\"   • Boyut azaltma oranı: {((X_original.shape[1] - X_selected.shape[1]) / X_original.shape[1] * 100):.1f}%\")\n",
    "print(f\"   • Veri boyutu değişimi: {X_original.shape} → {X_selected.shape}\")\n",
    "\n",
    "# En yüksek F-Skorlu öznitelikleri göster\n",
    "print(f\"\\n🏆 En Yüksek F-Skorlu 10 Öznitelik:\")\n",
    "# Sort selected_f_scores and get top indices from that sorted list\n",
    "sorted_indices_selected = np.argsort(selected_f_scores)[::-1] # Sort descending\n",
    "top_indices_selected = sorted_indices_selected[:10]\n",
    "\n",
    "for i, idx in enumerate(top_indices_selected):\n",
    "    feature_name = selected_feature_names[idx]\n",
    "    score = selected_f_scores[idx]\n",
    "    print(f\"   {i+1:2d}. {feature_name}: {score:.2f}\")\n",
    "\n",
    "# X_selected and selected_feature_names are now available for downstream use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf43ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seçilen özniteliklerin grup analizi\n",
    "print(\"\\n=== Seçilen Özniteliklerin Grup Analizi ===\")\n",
    "\n",
    "# Orijinal ve seçilen özniteliklerin grup dağılımını karşılaştır\n",
    "original_groups = {}\n",
    "selected_groups = {}\n",
    "\n",
    "# Orijinal öznitelik gruplarını say (using original_feature_columns from fc93bb40)\n",
    "for col in original_feature_columns:\n",
    "    if len(col) >= 2:\n",
    "        group = col[0]\n",
    "        if group not in original_groups:\n",
    "            original_groups[group] = 0\n",
    "        original_groups[group] += 1\n",
    "\n",
    "# Seçilen öznitelik gruplarını say (using selected_feature_names from 980a711c)\n",
    "for col in selected_feature_names:\n",
    "    if len(col) >= 2:\n",
    "        group = col[0]\n",
    "        if group not in selected_groups:\n",
    "            selected_groups[group] = 0\n",
    "        selected_groups[group] += 1\n",
    "\n",
    "# Karşılaştırma tablosu oluştur\n",
    "comparison_data = []\n",
    "for group in original_groups.keys():\n",
    "    original_count = original_groups[group]\n",
    "    selected_count = selected_groups.get(group, 0)\n",
    "    selection_rate = (selected_count / original_count) * 100 if original_count > 0 else 0\n",
    "    \n",
    "    comparison_data.append({\n",
    "        'Öznitelik Grubu': group,\n",
    "        'Orijinal Sayı': original_count,\n",
    "        'Seçilen Sayı': selected_count,\n",
    "        'Seçim Oranı (%)': f\"{selection_rate:.1f}%\"\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"\\n📋 Öznitelik Grupları Karşılaştırması:\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Hangi grupların daha çok seçildiğini analiz et\n",
    "print(\"\\n🎯 Grup Seçim Analizi:\")\n",
    "for _, row in comparison_df.iterrows():\n",
    "    group = row['Öznitelik Grubu']\n",
    "    rate = float(row['Seçim Oranı (%)'].replace('%', ''))\n",
    "    if rate >= 50:\n",
    "        print(f\"   ✅ {group}: Yüksek seçim oranı ({rate:.1f}%) - Bu grup sınıflandırma için önemli\")\n",
    "    elif rate >= 30:\n",
    "        print(f\"   🔶 {group}: Orta seçim oranı ({rate:.1f}%) - Kısmen bilgilendirici\")\n",
    "    else:\n",
    "        print(f\"   ❌ {group}: Düşük seçim oranı ({rate:.1f}%) - Sınıflandırma için az önemli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd0e902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Öznitelik seçimi sonuçlarının görselleştirilmesi\n",
    "print(\"\\n=== Öznitelik Seçimi Görselleştirme ===\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Öznitelik Seçimi Analiz Sonuçları', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. F-skorlarının dağılımı\n",
    "ax1 = axes[0, 0]\n",
    "ax1.hist(f_scores, bins=50, alpha=0.7, color='lightblue', edgecolor='black')\n",
    "# Use K_BEST from config for the threshold line\n",
    "ax1.axvline(np.sort(f_scores)[-K_BEST], color='red', linestyle='--', linewidth=2, label=f'Seçim Eşiği (Top {K_BEST})')\n",
    "ax1.set_title('F-Skorlarının Dağılımı')\n",
    "ax1.set_xlabel('F-Skoru')\n",
    "ax1.set_ylabel('Frekans')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Öznitelik gruplarının karşılaştırması\n",
    "ax2 = axes[0, 1]\n",
    "groups = list(original_groups.keys())\n",
    "x_pos = np.arange(len(groups))\n",
    "original_counts = [original_groups[g] for g in groups]\n",
    "selected_counts = [selected_groups.get(g, 0) for g in groups]\n",
    "\n",
    "width = 0.35\n",
    "ax2.bar(x_pos - width/2, original_counts, width, label='Orijinal', alpha=0.7, color='lightcoral')\n",
    "ax2.bar(x_pos + width/2, selected_counts, width, label='Seçilen', alpha=0.7, color='lightgreen')\n",
    "ax2.set_title('Öznitelik Grupları: Orijinal vs Seçilen')\n",
    "ax2.set_xlabel('Öznitelik Grubu')\n",
    "ax2.set_ylabel('Öznitelik Sayısı')\n",
    "ax2.set_xticks(x_pos)\n",
    "ax2.set_xticklabels(groups, rotation=45, ha='right')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. En yüksek F-skorlu öznitelikler\n",
    "ax3 = axes[1, 0]\n",
    "top_n = 15\n",
    "# Use selected_f_scores and selected_feature_names from cell 980a711c\n",
    "sorted_indices_selected_viz = np.argsort(selected_f_scores)[-top_n:] # Get indices of top N from selected_f_scores\n",
    "top_scores_viz = selected_f_scores[sorted_indices_selected_viz]\n",
    "top_names_viz = [str(selected_feature_names[i]) for i in sorted_indices_selected_viz]\n",
    "\n",
    "# Öznitelik isimlerini kısalt\n",
    "top_names_short = [name.replace('(', '').replace(')', '').replace(',', '_')[:20] + '...' if len(str(name)) > 23 else str(name) for name in top_names_viz]\n",
    "\n",
    "y_pos = np.arange(len(top_names_short))\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(top_scores_viz)))\n",
    "ax3.barh(y_pos, top_scores_viz, color=colors)\n",
    "ax3.set_title(f'En Yüksek F-Skorlu {top_n} Öznitelik')\n",
    "ax3.set_xlabel('F-Skoru')\n",
    "ax3.set_yticks(y_pos)\n",
    "ax3.set_yticklabels(top_names_short, fontsize=8)\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Boyut azaltma etkisi\n",
    "ax4 = axes[1, 1]\n",
    "labels = ['Orijinal Boyut', 'Seçilen Boyut']\n",
    "sizes = [X_original.shape[1], X_selected.shape[1]]\n",
    "colors = ['#ff9999', '#66b3ff']\n",
    "explode = (0, 0.1)  # Seçilen kısmı vurgula\n",
    "\n",
    "ax4.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%',\n",
    "        shadow=True, startangle=90)\n",
    "ax4.set_title('Boyut Azaltma Etkisi')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✅ Öznitelik seçimi görselleştirmesi tamamlandı!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2046ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Öznitelik seçiminin etkilerinin detaylı analizi\n",
    "print(\"\\n=== Öznitelik Seçimi Etki Analizi ===\")\n",
    "\n",
    "# Bellek kullanımı karşılaştırması\n",
    "original_memory = X_original.memory_usage(deep=True).sum() / (1024**2)  # MB\n",
    "selected_memory = pd.DataFrame(X_selected).memory_usage(deep=True).sum() / (1024**2)  # MB\n",
    "memory_reduction = ((original_memory - selected_memory) / original_memory) * 100\n",
    "\n",
    "print(f\"\\n💾 Bellek Kullanımı Analizi:\")\n",
    "print(f\"   • Orijinal veri bellek kullanımı: {original_memory:.1f} MB\")\n",
    "print(f\"   • Seçilen veri bellek kullanımı: {selected_memory:.1f} MB\")\n",
    "print(f\"   • Bellek tasarrufu: {memory_reduction:.1f}% ({original_memory-selected_memory:.1f} MB)\")\n",
    "\n",
    "# Hesaplama karmaşıklığı tahmini\n",
    "original_complexity = X_original.shape[0] * X_original.shape[1]\n",
    "selected_complexity = X_selected.shape[0] * X_selected.shape[1]\n",
    "complexity_reduction = ((original_complexity - selected_complexity) / original_complexity) * 100\n",
    "\n",
    "print(f\"\\n⚡ Hesaplama Karmaşıklığı:\")\n",
    "print(f\"   • Orijinal işlem sayısı: {original_complexity:,}\")\n",
    "print(f\"   • Seçilen işlem sayısı: {selected_complexity:,}\")\n",
    "print(f\"   • Hesaplama azalması: {complexity_reduction:.1f}%\")\n",
    "\n",
    "# En bilgilendirici öznitelik gruplarını belirle\n",
    "print(f\"\\n🎯 En Bilgilendirici Öznitelik Grupları:\")\n",
    "group_importance = {}\n",
    "for i, col in enumerate(selected_feature_names):\n",
    "    if len(col) >= 2:\n",
    "        group = col[0]\n",
    "        score = selected_f_scores[i]\n",
    "        if group not in group_importance:\n",
    "            group_importance[group] = []\n",
    "        group_importance[group].append(score)\n",
    "\n",
    "# Her grup için ortalama F-skoru hesapla\n",
    "group_avg_scores = {}\n",
    "for group, scores in group_importance.items():\n",
    "    group_avg_scores[group] = np.mean(scores)\n",
    "\n",
    "# Grupları önem sırasına göre sırala\n",
    "sorted_groups = sorted(group_avg_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for i, (group, avg_score) in enumerate(sorted_groups):\n",
    "    count = len(group_importance[group])\n",
    "    selection_rate = (count / original_groups[group]) * 100\n",
    "    print(f\"   {i+1}. {group}: Ort. F-skoru={avg_score:.2f}, Seçilen={count}/{original_groups[group]} ({selection_rate:.1f}%)\")\n",
    "\n",
    "print(f\"\\n📈 Özet:\")\n",
    "print(f\"   ✅ Veri boyutu {X_original.shape[1]} → {X_selected.shape[1]} özniteliğe düşürüldü\")\n",
    "print(f\"   ✅ {memory_reduction:.1f}% bellek tasarrufu sağlandı\")\n",
    "print(f\"   ✅ {complexity_reduction:.1f}% hesaplama karmaşıklığı azaltıldı\")\n",
    "print(f\"   ✅ En bilgilendirici grup: {sorted_groups[0][0]} (Ort. F-skoru: {sorted_groups[0][1]:.2f})\")\n",
    "print(f\"   ✅ Model aşırı uyum riski azaltıldı\")\n",
    "print(f\"   ✅ Eğitim süresi optimize edildi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2d68df",
   "metadata": {},
   "source": [
    "## 4.5. Sonraki Adımlar\n",
    "\n",
    "Öznitelik seçimi işlemi tamamlandıktan sonra, veri seti şu şekilde hazır hale gelmiştir:\n",
    "\n",
    "### ✅ Tamamlanan İşlemler:\n",
    "1. **Boyut Azaltma**: 518 → 225 öznitelik\n",
    "2. **Etiket Kodlama**: Müzik türleri sayısallaştırıldı\n",
    "3. **Veri Temizleme**: Eksik ve sonsuz değerler giderildi\n",
    "4. **Optimizasyon**: Bellek ve hesaplama verimliliği artırıldı\n",
    "\n",
    "### 🔄 Sıradaki İşlemler:\n",
    "1. **Veri Dengeleme**: RandomOverSampler + BorderlineSMOTE\n",
    "2. **Eğitim-Test Bölme**: Stratified split uygulaması\n",
    "3. **Model Eğitimi**: LSTM ağ yapısı\n",
    "4. **Performans Değerlendirme**: Accuracy, precision, recall metrikleri\n",
    "\n",
    "Veri seti artık **sınıf dengesizliği problemi çözülmek üzere** bir sonraki aşamaya hazırdır."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c705ac60",
   "metadata": {},
   "source": [
    "## Başlangıç Veri Analizi\n",
    "\n",
    "# Veriyi yükle ve önişle - This cell now relies on variables from cell fc93bb40\n",
    "# X_original, y_original_labels, label_encoder_global, original_feature_columns are already loaded\n",
    "\n",
    "print(\"Plotting initial class distribution using data from 'load_and_preprocess_data'...\")\n",
    "# y_original_labels is numeric here, label_encoder_global.classes_ provides the names\n",
    "plot_class_distribution(y_original_labels, label_encoder_global.classes_, 'Başlangıç Sınıf Dağılımı (Filtrelenmemiş)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ef4617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veriyi böl ve eğitim dağılımını göster\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_selected, y_original_labels, test_size=0.2, stratify=y_original_labels, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "plot_class_distribution(y_train, label_encoder_global.classes_, 'Eğitim Seti Dağılımı')\n",
    "print(f'Eğitim/test bölünmesi tamamlandı: X_train {X_train.shape}, X_test {X_test.shape}')\n",
    "\n",
    "# Detaylı dağılımı yazdır\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "print(\"\\nEğitim Seti Dağılımı (ham sayılar):\")\n",
    "for i, (u, c) in enumerate(zip(unique, counts)):\n",
    "    print(f\"Sınıf {u} ({label_encoder_global.classes_[i]}): {c} örnek\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48a9420",
   "metadata": {},
   "source": [
    "## Veri Dengeleme - Aşama 1\n",
    "\n",
    "İlk aşamada, çok az örneğe sahip sınıflar için RandomOverSampler kullanılıyor. Bu aşama, BorderlineSMOTE için yeterli örnek sayısına ulaşmamızı sağlar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d82e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adım 1: En az temsil edilen sınıflar için RandomOverSampler\n",
    "print('\\nAdım 1: Aşırı az temsil edilen sınıflar için RandomOverSampler uygulanıyor...')\n",
    "\n",
    "# Mevcut sınıf dağılımını kontrol et\n",
    "unique_train, counts_train = np.unique(y_train, return_counts=True)\n",
    "print(\"\\nEğitim setindeki mevcut dağılım:\")\n",
    "for i, (u, c) in enumerate(zip(unique_train, counts_train)):\n",
    "    class_name = label_encoder_global.classes_[u]\n",
    "    print(f\"Sınıf {u} ({class_name}): {c} örnek\")\n",
    "\n",
    "# MIN_SAMPLES_THRESHOLD'dan az örneğe sahip sınıfları belirle\n",
    "classes_to_oversample = {}\n",
    "for i, (u, c) in enumerate(zip(unique_train, counts_train)):\n",
    "    if c < MIN_SAMPLES_THRESHOLD:\n",
    "        classes_to_oversample[u] = MIN_SAMPLES_THRESHOLD\n",
    "        class_name = label_encoder_global.classes_[u]\n",
    "        print(f\"Sınıf {u} ({class_name}) örneklem sayısı {c} → {MIN_SAMPLES_THRESHOLD} artırılacak\")\n",
    "\n",
    "# Eğer örneklem artırılacak sınıf varsa RandomOverSampler uygula\n",
    "if classes_to_oversample:\n",
    "    ros = RandomOverSampler(sampling_strategy=classes_to_oversample, random_state=RANDOM_STATE)\n",
    "    X_partial, y_partial = ros.fit_resample(X_train, y_train)\n",
    "    print(f\"\\nRandomOverSampler uygulandı: {len(classes_to_oversample)} sınıf için örneklem artırıldı\")\n",
    "else:\n",
    "    X_partial, y_partial = X_train, y_train\n",
    "    print(f\"\\nTüm sınıflar zaten {MIN_SAMPLES_THRESHOLD} eşiğinin üzerinde, RandomOverSampler uygulanmadı\")\n",
    "\n",
    "# Ara sonuçları göster\n",
    "unique_partial, counts_partial = np.unique(y_partial, return_counts=True)\n",
    "print(\"\\nRandomOverSampler sonrası dağılım (ham sayılar):\")\n",
    "for i, (u, c) in enumerate(zip(unique_partial, counts_partial)):\n",
    "    # Use label_encoder_global from cell 20 for class names\n",
    "    print(f\"Sınıf {u} ({label_encoder_global.classes_[i]}): {c} örnek\")\n",
    "\n",
    "# Use label_encoder_global from cell 20 for class names\n",
    "plot_class_distribution(y_partial, label_encoder_global.classes_, 'RandomOverSampler Sonrası')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0017c8",
   "metadata": {},
   "source": [
    "## Veri Dengeleme - Aşama 2\n",
    "\n",
    "İkinci aşamada, daha sofistike bir yaklaşım olan BorderlineSMOTE kullanılarak kalan sınıflar dengeleniyor. Bu yöntem, sadece rastgele kopyalama yerine sentetik örnekler oluşturur.\n",
    "\n",
    "Not: Bu aşama, veri setinin yapısına bağlı olarak başarısız olabilir. Bu durumda, ilk aşamadaki sonuçlar kullanılacaktır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08db968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adım 2: Kalan sınıflar için BorderlineSMOTE\n",
    "print('\\nAdım 2: Kalan sınıflar için BorderlineSMOTE uygulanıyor...')\n",
    "borderline_smote = BorderlineSMOTE(random_state=RANDOM_STATE) # Use RANDOM_STATE from config\n",
    "\n",
    "try:\n",
    "    X_res, y_res = borderline_smote.fit_resample(X_partial, y_partial)\n",
    "    print(f'Kombine örnekleme tamamlandı: X_res {X_res.shape}, y_res {y_res.shape}')\n",
    "    \n",
    "    # Son dağılımı yazdır ve göster\n",
    "    unique_res, counts_res = np.unique(y_res, return_counts=True)\n",
    "    print(\"\\nSon Dağılım (ham sayılar):\")\n",
    "    for i, (u, c) in enumerate(zip(unique_res, counts_res)):\n",
    "        # Use label_encoder_global from cell 20 for class names\n",
    "        print(f\"Sınıf {u} ({label_encoder_global.classes_[i]}): {c} örnek\")\n",
    "    \n",
    "    # Use label_encoder_global from cell 20 for class names\n",
    "    plot_class_distribution(y_res, label_encoder_global.classes_, 'Son Dengelenmiş Dağılım')\n",
    "\n",
    "except Exception as e:\n",
    "    print(f'BorderlineSMOTE örnekleme başarısız oldu: {e} - kısmi örneklenmiş veri kullanılıyor')\n",
    "    X_res, y_res = X_partial, y_partial\n",
    "    # Use label_encoder_global from cell 20 for class names\n",
    "    plot_class_distribution(y_res, label_encoder_global.classes_, 'Kısmi Örnekleme (BorderlineSMOTE başarısız)')\n",
    "\n",
    "print(\"\\nİşlem hattı tamamlandı. Yeniden örneklenmiş eğitim verisi (X_res, y_res) ve test verisi (X_test, y_test) hazır.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36224907",
   "metadata": {},
   "source": [
    "## PyTorch LSTM MODEL EĞİTİMİ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a149b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPyTorch LSTM Model Eğitimi Başlıyor...\")\n",
    "\n",
    "# Veri yükleme, önişleme, bölme ve dengeleme adımlarının tamamlandığı varsayılır.\n",
    "# Bu noktada aşağıdaki değişkenlerin mevcut olması beklenir:\n",
    "# X_res, y_res (Dengelenmiş eğitim verisi)\n",
    "# X_test, y_test (Test verisi)\n",
    "# label_encoder_global (LabelEncoder nesnesi)\n",
    "# X_val, y_val (Doğrulama verisi - bir sonraki hücrede oluşturulacak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2538a571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dengelenmiş veri setinden doğrulama seti ayır\n",
    "X_train_bal, X_val, y_train_bal, y_val = train_test_split(\n",
    "    X_res, y_res, test_size=0.1, stratify=y_res, random_state=RANDOM_STATE # Use RANDOM_STATE from config\n",
    ")\n",
    "\n",
    "# Veri Ölçeklendirme (StandardScaler)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_bal)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test) # Ensure X_test from the initial split is used here\n",
    "\n",
    "print(\"Veri ölçeklendirme tamamlandı.\")\n",
    "print(f\"Ölçeklenmiş eğitim verisi boyutu: {X_train_scaled.shape}\")\n",
    "print(f\"Ölçeklenmiş doğrulama verisi boyutu: {X_val_scaled.shape}\")\n",
    "print(f\"Ölçeklenmiş test verisi boyutu: {X_test_scaled.shape}\")\n",
    "\n",
    "# Save the scaler for later use (using global config path)\n",
    "save_scaler_and_encoder(scaler, label_encoder_global, SCALER_SAVE_PATH, ENCODER_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ad9976",
   "metadata": {},
   "source": [
    "## LSTM Modeli için Veri Hazırlığı\n",
    "\n",
    "PyTorch LSTM modeli için, veriyi uygun formata dönüştürmemiz gerekir. LSTM modeller sıralı veri bekler, bu nedenle öznitelik vektörünü zamansal bir diziye dönüştüreceğiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57400533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch tensörlerine dönüştürme ve veri setlerini hazırlama\n",
    "def create_sequence_data(X, y, sequence_length=SEQUENCE_LENGTH): # Use SEQUENCE_LENGTH from config\n",
    "    \"\"\"\n",
    "    Öznitelik vektörünü sıralı verilere dönüştürür.\n",
    "    FMA veri seti sıralı yapıda değil, bu nedenle yapay bir sıra oluşturuyoruz.\n",
    "    \"\"\"\n",
    "    # Veri boyutlarını kontrol et\n",
    "    n_samples, n_features = X.shape\n",
    "    \n",
    "    # Veriyi yeniden şekillendirme\n",
    "    features_per_timestep = n_features // sequence_length\n",
    "    \n",
    "    if features_per_timestep == 0:\n",
    "        print(f\"Warning: features_per_timestep is 0. n_features={n_features}, sequence_length={sequence_length}. Adjusting sequence_length.\")\n",
    "        features_per_timestep = 1 # Ensure at least one feature per timestep\n",
    "        sequence_length = min(sequence_length, n_features) # Adjust sequence length if too large\n",
    "        print(f\"Adjusted: features_per_timestep={features_per_timestep}, sequence_length={sequence_length}\")\n",
    "\n",
    "    # Son timestep'e sığmayan özellikleri ele alma (padding or truncation implicitly handled by slicing)\n",
    "    # X_padded = np.pad(X, ((0,0), (0, sequence_length * features_per_timestep - n_features)), 'constant') if n_features < sequence_length * features_per_timestep else X[:, :sequence_length * features_per_timestep]\n",
    "    # X_reshaped = X_padded.reshape(n_samples, sequence_length, features_per_timestep)\n",
    "    \n",
    "    # Yeniden şekillendirilmiş veri için array oluşturma\n",
    "    # Ensure the last dimension matches features_per_timestep\n",
    "    X_seq = np.zeros((n_samples, sequence_length, features_per_timestep))\n",
    "    \n",
    "    # Veriyi yeniden şekillendirme\n",
    "    for i in range(n_samples):\n",
    "        for t in range(sequence_length):\n",
    "            start_idx = t * features_per_timestep\n",
    "            # Ensure end_idx does not exceed n_features and slice correctly for X_seq's last dimension\n",
    "            end_idx = start_idx + features_per_timestep \n",
    "            current_features_slice = X[i, start_idx:end_idx]\n",
    "            X_seq[i, t, :len(current_features_slice)] = current_features_slice\n",
    "\n",
    "    # PyTorch tensörlerine dönüştürme\n",
    "    X_tensor = torch.FloatTensor(X_seq).to(device) # Move to device\n",
    "    y_tensor = torch.LongTensor(y).to(device)   # Move to device\n",
    "    \n",
    "    return X_tensor, y_tensor\n",
    "\n",
    "# Sıralı veri için hiperparametre (SEQUENCE_LENGTH is from global config)\n",
    "\n",
    "# Ölçeklenmiş verileri sıralı forma dönüştürme\n",
    "X_train_seq, y_train_tensor = create_sequence_data(X_train_scaled, y_train_bal)\n",
    "X_val_seq, y_val_tensor = create_sequence_data(X_val_scaled, y_val)\n",
    "X_test_seq, y_test_tensor = create_sequence_data(X_test_scaled, y_test)\n",
    "\n",
    "print(f\"Eğitim veri boyutu (Tensor): {X_train_seq.shape}, Etiketler: {y_train_tensor.shape}\")\n",
    "print(f\"Doğrulama veri boyutu (Tensor): {X_val_seq.shape}, Etiketler: {y_val_tensor.shape}\")\n",
    "print(f\"Test veri boyutu (Tensor): {X_test_seq.shape}, Etiketler: {y_test_tensor.shape}\")\n",
    "\n",
    "# PyTorch DataLoader oluşturma (BATCH_SIZE from global config)\n",
    "train_dataset = TensorDataset(X_train_seq, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_seq, y_val_tensor)\n",
    "test_dataset = TensorDataset(X_test_seq, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"DataLoaders created with batch size: {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d3a574",
   "metadata": {},
   "source": [
    "## 📊 LSTM Model Tanımı ve Eğitimi\n",
    "\n",
    "Aşağıda müzik türü sınıflandırması için bir LSTM (Long Short-Term Memory) ağı tanımlıyoruz. LSTM'ler, müzik gibi sıralı verilerde başarılı olan bir derin öğrenme mimarisidir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72764d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === LSTM Model Definition ===\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers, dropout_prob, bidirectional=True):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, \n",
    "                              batch_first=True, dropout=dropout_prob, \n",
    "                              bidirectional=bidirectional)\n",
    "        \n",
    "        # Adjust linear layer input if bidirectional\n",
    "        self.fc_input_dim = hidden_dim * 2 if bidirectional else hidden_dim\n",
    "        self.fc = nn.Linear(self.fc_input_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, seq_length, input_dim)\n",
    "        # h0 and c0 are initialized to zero by default if not provided\n",
    "        out, (hn, cn) = self.lstm(x)\n",
    "        \n",
    "        # out shape: (batch_size, seq_length, hidden_dim * num_directions)\n",
    "        # We are interested in the output of the last time step\n",
    "        if self.lstm.bidirectional:\n",
    "            # Concatenate the last hidden state of the forward pass (from hn)\n",
    "            # and the last hidden state of the backward pass (from hn)\n",
    "            # hn shape: (num_layers * num_directions, batch, hidden_dim)\n",
    "            # Forward direction: hn[-2,:,:] (last layer, forward)\n",
    "            # Backward direction: hn[-1,:,:] (last layer, backward)\n",
    "            out_forward = hn[-2,:,:] \n",
    "            out_backward = hn[-1,:,:]\n",
    "            out_concat = torch.cat((out_forward, out_backward), dim=1)\n",
    "        else:\n",
    "            # If not bidirectional, just take the last hidden state of the last layer\n",
    "            # hn shape: (num_layers, batch, hidden_dim)\n",
    "            out_concat = hn[-1,:,:] # (batch, hidden_dim)\n",
    "            \n",
    "        out_concat = self.dropout(out_concat)\n",
    "        out = self.fc(out_concat) # (batch, output_dim)\n",
    "        return out\n",
    "\n",
    "# Model Instantiation using global config\n",
    "input_dim = X_train_seq.shape[2]  # Number of features per timestep\n",
    "output_dim = len(label_encoder_global.classes_)\n",
    "\n",
    "model = LSTMClassifier(input_dim, HIDDEN_SIZE, output_dim, NUM_LAYERS, DROPOUT_PROB, BIDIRECTIONAL)\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "print(f\"LSTM Model Instantiated on {device}:\")\n",
    "print(model)\n",
    "print(f\"Input Dim: {input_dim}, Hidden Dim: {HIDDEN_SIZE}, Output Dim: {output_dim}, Layers: {NUM_LAYERS}, Dropout: {DROPOUT_PROB}, Bidirectional: {BIDIRECTIONAL}\")\n",
    "print(f\"Optimizer: Adam, LR: {LEARNING_RATE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95425cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Model Training Loop ===\n",
    "print(\"\\nStarting LSTM Model Training...\")\n",
    "\n",
    "# Fix for NumPy 2.0 compatibility - replace np.Inf with np.inf in any imported modules\n",
    "import numpy as np\n",
    "\n",
    "# Define EarlyStopping class for NumPy 2.0 compatibility\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt'):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}). Saving model...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss\n",
    "\n",
    "# Define load_model helper function\n",
    "def load_model(model, path_param):\n",
    "    model.load_state_dict(torch.load(path_param))\n",
    "    return model\n",
    "\n",
    "# Initialize EarlyStopping with patience and model save path from config\n",
    "early_stopping = EarlyStopping(patience=PATIENCE_EARLY_STOPPING, verbose=True, path=MODEL_SAVE_PATH)\n",
    "\n",
    "training_history = {'loss': [], 'acc': [], 'val_loss': [], 'val_acc': []}\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    for i, (sequences, labels) in enumerate(train_loader):\n",
    "        sequences, labels = sequences.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(sequences)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * sequences.size(0)\n",
    "        _, predicted_train = torch.max(outputs.data, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted_train == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / total_train\n",
    "    epoch_acc = correct_train / total_train\n",
    "    training_history['loss'].append(epoch_loss)\n",
    "    training_history['acc'].append(epoch_acc)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    with torch.no_grad():\n",
    "        for sequences_val, labels_val in val_loader:\n",
    "            sequences_val, labels_val = sequences_val.to(device), labels_val.to(device)\n",
    "            outputs_val = model(sequences_val)\n",
    "            loss_val = criterion(outputs_val, labels_val)\n",
    "            val_running_loss += loss_val.item() * sequences_val.size(0)\n",
    "            _, predicted_val = torch.max(outputs_val.data, 1)\n",
    "            total_val += labels_val.size(0)\n",
    "            correct_val += (predicted_val == labels_val).sum().item()\n",
    "\n",
    "    epoch_val_loss = val_running_loss / total_val\n",
    "    epoch_val_acc = correct_val / total_val\n",
    "    training_history['val_loss'].append(epoch_val_loss)\n",
    "    training_history['val_acc'].append(epoch_val_acc)\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{EPOCHS} - Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}, Val Loss: {epoch_val_loss:.4f}, Val Acc: {epoch_val_acc:.4f}')\n",
    "\n",
    "    # Early stopping call (path is now handled within the EarlyStopping class)\n",
    "    early_stopping(epoch_val_loss, model)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "print(\"Training finished.\")\n",
    "# Load best model\n",
    "# Ensure model is an instance of LSTMClassifier before calling load_model\n",
    "if isinstance(model, LSTMClassifier):\n",
    "    model = load_model(model, path_param=MODEL_SAVE_PATH) # Use the specific load_model helper\n",
    "    print(f\"Best model re-loaded from {MODEL_SAVE_PATH} using helper function.\")\n",
    "else:\n",
    "    # Fallback to direct loading if model object type is unexpected, though it should be LSTMClassifier\n",
    "    model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
    "    print(f\"Best model loaded from {MODEL_SAVE_PATH} directly.\")\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(training_history['loss'], label='Training Loss')\n",
    "plt.plot(training_history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(training_history['acc'], label='Training Accuracy')\n",
    "plt.plot(training_history['val_acc'], label='Validation Accuracy')\n",
    "plt.title('Accuracy Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b3bc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Model Evaluation on Test Set ===\n",
    "print(\"\\nEvaluating model on the test set...\")\n",
    "model.eval()\n",
    "y_pred_list = []\n",
    "y_true_list = []\n",
    "y_prob_list = [] # For ROC-AUC\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sequences_test, labels_test in test_loader:\n",
    "        sequences_test, labels_test = sequences_test.to(device), labels_test.to(device)\n",
    "        outputs_test = model(sequences_test)\n",
    "        \n",
    "        # Probabilities for ROC-AUC\n",
    "        probs = torch.softmax(outputs_test, dim=1)\n",
    "        y_prob_list.extend(probs.cpu().numpy())\n",
    "        \n",
    "        _, predicted_test = torch.max(outputs_test.data, 1)\n",
    "        y_pred_list.extend(predicted_test.cpu().numpy())\n",
    "        y_true_list.extend(labels_test.cpu().numpy())\n",
    "\n",
    "y_pred_np = np.array(y_pred_list)\n",
    "y_true_np = np.array(y_true_list)\n",
    "y_prob_np = np.array(y_prob_list)\n",
    "\n",
    "# Classification Report and Confusion Matrix\n",
    "print(\"\\nTest Set Evaluation:\")\n",
    "plot_confusion_matrix_and_report(y_true_np, y_pred_np, label_encoder_global.classes_, title='Test Set Confusion Matrix')\n",
    "\n",
    "# Advanced Metrics\n",
    "print(\"\\nAdvanced Test Set Metrics:\")\n",
    "# Pass the number of classes for num_classes_for_roc\n",
    "advanced_metrics(y_true_np, y_pred_np, y_prob_np, num_classes_for_roc=len(label_encoder_global.classes_))\n",
    "\n",
    "# Log Experiment\n",
    "experiment_params = {\n",
    "    \"K_BEST\": K_BEST,\n",
    "    \"SEQUENCE_LENGTH\": SEQUENCE_LENGTH,\n",
    "    \"HIDDEN_SIZE\": HIDDEN_SIZE,\n",
    "    \"NUM_LAYERS\": NUM_LAYERS,\n",
    "    \"DROPOUT_PROB\": DROPOUT_PROB,\n",
    "    \"BIDIRECTIONAL\": BIDIRECTIONAL,\n",
    "    \"LEARNING_RATE\": LEARNING_RATE,\n",
    "    \"EPOCHS_RUN\": len(training_history['loss']), # Actual epochs run\n",
    "    \"BATCH_SIZE\": BATCH_SIZE,\n",
    "    \"RANDOM_STATE\": RANDOM_STATE,\n",
    "    \"MIN_SAMPLES_THRESHOLD\": MIN_SAMPLES_THRESHOLD,\n",
    "    \"DATA_USED\": \"BorderlineSMOTE_balanced\"\n",
    "}\n",
    "\n",
    "# Collect metrics for logging\n",
    "# Ensure these are calculated correctly based on your evaluation\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "accuracy = accuracy_score(y_true_np, y_pred_np)\n",
    "test_f1_weighted = f1_score(y_true_np, y_pred_np, average='weighted')\n",
    "\n",
    "# Handle ROC-AUC for multi-class\n",
    "try:\n",
    "    test_roc_auc_ovr = roc_auc_score(y_true_np, y_prob_np, multi_class='ovr', average='weighted')\n",
    "except ValueError as e:\n",
    "    print(f\"Could not calculate ROC AUC: {e}\")\n",
    "    test_roc_auc_ovr = None # Or some placeholder like 0.0 or np.nan\n",
    "\n",
    "experiment_metrics = {\n",
    "    \"test_accuracy\": accuracy,\n",
    "    \"test_f1_weighted\": test_f1_weighted,\n",
    "    \"test_roc_auc_ovr\": test_roc_auc_ovr,\n",
    "    \"final_train_loss\": training_history['loss'][-1] if training_history['loss'] else None,\n",
    "    \"final_val_loss\": training_history['val_loss'][-1] if training_history['val_loss'] else None,\n",
    "    \"final_train_acc\": training_history['acc'][-1] if training_history['acc'] else None,\n",
    "    \"final_val_acc\": training_history['val_acc'][-1] if training_history['val_acc'] else None\n",
    "}\n",
    "\n",
    "log_experiment(experiment_params, experiment_metrics)\n",
    "\n",
    "print(\"\\nModel evaluation and logging complete.\")\n",
    "\n",
    "# Save scaler and encoder (already done after scaling, but good to ensure it's here if flow changes)\n",
    "# save_scaler_and_encoder(scaler, label_encoder_global, SCALER_SAVE_PATH, ENCODER_SAVE_PATH)\n",
    "# print(f\"Scaler and LabelEncoder saved to {SCALER_SAVE_PATH} and {ENCODER_SAVE_PATH} respectively.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f908ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === SIMPLE DASHBOARD: Quick Experiment Summary ===\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def dashboard(history, metrics):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    ax[0].plot(history['loss'], label='Loss')\n",
    "    ax[0].set_title('Training Loss')\n",
    "    ax[0].set_xlabel('Epoch')\n",
    "    ax[0].set_ylabel('Loss')\n",
    "    ax[0].legend()\n",
    "    ax[1].plot(history['acc'], label='Accuracy')\n",
    "    ax[1].set_title('Training Accuracy')\n",
    "    ax[1].set_xlabel('Epoch')\n",
    "    ax[1].set_ylabel('Accuracy')\n",
    "    ax[1].legend()\n",
    "    plt.suptitle('Experiment Dashboard')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print('Final Metrics:', metrics)\n",
    "\n",
    "# Example usage:\n",
    "# dashboard(history, {'F1': 0.88, 'ROC-AUC': 0.91})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydebian (3.11.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
