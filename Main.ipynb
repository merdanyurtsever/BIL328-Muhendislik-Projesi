{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bfa6a60",
   "metadata": {},
   "source": [
    "# Müzik Türü Sınıflandırma Projesi\n",
    "\n",
    "Bu notebook, FMA (Free Music Archive) veri setini kullanarak müzik türü sınıflandırma modeli geliştirmek için veri hazırlama ve dengeleme işlemlerini içermektedir.\n",
    "\n",
    "## Gerekli Kütüphanelerin İçe Aktarılması\n",
    "Aşağıdaki hücrede, projede kullanılacak temel Python kütüphaneleri import edilmektedir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2a41ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from imblearn.over_sampling import RandomOverSampler, BorderlineSMOTE\n",
    "from collections import Counter\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(style='whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4206449",
   "metadata": {},
   "source": [
    "## Yardımcı Fonksiyonlar\n",
    "\n",
    "### Sınıf Dağılımı Görselleştirme Fonksiyonu\n",
    "Aşağıdaki fonksiyon, veri setindeki sınıf dağılımlarını görselleştirmek için kullanılacaktır. Bu görselleştirme, veri dengesizliğini anlamamıza yardımcı olur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ae2a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_class_distribution(y, labels, title):\n",
    "    counts = pd.Series(y).value_counts().sort_index()\n",
    "    valid_indices = counts.index[counts.index < len(labels)]\n",
    "    counts = counts.loc[valid_indices]\n",
    "    names = labels[counts.index]\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    ax = sns.barplot(x=names, y=counts.values, hue=names, palette='viridis', legend=False)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Sınıf')\n",
    "    ax.set_ylabel('Sayı')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471baca3",
   "metadata": {},
   "source": [
    "## Veri Yükleme ve Ön İşleme\n",
    "\n",
    "Bu bölümdeki fonksiyon:\n",
    "- FMA metadata dosyalarını yükler\n",
    "- Gerekli sütunları seçer\n",
    "- Eksik verileri temizler\n",
    "- Etiketleri kodlar\n",
    "- Veriyi sayısal formata dönüştürür"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e25b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    tracks_path = 'fma_metadata/tracks.csv'\n",
    "    features_path = 'fma_metadata/features.csv'\n",
    "\n",
    "    if not os.path.exists(tracks_path) or not os.path.exists(features_path):\n",
    "        raise FileNotFoundError(f\"Gerekli veri dosyaları bulunamadı. '{tracks_path}' ve '{features_path}' dosyalarının mevcut olduğundan emin olun.\")\n",
    "\n",
    "    tracks = pd.read_csv(tracks_path, index_col=0, header=[0,1])\n",
    "    \n",
    "    features = pd.read_csv(features_path, index_col=0, header=[0,1])  # Çok seviyeli başlıkla oku\n",
    "    features = features.loc[:, features.columns.get_level_values(0) != 'statistics']  # 'statistics' sütunlarını kaldır\n",
    "    features = features.astype(np.float32)  # Sayısal olmayan sütunları kaldırdıktan sonra float'a dönüştür\n",
    "\n",
    "    features.index = features.index.astype(str)\n",
    "    tracks.index = tracks.index.astype(str)\n",
    "\n",
    "    genre_series = tracks[('track', 'genre_top')].dropna()\n",
    "    common_index = features.index.intersection(genre_series.index)\n",
    "\n",
    "    X = features.loc[common_index]\n",
    "    y_labels = genre_series.loc[common_index]\n",
    "\n",
    "    X = X.fillna(0).replace([np.inf, -np.inf], 0).astype(np.float32)\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    y = label_encoder.fit_transform(y_labels)\n",
    "\n",
    "    print('Veriler yüklendi ve önişlendi.')\n",
    "    return X, y, label_encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c705ac60",
   "metadata": {},
   "source": [
    "## Başlangıç Veri Analizi\n",
    "\n",
    "Verinin ilk yüklemesini yapıp, başlangıçtaki sınıf dağılımını inceleyelim. Bu analiz, veri dengesizliği problemini görselleştirmemize yardımcı olacak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97f61d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veriyi yükle ve önişle\n",
    "X, y, le = load_data()\n",
    "\n",
    "# Başlangıç dağılımını göster\n",
    "plot_class_distribution(y, le.classes_, 'Başlangıç Sınıf Dağılımı')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b6b7b9",
   "metadata": {},
   "source": [
    "## Veri Bölme ve Eğitim Seti Analizi\n",
    "\n",
    "Veriyi eğitim ve test setlerine ayırıp, eğitim setindeki sınıf dağılımını inceliyoruz. Stratified split kullanarak orijinal dağılımı koruyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ef4617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veriyi böl ve eğitim dağılımını göster\n",
    "# İlk bölme: Ana eğitim ve test setleri\n",
    "X_train_orig, X_test, y_train_orig, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# İkinci bölme: Ana eğitim setini resampling ve temiz doğrulama setlerine ayır\n",
    "X_train_for_resample, X_val_clean, y_train_for_resample, y_val_clean = train_test_split(\n",
    "    X_train_orig, y_train_orig, test_size=0.15, stratify=y_train_orig, random_state=42\n",
    ")\n",
    "\n",
    "print(f'İlk bölünme tamamlandı: X_train_orig {X_train_orig.shape}, X_test {X_test.shape}')\n",
    "print(f'İkinci bölünme tamamlandı: X_train_for_resample {X_train_for_resample.shape}, X_val_clean {X_val_clean.shape}')\n",
    "\n",
    "plot_class_distribution(y_train_for_resample, le.classes_, 'Resampling İçin Eğitim Seti Dağılımı')\n",
    "\n",
    "# Detaylı dağılımı yazdır\n",
    "unique, counts = np.unique(y_train_for_resample, return_counts=True)\n",
    "print(\"\\nResampling İçin Eğitim Seti Dağılımı (ham sayılar):\")\n",
    "for i, (u, c) in enumerate(zip(unique, counts)):\n",
    "    print(f\"Sınıf {u} ({le.classes_[i]}): {c} örnek\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48a9420",
   "metadata": {},
   "source": [
    "## Veri Dengeleme - Aşama 1\n",
    "\n",
    "İlk aşamada, çok az örneğe sahip sınıflar için RandomOverSampler kullanılıyor. Bu aşama, BorderlineSMOTE için yeterli örnek sayısına ulaşmamızı sağlar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d82e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Oversampling Strategy - MORE AGGRESSIVE FOR BETTER BALANCE\n",
    "print('\\nEnhanced oversampling strategy for better class balance...')\n",
    "\n",
    "# Get current distribution\n",
    "unique, counts = np.unique(y_train_for_resample, return_counts=True)\n",
    "print(f\"Original distribution - Max: {max(counts)}, Min: {min(counts)}, Classes: {len(unique)}\")\n",
    "\n",
    "# More aggressive strategy: bring all classes to at least 25% of the max class\n",
    "max_samples = max(counts)\n",
    "target_min = max(15, int(max_samples * 0.25))  # At least 15 samples or 25% of max class\n",
    "\n",
    "print(f\"Target minimum samples per class: {target_min}\")\n",
    "\n",
    "# Create sampling strategy\n",
    "sampling_strategy = {}\n",
    "total_added = 0\n",
    "\n",
    "for class_idx, count in zip(unique, counts):\n",
    "    if count < target_min:\n",
    "        sampling_strategy[class_idx] = target_min\n",
    "        total_added += (target_min - count)\n",
    "        print(f\"  Boosting {le.classes_[class_idx]}: {count} → {target_min} (+{target_min - count})\")\n",
    "\n",
    "if sampling_strategy:\n",
    "    print(f\"\\nApplying oversampling to {len(sampling_strategy)} classes...\")\n",
    "    print(f\"Total samples to be added: {total_added}\")\n",
    "    \n",
    "    ros = RandomOverSampler(sampling_strategy=sampling_strategy, random_state=42)\n",
    "    X_res, y_res = ros.fit_resample(X_train_for_resample, y_train_for_resample)\n",
    "    \n",
    "    print(f\"✅ Enhanced oversampling completed!\")\n",
    "    print(f\"Dataset size: {len(y_train_for_resample)} → {len(y_res)} (+{len(y_res) - len(y_train_for_resample)})\")\n",
    "else:\n",
    "    print(\"No oversampling needed - all classes already well represented\")\n",
    "    X_res, y_res = X_train_for_resample, y_train_for_resample\n",
    "\n",
    "# Show final distribution\n",
    "unique_final, counts_final = np.unique(y_res, return_counts=True)\n",
    "print(f\"\\nFinal distribution after enhanced oversampling:\")\n",
    "print(f\"Max: {max(counts_final)}, Min: {min(counts_final)}, Ratio: {max(counts_final)/min(counts_final):.2f}\")\n",
    "\n",
    "for i, (u, c) in enumerate(zip(unique_final, counts_final)):\n",
    "    if i < len(le.classes_):\n",
    "        print(f\"  {le.classes_[u]}: {c} samples\")\n",
    "\n",
    "plot_class_distribution(y_res, le.classes_, 'Enhanced Oversampling Results')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b9d611",
   "metadata": {},
   "source": [
    "## Veri Dengeleme - Aşama 2\n",
    "\n",
    "İkinci aşamada, daha sofistike bir yaklaşım olan BorderlineSMOTE kullanılarak kalan sınıflar dengeleniyor. Bu yöntem, sadece rastgele kopyalama yerine sentetik örnekler oluşturur.\n",
    "\n",
    "Not: Bu aşama, veri setinin yapısına bağlı olarak başarısız olabilir. Bu durumda, ilk aşamadaki sonuçlar kullanılacaktır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0e95e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE BorderlineSMOTE - Major overfitting culprit\n",
    "print('\\nSkipping BorderlineSMOTE to prevent overfitting...')\n",
    "print('Using only minimal RandomOverSampler results for better generalization.')\n",
    "\n",
    "# No BorderlineSMOTE - use minimal oversampling results directly\n",
    "print(\"\\nFinal distribution after minimal oversampling:\")\n",
    "unique_final, counts_final = np.unique(y_res, return_counts=True)\n",
    "for i, (u, c) in enumerate(zip(unique_final, counts_final)):\n",
    "    print(f\"Sınıf {u} ({le.classes_[i]}): {c} örnek\")\n",
    "\n",
    "print(\"\\nOversampling pipeline completed. Using conservative approach for better generalization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2090aaf6",
   "metadata": {},
   "source": [
    "## Sınıf Ağırlıklandırma (Class Weighting)\n",
    "\n",
    "Veri dengelemeye ek olarak, model eğitimi sırasında sınıf ağırlıklandırma uygulayacağız. Bu yaklaşım, az temsil edilen sınıflara daha fazla önem vererek modelin bu sınıfları daha iyi öğrenmesini sağlar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f61f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Simplified class weighting - focus on original imbalance\n",
    "print(\"\\nCalculating class weights for loss function...\")\n",
    "\n",
    "# Calculate weights from original unbalanced data\n",
    "class_weights = compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(y_train_for_resample),\n",
    "    y=y_train_for_resample\n",
    ")\n",
    "\n",
    "# Convert to PyTorch tensor\n",
    "class_weights_tensor = torch.FloatTensor(class_weights)\n",
    "\n",
    "print(\"Class weights calculated:\")\n",
    "for i, weight in enumerate(class_weights):\n",
    "    if i < len(le.classes_):\n",
    "        print(f\"{le.classes_[i]}: {weight:.3f}\")\n",
    "\n",
    "print(f\"\\nClass weights tensor shape: {class_weights_tensor.shape}\")\n",
    "print(f\"Max weight: {class_weights_tensor.max():.3f}, Min weight: {class_weights_tensor.min():.3f}\")\n",
    "\n",
    "# Check if weights are too extreme\n",
    "weight_ratio = class_weights_tensor.max() / class_weights_tensor.min()\n",
    "print(f\"Weight ratio (max/min): {weight_ratio:.2f}\")\n",
    "if weight_ratio > 10:\n",
    "    print(\"⚠️  WARNING: Very extreme class weights detected!\")\n",
    "    print(\"This may cause training instability. Consider using no weights or softer weights.\")\n",
    "    \n",
    "    # Option to use no class weights\n",
    "    USE_CLASS_WEIGHTS = False  # Set to False if weights are too extreme\n",
    "    if not USE_CLASS_WEIGHTS:\n",
    "        print(\"Disabling class weights for stability...\")\n",
    "        class_weights_tensor = torch.ones(len(le.classes_))\n",
    "else:\n",
    "    print(\"✅ Class weights look reasonable.\")\n",
    "    USE_CLASS_WEIGHTS = True\n",
    "\n",
    "print(\"These weights will be used in CrossEntropyLoss.\")\n",
    "print(f\"Using class weights: {USE_CLASS_WEIGHTS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8700f560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DETAILED DATA FLOW VERIFICATION\n",
    "print(\"\\n=== DETAILED DATA PREPARATION SUMMARY ===\")\n",
    "print(f\"Original training samples: {len(y_train_for_resample)}\")\n",
    "print(f\"After minimal oversampling: {len(y_res)}\")\n",
    "print(f\"Features: {X_res.shape[1]}\")\n",
    "print(f\"Classes: {len(le.classes_)}\")\n",
    "\n",
    "# Show detailed class distribution comparison\n",
    "print(\"\\n🔍 OVERSAMPLING VERIFICATION:\")\n",
    "print(\"BEFORE oversampling:\")\n",
    "unique_before, counts_before = np.unique(y_train_for_resample, return_counts=True)\n",
    "for i, (u, c) in enumerate(zip(unique_before, counts_before)):\n",
    "    if i < len(le.classes_):\n",
    "        print(f\"  {le.classes_[u]}: {c} samples\")\n",
    "\n",
    "print(\"\\nAFTER oversampling:\")\n",
    "unique_after, counts_after = np.unique(y_res, return_counts=True)\n",
    "for i, (u, c) in enumerate(zip(unique_after, counts_after)):\n",
    "    if i < len(le.classes_):\n",
    "        print(f\"  {le.classes_[u]}: {c} samples\")\n",
    "\n",
    "# Calculate oversampling effect\n",
    "total_before = len(y_train_for_resample)\n",
    "total_after = len(y_res)\n",
    "oversampling_factor = total_after / total_before\n",
    "print(f\"\\nOversampling effect: {total_before} → {total_after} samples\")\n",
    "print(f\"Oversampling factor: {oversampling_factor:.2f}x\")\n",
    "\n",
    "if oversampling_factor <= 1.05:\n",
    "    print(\"⚠️  WARNING: Very little or no oversampling applied!\")\n",
    "    print(\"This might explain why accuracy hasn't improved significantly.\")\n",
    "else:\n",
    "    print(\"✅ Oversampling successfully applied!\")\n",
    "\n",
    "print(\"\\nProceeding to feature selection and model training...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65e0072",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e4cdda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "291b507b",
   "metadata": {},
   "source": [
    "## Özellik Seçimi (K-Best Feature Selection)\n",
    "\n",
    "Model performansını artırmak ve aşırı öğrenmeyi (overfitting) azaltmak için K-Best özellik seçimi algoritmasını uygulayacağız. Bu algoritma, her özelliğin hedef değişkenle olan istatistiksel ilişkisini ölçer ve en anlamlı K özelliği seçer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c6196b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Best özellik seçimi uygulaması - OPTIMIZED FOR BETTER PERFORMANCE\n",
    "print('\\nK-Best özellik seçimi uygulanıyor...')\n",
    "\n",
    "k = 150  # INCREASED from 100 - more features for better performance\n",
    "print(f\"Toplam özellik sayısı: {X_res.shape[1]}, Seçilecek özellik sayısı: {k}\")\n",
    "\n",
    "# SelectKBest ile özellik seçimi - Sadece resampled data üzerinde fit et\n",
    "selector = SelectKBest(score_func=f_classif, k=k)\n",
    "X_res_selected = selector.fit_transform(X_res, y_res)\n",
    "\n",
    "# Fitted selector ile validation ve test setlerini transform et\n",
    "X_val_clean_selected = selector.transform(X_val_clean)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "print(f\"Özellik seçimi tamamlandı. Seçilen özelliklerin boyutu: {X_res_selected.shape}\")\n",
    "print(f\"Validation set boyutu: {X_val_clean_selected.shape}\")\n",
    "print(f\"Test set boyutu: {X_test_selected.shape}\")\n",
    "\n",
    "# Orijinal veriyi güncellenmiş veri ile değiştirelim\n",
    "X_res = X_res_selected\n",
    "X_val_clean = X_val_clean_selected\n",
    "X_test = X_test_selected\n",
    "\n",
    "# Veri Ölçeklendirme (RobustScaler) - Better for outliers\n",
    "print('\\nVeri ölçeklendirme uygulanıyor (RobustScaler)...')\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler = RobustScaler()  # More robust to outliers than StandardScaler\n",
    "X_res_scaled = scaler.fit_transform(X_res)\n",
    "X_val_clean_scaled = scaler.transform(X_val_clean)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Veri ölçeklendirme tamamlandı.\")\n",
    "print(f\"Ölçeklenmiş resampled eğitim verisi boyutu: {X_res_scaled.shape}\")\n",
    "print(f\"Ölçeklenmiş validation verisi boyutu: {X_val_clean_scaled.shape}\")\n",
    "print(f\"Ölçeklenmiş test verisi boyutu: {X_test_scaled.shape}\")\n",
    "\n",
    "# Veriyi güncellenmiş ölçeklenmiş veriler ile değiştir\n",
    "X_res = X_res_scaled\n",
    "X_val_clean = X_val_clean_scaled\n",
    "X_test = X_test_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69962f4f",
   "metadata": {},
   "source": [
    "*-----------------------------------------------------------------------------------*\n",
    "# PyTorch LSTM MODEL EĞİTİMİ\n",
    "*-----------------------------------------------------------------------------------*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340b3123",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPyTorch LSTM Model Eğitimi Başlıyor...\")\n",
    "\n",
    "# Veri yükleme, önişleme, bölme ve dengeleme adımlarının tamamlandığı varsayılır.\n",
    "# Bu noktada aşağıdaki değişkenlerin mevcut olması beklenir:\n",
    "# X_res, y_res (Dengelenmiş eğitim verisi)\n",
    "# X_val, y_val (Doğrulama verisi)\n",
    "# X_test, y_test (Test verisi)\n",
    "# le (LabelEncoder nesnesi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9a8a07",
   "metadata": {},
   "source": [
    "## Gelişmiş Özellik Mühendisliği ve Model Optimizasyonu (İsteğe Bağlı)\n",
    "\n",
    "Bu bölümde, model performansını artırmak için gelişmiş özellik mühendisliği tekniklerini ve model optimizasyonlarını güvenli bir şekilde uygulayabiliriz. Bu teknikler veri sızıntısını önlemek için dikkatli bir şekilde tasarlanmıştır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2a356a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced feature engineering - DISABLED to prevent overfitting\n",
    "print(\"Enhanced feature engineering is DISABLED to prevent overfitting.\")\n",
    "print(\"Using only basic features with minimal oversampling approach.\")\n",
    "\n",
    "print(f\"\\nFinal data dimensions:\")\n",
    "print(f\"Training (X_res): {X_res.shape}\")\n",
    "print(f\"Validation (X_val_clean): {X_val_clean.shape}\")\n",
    "print(f\"Test (X_test): {X_test.shape}\")\n",
    "\n",
    "print(\"\\nSimple and conservative approach for better generalization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f746e0b",
   "metadata": {},
   "source": [
    "## LSTM Modeli için Veri Hazırlığı\n",
    "\n",
    "PyTorch LSTM modeli için, veriyi uygun formata dönüştürmemiz gerekir. LSTM modeller sıralı veri bekler, bu nedenle öznitelik vektörünü zamansal bir diziye dönüştüreceğiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa7d165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch tensörlerine dönüştürme ve veri setlerini hazırlama\n",
    "def create_sequence_data(X, y, sequence_length=10):\n",
    "    \"\"\"\n",
    "    Öznitelik vektörünü sıralı verilere dönüştürür.\n",
    "    FMA veri seti sıralı yapıda değil, bu nedenle yapay bir sıra oluşturuyoruz.\n",
    "    \"\"\"\n",
    "    print(f\"Creating sequences from {X.shape[0]} samples with {X.shape[1]} features...\")\n",
    "    \n",
    "    # Veri boyutlarını kontrol et\n",
    "    n_samples, n_features = X.shape\n",
    "    \n",
    "    # Veriyi yeniden şekillendirme\n",
    "    features_per_timestep = n_features // sequence_length\n",
    "    \n",
    "    if features_per_timestep == 0:\n",
    "        features_per_timestep = 1\n",
    "        sequence_length = min(sequence_length, n_features)\n",
    "    \n",
    "    print(f\"Sequence config: {sequence_length} timesteps, {features_per_timestep} features per timestep\")\n",
    "    \n",
    "    # Son timestep'e sığmayan özellikleri ele alma\n",
    "    remainder = n_features - (sequence_length * features_per_timestep)\n",
    "    if remainder > 0:\n",
    "        print(f\"Note: {remainder} features will be unused due to sequence reshaping\")\n",
    "    \n",
    "    # Yeniden şekillendirilmiş veri için array oluşturma\n",
    "    X_seq = np.zeros((n_samples, sequence_length, features_per_timestep))\n",
    "    \n",
    "    # Veriyi yeniden şekillendirme\n",
    "    for i in range(n_samples):\n",
    "        for t in range(sequence_length):\n",
    "            start_idx = t * features_per_timestep\n",
    "            end_idx = min(start_idx + features_per_timestep, n_features)\n",
    "            \n",
    "            if start_idx < n_features:\n",
    "                X_seq[i, t, :end_idx-start_idx] = X[i, start_idx:end_idx]\n",
    "    \n",
    "    # PyTorch tensörlerine dönüştürme\n",
    "    X_tensor = torch.FloatTensor(X_seq)\n",
    "    y_tensor = torch.LongTensor(y)\n",
    "    \n",
    "    print(f\"✅ Sequence creation completed: {X_tensor.shape} -> {y_tensor.shape}\")\n",
    "    return X_tensor, y_tensor\n",
    "\n",
    "# Optimized sequence parameters\n",
    "sequence_length = 10  # INCREASED from 5 for better temporal modeling\n",
    "\n",
    "print(\"\\n=== CREATING SEQUENCE DATA ===\")\n",
    "print(\"Converting scaled data to sequence format...\")\n",
    "\n",
    "# Ölçeklenmiş verileri sıralı forma dönüştürme\n",
    "X_train_seq, y_train_tensor = create_sequence_data(X_res, y_res, sequence_length)\n",
    "X_val_seq, y_val_tensor = create_sequence_data(X_val_clean, y_val_clean, sequence_length)\n",
    "X_test_seq, y_test_tensor = create_sequence_data(X_test, y_test, sequence_length)\n",
    "\n",
    "print(f\"\\nFinal data shapes:\")\n",
    "print(f\"  Training: {X_train_seq.shape} samples\")\n",
    "print(f\"  Validation: {X_val_seq.shape} samples\")\n",
    "print(f\"  Test: {X_test_seq.shape} samples\")\n",
    "\n",
    "# Optimized DataLoader settings\n",
    "batch_size = 256  # REDUCED from 512 for better gradient updates\n",
    "train_dataset = TensorDataset(X_train_seq, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_seq, y_val_tensor)\n",
    "test_dataset = TensorDataset(X_test_seq, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "print(f\"\\nDataLoaders created:\")\n",
    "print(f\"  Training batches: {len(train_loader)} (batch_size={batch_size})\")\n",
    "print(f\"  Validation batches: {len(val_loader)}\")\n",
    "print(f\"  Test batches: {len(test_loader)}\")\n",
    "print(f\"  Total training samples: {len(train_loader.dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719d6bcd",
   "metadata": {},
   "source": [
    "## LSTM Model Tanımı ve Eğitimi\n",
    "\n",
    "Aşağıda müzik türü sınıflandırması için bir LSTM (Long Short-Term Memory) ağı tanımlıyoruz. LSTM'ler, müzik gibi sıralı verilerde başarılı olan bir derin öğrenme mimarisidir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6ce84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced LSTM model - FOCUSED IMPROVEMENTS FOR BETTER ACCURACY\n",
    "class MusicGenreLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, dropout=0.3):\n",
    "        super(MusicGenreLSTM, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # Bidirectional LSTM for better feature capture\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size, \n",
    "            hidden_size=hidden_size, \n",
    "            num_layers=num_layers, \n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0,\n",
    "            bidirectional=True  # Key improvement: bidirectional\n",
    "        )\n",
    "        \n",
    "        # Batch normalization for training stability\n",
    "        self.batch_norm = nn.BatchNorm1d(hidden_size * 2)  # *2 for bidirectional\n",
    "        \n",
    "        # Dropout for regularization\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Two-layer classifier for better decision boundary\n",
    "        self.fc1 = nn.Linear(hidden_size * 2, hidden_size)  # *2 for bidirectional\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # LSTM forward pass\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        \n",
    "        # Use last time step output (both directions)\n",
    "        lstm_out = lstm_out[:, -1, :]\n",
    "        \n",
    "        # Batch normalization\n",
    "        lstm_out = self.batch_norm(lstm_out)\n",
    "        \n",
    "        # First FC layer with activation and dropout\n",
    "        out = self.fc1(lstm_out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        # Final classification layer\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "# Improved model parameters - balanced for better performance\n",
    "input_size = X_train_seq.shape[2]\n",
    "hidden_size = 64  # Keep balanced\n",
    "num_layers = 2  # Increased for more capacity\n",
    "num_classes = len(le.classes_)\n",
    "dropout = 0.3  # Optimal dropout\n",
    "\n",
    "# GPU kontrolü\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Kullanılan cihaz: {device}\")\n",
    "\n",
    "# Enhanced model creation\n",
    "model = MusicGenreLSTM(input_size, hidden_size, num_layers, num_classes, dropout).to(device)\n",
    "print(model)\n",
    "\n",
    "# Model parameter count\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable parameters: {total_params:,}\")\n",
    "\n",
    "# Enhanced loss function and optimizer\n",
    "print(f\"Class weights being used: {class_weights_tensor}\")\n",
    "class_weights_device = class_weights_tensor.to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights_device, label_smoothing=0.1)  # Label smoothing\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)  # AdamW for better generalization\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=5, eta_min=1e-6)  # Better LR schedule\n",
    "\n",
    "# Enhanced Training function - FOCUSED IMPROVEMENTS\n",
    "def train_model_enhanced(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "    \n",
    "    best_val_acc = 0.0  # Track best validation accuracy instead of loss\n",
    "    best_model = None\n",
    "    patience_counter = 0\n",
    "    PATIENCE = 7  # Increased patience for better convergence\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping for stability\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Calculate metrics\n",
    "        epoch_train_loss = train_loss / len(train_loader.dataset)\n",
    "        epoch_val_loss = val_loss / len(val_loader.dataset)\n",
    "        epoch_train_acc = train_correct / train_total\n",
    "        epoch_val_acc = val_correct / val_total\n",
    "        \n",
    "        # Learning rate scheduling\n",
    "        scheduler.step()\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        # Store metrics\n",
    "        train_losses.append(epoch_train_loss)\n",
    "        val_losses.append(epoch_val_loss)\n",
    "        train_accs.append(epoch_train_acc)\n",
    "        val_accs.append(epoch_val_acc)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs} - '\n",
    "              f'Train Loss: {epoch_train_loss:.4f}, Train Acc: {epoch_train_acc:.4f}, '\n",
    "              f'Val Loss: {epoch_val_loss:.4f}, Val Acc: {epoch_val_acc:.4f}, LR: {current_lr:.6f}')\n",
    "        \n",
    "        # Save best model based on validation accuracy\n",
    "        if epoch_val_acc > best_val_acc:\n",
    "            best_val_acc = epoch_val_acc\n",
    "            best_model = model.state_dict().copy()\n",
    "            patience_counter = 0\n",
    "            print(f'*** New best validation accuracy: {best_val_acc:.4f} ***')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            \n",
    "        if patience_counter >= PATIENCE:\n",
    "            print(f'Early stopping at epoch {epoch+1}')\n",
    "            break\n",
    "    \n",
    "    # Load best model\n",
    "    model.load_state_dict(best_model)\n",
    "    print(f'Best validation accuracy achieved: {best_val_acc:.4f}')\n",
    "    return model, train_losses, val_losses, train_accs, val_accs\n",
    "\n",
    "# Train with enhanced settings\n",
    "print(\"Training with enhanced settings for better accuracy...\")\n",
    "model, train_losses, val_losses, train_accs, val_accs = train_model_enhanced(\n",
    "    model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=25\n",
    ")\n",
    "print(\"Enhanced training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d73d18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIAGNOSTIC ANALYSIS - Check for potential issues\n",
    "print(\"=== DIAGNOSTIC ANALYSIS ===\")\n",
    "\n",
    "# 1. Check data shapes and ranges\n",
    "print(f\"Training data shape: {X_train_seq.shape}\")\n",
    "print(f\"Training labels shape: {y_train_tensor.shape}\")\n",
    "print(f\"Unique classes in training: {torch.unique(y_train_tensor)}\")\n",
    "print(f\"Data range - Min: {X_train_seq.min():.4f}, Max: {X_train_seq.max():.4f}\")\n",
    "print(f\"Data mean: {X_train_seq.mean():.4f}, std: {X_train_seq.std():.4f}\")\n",
    "\n",
    "# 2. Check class distribution\n",
    "class_counts = torch.bincount(y_train_tensor)\n",
    "print(f\"\\nClass distribution in training:\")\n",
    "for i, count in enumerate(class_counts):\n",
    "    if i < len(le.classes_):\n",
    "        print(f\"  {le.classes_[i]}: {count} samples\")\n",
    "\n",
    "# 3. Check for data leakage or issues\n",
    "print(f\"\\nValidation data shape: {X_val_seq.shape}\")\n",
    "print(f\"Test data shape: {X_test_seq.shape}\")\n",
    "print(f\"Val data range - Min: {X_val_seq.min():.4f}, Max: {X_val_seq.max():.4f}\")\n",
    "\n",
    "# 4. Check model complexity\n",
    "model_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "data_samples = len(y_train_tensor)\n",
    "params_per_sample = model_params / data_samples\n",
    "print(f\"\\nModel complexity analysis:\")\n",
    "print(f\"  Total parameters: {model_params:,}\")\n",
    "print(f\"  Training samples: {data_samples:,}\")\n",
    "print(f\"  Parameters per sample: {params_per_sample:.2f}\")\n",
    "if params_per_sample > 10:\n",
    "    print(\"  ⚠️  WARNING: High parameter-to-sample ratio may cause overfitting\")\n",
    "elif params_per_sample < 0.1:\n",
    "    print(\"  ⚠️  WARNING: Very low parameter-to-sample ratio may cause underfitting\")\n",
    "else:\n",
    "    print(\"  ✅ Parameter-to-sample ratio looks reasonable\")\n",
    "\n",
    "# 5. Quick baseline test\n",
    "print(f\"\\nBaseline accuracy (most frequent class): {class_counts.max().item() / data_samples:.4f}\")\n",
    "print(\"If model performs worse than this, there's a serious issue.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6d764e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIMPLE BASELINE COMPARISON\n",
    "print(\"=== BASELINE MODEL COMPARISON ===\")\n",
    "\n",
    "# Let's try a simple feedforward network first to establish baseline\n",
    "class SimpleFFN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes, dropout=0.3):\n",
    "        super(SimpleFFN, self).__init__()\n",
    "        # Flatten the sequence dimension\n",
    "        self.flatten_size = input_size * 5  # sequence_length = 5\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(self.flatten_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_size, hidden_size // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_size // 2, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Flatten sequence data\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.layers(x)\n",
    "\n",
    "# Create baseline model\n",
    "baseline_model = SimpleFFN(input_size, 64, num_classes, 0.3).to(device)\n",
    "baseline_params = sum(p.numel() for p in baseline_model.parameters() if p.requires_grad)\n",
    "print(f\"Baseline FFN parameters: {baseline_params:,}\")\n",
    "print(f\"LSTM parameters: {model_params:,}\")\n",
    "\n",
    "# Quick test to see if data flows correctly\n",
    "with torch.no_grad():\n",
    "    sample_batch = next(iter(train_loader))\n",
    "    sample_input, sample_labels = sample_batch[0][:5].to(device), sample_batch[1][:5].to(device)\n",
    "    \n",
    "    # Test LSTM\n",
    "    lstm_output = model(sample_input)\n",
    "    print(f\"\\nLSTM output shape: {lstm_output.shape}\")\n",
    "    print(f\"LSTM output range: {lstm_output.min():.4f} to {lstm_output.max():.4f}\")\n",
    "    \n",
    "    # Test FFN\n",
    "    ffn_output = baseline_model(sample_input)\n",
    "    print(f\"FFN output shape: {ffn_output.shape}\")\n",
    "    print(f\"FFN output range: {ffn_output.min():.4f} to {ffn_output.max():.4f}\")\n",
    "    \n",
    "    print(f\"Sample labels: {sample_labels}\")\n",
    "    print(f\"Expected output classes: {num_classes}\")\n",
    "\n",
    "print(\"\\nModels initialized successfully. Proceeding with training...\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41781a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENSEMBLE APPROACH FOR BETTER ACCURACY\n",
    "print(\"=== ENSEMBLE TRAINING ===\")\n",
    "\n",
    "# Train multiple models with different initialization\n",
    "class EnsembleModel:\n",
    "    def __init__(self, num_models=3):\n",
    "        self.models = []\n",
    "        self.num_models = num_models\n",
    "        \n",
    "        for i in range(num_models):\n",
    "            model = MusicGenreLSTM(input_size, hidden_size, num_layers, num_classes, dropout).to(device)\n",
    "            self.models.append(model)\n",
    "            print(f\"Model {i+1} initialized\")\n",
    "    \n",
    "    def train_ensemble(self, train_loader, val_loader, criterion, num_epochs=20):\n",
    "        \"\"\"Train all models in ensemble\"\"\"\n",
    "        trained_models = []\n",
    "        \n",
    "        for i, model in enumerate(self.models):\n",
    "            print(f\"\\nTraining Model {i+1}/{self.num_models}...\")\n",
    "            \n",
    "            # Create separate optimizer for each model\n",
    "            optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "            scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=5)\n",
    "            \n",
    "            # Train model\n",
    "            trained_model, _, _, _, _ = train_model_enhanced(\n",
    "                model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs\n",
    "            )\n",
    "            trained_models.append(trained_model)\n",
    "        \n",
    "        self.models = trained_models\n",
    "        return self.models\n",
    "    \n",
    "    def predict(self, data_loader):\n",
    "        \"\"\"Make ensemble predictions\"\"\"\n",
    "        all_predictions = []\n",
    "        \n",
    "        # Get predictions from each model\n",
    "        for model in self.models:\n",
    "            model.eval()\n",
    "            predictions = []\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for inputs, _ in data_loader:\n",
    "                    inputs = inputs.to(device)\n",
    "                    outputs = model(inputs)\n",
    "                    probabilities = torch.softmax(outputs, dim=1)\n",
    "                    predictions.append(probabilities.cpu())\n",
    "            \n",
    "            all_predictions.append(torch.cat(predictions, dim=0))\n",
    "        \n",
    "        # Average predictions\n",
    "        ensemble_predictions = torch.stack(all_predictions).mean(dim=0)\n",
    "        return ensemble_predictions\n",
    "\n",
    "# Create and train ensemble (using 3 models for balance of performance and time)\n",
    "ensemble = EnsembleModel(num_models=3)\n",
    "print(f\"Training ensemble of {ensemble.num_models} models...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c3a4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA AUGMENTATION FOR BETTER GENERALIZATION\n",
    "print(\"\\n=== DATA AUGMENTATION ===\")\n",
    "\n",
    "def augment_data(X, y, augment_factor=0.2):\n",
    "    \"\"\"Simple data augmentation with noise injection\"\"\"\n",
    "    n_samples = X.shape[0]\n",
    "    n_augmented = int(n_samples * augment_factor)\n",
    "    \n",
    "    # Random indices for augmentation\n",
    "    aug_indices = np.random.choice(n_samples, n_augmented, replace=True)\n",
    "    \n",
    "    # Create augmented samples\n",
    "    X_aug = X[aug_indices].copy()\n",
    "    y_aug = y[aug_indices].copy()\n",
    "    \n",
    "    # Add small gaussian noise\n",
    "    noise_std = 0.01 * X_aug.std()\n",
    "    noise = np.random.normal(0, noise_std, X_aug.shape)\n",
    "    X_aug = X_aug + noise\n",
    "    \n",
    "    # Combine original and augmented data\n",
    "    X_combined = np.vstack([X, X_aug])\n",
    "    y_combined = np.hstack([y, y_aug])\n",
    "    \n",
    "    return X_combined, y_combined\n",
    "\n",
    "# Apply data augmentation to training data\n",
    "print(\"Applying data augmentation...\")\n",
    "X_res_aug, y_res_aug = augment_data(X_res, y_res, augment_factor=0.15)\n",
    "\n",
    "print(f\"Original training size: {X_res.shape[0]}\")\n",
    "print(f\"Augmented training size: {X_res_aug.shape[0]}\")\n",
    "print(f\"Augmentation factor: {(X_res_aug.shape[0] - X_res.shape[0]) / X_res.shape[0]:.2f}\")\n",
    "\n",
    "# CRITICAL: Verify class distribution is maintained after augmentation\n",
    "print(\"\\n🔍 VERIFYING AUGMENTATION EFFECT:\")\n",
    "print(\"Before augmentation:\")\n",
    "unique_before_aug, counts_before_aug = np.unique(y_res, return_counts=True)\n",
    "for i, (u, c) in enumerate(zip(unique_before_aug, counts_before_aug)):\n",
    "    if i < len(le.classes_):\n",
    "        print(f\"  {le.classes_[u]}: {c} samples\")\n",
    "\n",
    "print(\"\\nAfter augmentation:\")\n",
    "unique_after_aug, counts_after_aug = np.unique(y_res_aug, return_counts=True)\n",
    "for i, (u, c) in enumerate(zip(unique_after_aug, counts_after_aug)):\n",
    "    if i < len(le.classes_):\n",
    "        print(f\"  {le.classes_[u]}: {c} samples\")\n",
    "\n",
    "# Update training data\n",
    "X_res = X_res_aug\n",
    "y_res = y_res_aug\n",
    "\n",
    "# Recreate sequence data with augmented dataset\n",
    "X_train_seq, y_train_tensor = create_sequence_data(X_res, y_res, sequence_length)\n",
    "print(f\"\\nNew training sequence shape: {X_train_seq.shape}\")\n",
    "print(f\"Final training labels: {len(y_train_tensor)} samples\")\n",
    "\n",
    "# Update train loader\n",
    "train_dataset = TensorDataset(X_train_seq, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "\n",
    "print(\"✅ Data augmentation completed successfully!\")\n",
    "print(f\"Final DataLoader has {len(train_loader)} batches with batch_size={batch_size}\")\n",
    "print(f\"Total training samples in DataLoader: {len(train_loader.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccc11c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRITICAL: VERIFY DATA PIPELINE INTEGRITY\n",
    "print(\"\\n=== DATA PIPELINE VERIFICATION ===\")\n",
    "print(\"Checking if our oversampling and augmentation actually made it to the training loop...\")\n",
    "\n",
    "# Check actual class distribution in the final training tensor\n",
    "final_class_counts = torch.bincount(y_train_tensor)\n",
    "print(\"\\n📊 FINAL TRAINING DATA DISTRIBUTION:\")\n",
    "for i, count in enumerate(final_class_counts):\n",
    "    if i < len(le.classes_):\n",
    "        print(f\"  {le.classes_[i]}: {count} samples\")\n",
    "\n",
    "# Calculate balance metrics\n",
    "max_count = final_class_counts.max().item()\n",
    "min_count = final_class_counts.min().item()\n",
    "balance_ratio = max_count / min_count if min_count > 0 else float('inf')\n",
    "\n",
    "print(f\"\\nBalance Analysis:\")\n",
    "print(f\"  Most samples: {max_count}\")\n",
    "print(f\"  Least samples: {min_count}\")\n",
    "print(f\"  Imbalance ratio: {balance_ratio:.2f}\")\n",
    "\n",
    "if balance_ratio > 10:\n",
    "    print(\"  ⚠️  WARNING: Still very imbalanced! Oversampling may not have worked.\")\n",
    "elif balance_ratio > 5:\n",
    "    print(\"  📊 Moderate imbalance - this is acceptable\")\n",
    "else:\n",
    "    print(\"  ✅ Good balance achieved!\")\n",
    "\n",
    "# Verify data actually changed from original\n",
    "original_samples = len(y_train_for_resample)\n",
    "final_samples = len(y_train_tensor)\n",
    "data_increase = (final_samples - original_samples) / original_samples * 100\n",
    "\n",
    "print(f\"\\nData Growth Verification:\")\n",
    "print(f\"  Original samples: {original_samples}\")\n",
    "print(f\"  Final samples: {final_samples}\")\n",
    "print(f\"  Increase: {data_increase:.1f}%\")\n",
    "\n",
    "if data_increase < 5:\n",
    "    print(\"  ⚠️  WARNING: Very little data augmentation applied!\")\n",
    "    print(\"  This suggests oversampling/augmentation isn't working properly.\")\n",
    "else:\n",
    "    print(f\"  ✅ Data successfully augmented by {data_increase:.1f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f720d377",
   "metadata": {},
   "source": [
    "## Model Değerlendirmesi ve Görselleştirme\n",
    "\n",
    "Bu bölümde eğitilmiş modeli test veri seti üzerinde değerlendirip, sonuçları görselleştireceğiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5361a1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eğitim sonuçlarını görselleştirme\n",
    "def plot_training_history(train_losses, val_losses, train_accs, val_accs):\n",
    "    plt.figure(figsize=(14, 5))\n",
    "    \n",
    "    # Kayıp grafiği\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Eğitim', marker='o')\n",
    "    plt.plot(val_losses, label='Doğrulama', marker='*')\n",
    "    plt.title('Model Kaybı')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Kayıp (Cross-Entropy)')\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    \n",
    "    # Doğruluk grafiği\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_accs, label='Eğitim', marker='o')\n",
    "    plt.plot(val_accs, label='Doğrulama', marker='*')\n",
    "    plt.title('Model Doğruluğu')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Doğruluk')\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Eğitim sonuçlarını görselleştir\n",
    "try:\n",
    "    plot_training_history(train_losses, val_losses, train_accs, val_accs)\n",
    "except NameError:\n",
    "    print(\"Eğitim geçmişi bulunamadı. Önce modeli eğitin.\")\n",
    "\n",
    "# Test veri seti üzerinde değerlendirme\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    \n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "    \n",
    "    # Doğruluk hesapla\n",
    "    accuracy = np.mean(np.array(y_true) == np.array(y_pred))\n",
    "    \n",
    "    # Sonuçları yazdır\n",
    "    print(f\"Test Doğruluğu: {accuracy:.4f}\")\n",
    "    \n",
    "    # Sınıflandırma raporu\n",
    "    print(\"\\nSınıflandırma Raporu:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=le.classes_, \n",
    "                               zero_division=0, labels=np.unique(y_true)))\n",
    "    \n",
    "    # Class-wise performance analysis\n",
    "    print(\"\\nDetaylı Sınıf Bazında Performans:\")\n",
    "    class_report = classification_report(y_true, y_pred, target_names=le.classes_, \n",
    "                                       output_dict=True, zero_division=0, labels=np.unique(y_true))\n",
    "    for class_name, metrics in class_report.items():\n",
    "        if isinstance(metrics, dict) and 'f1-score' in metrics:\n",
    "            print(f\"{class_name}: Precision={metrics['precision']:.3f}, Recall={metrics['recall']:.3f}, F1={metrics['f1-score']:.3f}, Support={metrics['support']}\")\n",
    "    \n",
    "    # Karmaşıklık matrisi\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "    plt.title('Karmaşıklık Matrisi')\n",
    "    plt.xlabel('Tahmin Edilen Etiketler')\n",
    "    plt.ylabel('Gerçek Etiketler')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return y_true, y_pred\n",
    "\n",
    "# Test veri seti üzerinde değerlendir\n",
    "try:\n",
    "    y_true, y_pred = evaluate_model(model, test_loader, device)\n",
    "except NameError:\n",
    "    print(\"Model bulunamadı. Önce modeli eğitin.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a7e87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score, accuracy_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def get_model_probabilities(model, test_loader, device):\n",
    "    \"\"\"\n",
    "    Get prediction probabilities from the trained model\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_proba = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            probabilities = F.softmax(outputs, dim=1)\n",
    "            \n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_proba.extend(probabilities.cpu().numpy())\n",
    "    \n",
    "    return np.array(y_true), np.array(y_proba)\n",
    "\n",
    "def comprehensive_evaluation(model, test_loader, device, class_names):\n",
    "    \"\"\"\n",
    "    Provide detailed evaluation metrics for the trained model\n",
    "    \"\"\"\n",
    "    # Get true labels and prediction probabilities\n",
    "    y_true, y_proba = get_model_probabilities(model, test_loader, device)\n",
    "    \n",
    "    # Get predictions\n",
    "    y_pred = np.argmax(y_proba, axis=1)\n",
    "    \n",
    "    # Basic metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    # Per-class metrics\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average=None, labels=range(len(class_names))\n",
    "    )\n",
    "    \n",
    "    # Macro and weighted averages\n",
    "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average='macro'\n",
    "    )\n",
    "    precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average='weighted'\n",
    "    )\n",
    "    \n",
    "    # AUC-ROC for multiclass\n",
    "    y_true_binarized = label_binarize(y_true, classes=range(len(class_names)))\n",
    "    auc_scores = []\n",
    "    for i in range(len(class_names)):\n",
    "        if len(np.unique(y_true_binarized[:, i])) > 1:  # Check if class exists\n",
    "            auc = roc_auc_score(y_true_binarized[:, i], y_proba[:, i])\n",
    "            auc_scores.append(auc)\n",
    "    \n",
    "    # Create detailed report\n",
    "    results = {\n",
    "        'accuracy': accuracy,\n",
    "        'macro_precision': precision_macro,\n",
    "        'macro_recall': recall_macro,\n",
    "        'macro_f1': f1_macro,\n",
    "        'weighted_precision': precision_weighted,\n",
    "        'weighted_recall': recall_weighted,\n",
    "        'weighted_f1': f1_weighted,\n",
    "        'mean_auc': np.mean(auc_scores) if auc_scores else 0,\n",
    "        'per_class_metrics': {\n",
    "            class_names[i]: {\n",
    "                'precision': precision[i],\n",
    "                'recall': recall[i],\n",
    "                'f1': f1[i],\n",
    "                'support': support[i]\n",
    "            } for i in range(len(class_names))\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Use the comprehensive evaluation function\n",
    "try:\n",
    "    if 'model' in locals() and 'test_loader' in locals():\n",
    "        print(\"\\nDetaylı model değerlendirmesi...\")\n",
    "        detailed_results = comprehensive_evaluation(model, test_loader, device, le.classes_)\n",
    "        \n",
    "        print(f\"\\nDetaylı Sonuçlar:\")\n",
    "        print(f\"Accuracy: {detailed_results['accuracy']:.4f}\")\n",
    "        print(f\"Macro F1: {detailed_results['macro_f1']:.4f}\")\n",
    "        print(f\"Weighted F1: {detailed_results['weighted_f1']:.4f}\")\n",
    "        print(f\"Mean AUC: {detailed_results['mean_auc']:.4f}\")\n",
    "        \n",
    "        print(\"\\nSınıf bazında detaylar:\")\n",
    "        for class_name, metrics in detailed_results['per_class_metrics'].items():\n",
    "            print(f\"{class_name}: F1={metrics['f1']:.3f}, Precision={metrics['precision']:.3f}, Recall={metrics['recall']:.3f}\")\n",
    "    else:\n",
    "        print(\"Model henüz eğitilmemiş. Önce modeli eğitin.\")\n",
    "except NameError:\n",
    "    print(\"Model bulunamadı. Önce modeli eğitin.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f88f77",
   "metadata": {},
   "source": [
    "## Model Değerlendirmesi ve İleriye Dönük Çalışmalar\n",
    "\n",
    "Müzik türü sınıflandırma modelimiz veriyi dengeledikten sonra eğitilmiştir. Sonuçlar değerlendirilirken şunlar göz önünde bulundurulmalıdır:\n",
    "\n",
    "1. **Veri Kalitesi**: FMA veri setindeki özellikler, ses dosyalarından çıkarılmış özelliklerdir. Daha iyi sonuçlar için ham ses verileri üzerinde spektrogram analizi yapılabilir.\n",
    "\n",
    "2. **Model Mimarisi**: LSTM modeli, sıralı verilerde başarılı olmasına rağmen, müzik türü tanıma için CNN (Convolutional Neural Network) veya CNN-LSTM hibrit modeller de kullanılabilir.\n",
    "\n",
    "3. **Hiperparametreler**: Farklı hiperparametreler (örn. öğrenme oranı, katman sayısı, nöron sayısı) ile model performansı artırılabilir.\n",
    "\n",
    "4. **Veri Dengeleme**: Kullandığımız veri dengeleme yöntemleri, eğitim setindeki sınıf dağılımını eşitlemeye yardımcı olur, ancak sentetik veri oluşturma riskleri de taşır.\n",
    "\n",
    "5. **Özellik Seçimi**: K-Best algoritması ile seçilen özellikler, modelin daha iyi genelleme yapmasına ve aşırı öğrenmesinin azalmasına yardımcı olabilir. Farklı K değerleri denenerek optimum özellik sayısı bulunabilir.\n",
    "\n",
    "İleriye dönük çalışmalarda, daha karmaşık modeller, farklı özellik çıkarma teknikleri ve daha büyük veri setleri kullanılarak performans artırılabilir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d18bee",
   "metadata": {},
   "source": [
    "## Model Optimizasyonu ve Sorun Giderme\n",
    "\n",
    "Bu bölüm, model performansını artırmak için çeşitli optimizasyon teknikleri ve sorun giderme yöntemlerini içerir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c4d430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Performans Analizi ve İyileştirme Önerileri\n",
    "\n",
    "def analyze_model_performance():\n",
    "    \"\"\"\n",
    "    Model performansını analiz et ve iyileştirme önerileri sun\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if 'detailed_results' in locals() or 'detailed_results' in globals():\n",
    "            results = detailed_results\n",
    "            \n",
    "            print(\"\\n=== MODEL PERFORMANS ANALİZİ ===\")\n",
    "            print(f\"Genel Doğruluk: {results['accuracy']:.4f}\")\n",
    "            print(f\"Macro F1 Skoru: {results['macro_f1']:.4f}\")\n",
    "            print(f\"Weighted F1 Skoru: {results['weighted_f1']:.4f}\")\n",
    "            print(f\"Ortalama AUC: {results['mean_auc']:.4f}\")\n",
    "            \n",
    "            # Performans değerlendirmesi ve öneriler\n",
    "            if results['accuracy'] < 0.6:\n",
    "                print(\"\\n⚠️  DÜŞÜK PERFORMANS TESPİT EDİLDİ\")\n",
    "                print(\"Öneriler:\")\n",
    "                print(\"1. Daha fazla veri toplama\")\n",
    "                print(\"2. Farklı model mimarisi deneme (CNN, Transformer)\")\n",
    "                print(\"3. Hiperparametre optimizasyonu\")\n",
    "                print(\"4. Veri ön işleme tekniklerini gözden geçirme\")\n",
    "                \n",
    "            elif results['accuracy'] < 0.75:\n",
    "                print(\"\\n📊 ORTA SEVİYE PERFORMANS\")\n",
    "                print(\"İyileştirme önerileri:\")\n",
    "                print(\"1. Özellik mühendisliği uygulama\")\n",
    "                print(\"2. Model ensemble teknikleri\")\n",
    "                print(\"3. Daha sofistike veri dengeleme\")\n",
    "                print(\"4. Regularization teknikleri\")\n",
    "                \n",
    "            else:\n",
    "                print(\"\\n✅ İYİ PERFORMANS\")\n",
    "                print(\"Model başarılı bir şekilde çalışıyor.\")\n",
    "                \n",
    "            # Sınıf bazında performans analizi\n",
    "            print(\"\\n=== SINIF BAZINDA PERFORMANS ===\")\n",
    "            poor_classes = []\n",
    "            for class_name, metrics in results['per_class_metrics'].items():\n",
    "                if metrics['f1'] < 0.5:\n",
    "                    poor_classes.append(class_name)\n",
    "                    \n",
    "            if poor_classes:\n",
    "                print(f\"Düşük performanslı sınıflar: {', '.join(poor_classes)}\")\n",
    "                print(\"Bu sınıflar için:\")\n",
    "                print(\"- Daha fazla veri toplama\")\n",
    "                print(\"- Sınıf ağırlıklandırma\")\n",
    "                print(\"- Focal loss kullanma\")\n",
    "                \n",
    "        else:\n",
    "            print(\"Model değerlendirmesi henüz yapılmamış.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Performans analizi sırasında hata: {e}\")\n",
    "\n",
    "def get_improvement_suggestions():\n",
    "    \"\"\"\n",
    "    Gelişmiş iyileştirme önerileri\n",
    "    \"\"\"\n",
    "    suggestions = {\n",
    "        \"Veri İyileştirmeleri\": [\n",
    "            \"Veri temizleme ve outlier detection\",\n",
    "            \"Feature scaling yöntemlerini karşılaştırma (RobustScaler, MinMaxScaler)\",\n",
    "            \"Veri artırma teknikleri (audio augmentation)\"\n",
    "        ],\n",
    "        \"Model İyileştirmeleri\": [\n",
    "            \"Bidirectional LSTM kullanma\",\n",
    "            \"Attention mechanism ekleme\",\n",
    "            \"Residual connections\",\n",
    "            \"Batch normalization optimizasyonu\"\n",
    "        ],\n",
    "        \"Eğitim İyileştirmeleri\": [\n",
    "            \"Learning rate scheduling\",\n",
    "            \"Gradient clipping\",\n",
    "            \"Warm-up strategies\",\n",
    "            \"Cyclical learning rates\"\n",
    "        ],\n",
    "        \"Ensemble Yöntemleri\": [\n",
    "            \"Farklı model mimarilerini birleştirme\",\n",
    "            \"Voting classifiers\",\n",
    "            \"Stacking\",\n",
    "            \"Bagging\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    print(\"\\n=== GELİŞMİŞ İYİLEŞTİRME ÖNERİLERİ ===\")\n",
    "    for category, items in suggestions.items():\n",
    "        print(f\"\\n{category}:\")\n",
    "        for item in items:\n",
    "            print(f\"  • {item}\")\n",
    "\n",
    "# Performans analizini çalıştır\n",
    "analyze_model_performance()\n",
    "get_improvement_suggestions()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL EĞİTİMİ VE DEĞERLENDİRMESİ TAMAMLANDI\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f66fac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIMPLIFICATION: Removed cross-validation and hyperparameter tuning\n",
    "# These add complexity and can lead to overfitting\n",
    "print(\"Cross-validation and hyperparameter tuning removed for simplicity.\")\n",
    "print(\"Focus on getting basic model to generalize well first.\")\n",
    "print(\"Once basic performance is good, then optimize hyperparameters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adafbaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FURTHER SIMPLIFICATION: Remove complex hyperparameter tuning\n",
    "print(\"Complex hyperparameter tuning removed to prevent overfitting.\")\n",
    "print(\"Current model uses conservative parameters proven to work well.\")\n",
    "print(\"Focus on data quality and model architecture before fine-tuning.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf044d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING DIAGNOSTICS - Check what's happening during training\n",
    "print(\"\\n=== TRAINING DIAGNOSTICS ===\")\n",
    "\n",
    "# Quick check of first batch performance\n",
    "with torch.no_grad():\n",
    "    # Get first batch\n",
    "    first_batch = next(iter(train_loader))\n",
    "    inputs, labels = first_batch[0].to(device), first_batch[1].to(device)\n",
    "    \n",
    "    # Check model output before training\n",
    "    model.eval()\n",
    "    outputs = model(inputs)\n",
    "    _, predictions = torch.max(outputs, 1)\n",
    "    \n",
    "    print(f\"First batch:\")\n",
    "    print(f\"  Input shape: {inputs.shape}\")\n",
    "    print(f\"  Labels shape: {labels.shape}\")\n",
    "    print(f\"  Output shape: {outputs.shape}\")\n",
    "    print(f\"  Unique labels in batch: {torch.unique(labels)}\")\n",
    "    print(f\"  Unique predictions: {torch.unique(predictions)}\")\n",
    "    \n",
    "    # Check if model is outputting reasonable probabilities\n",
    "    probs = torch.softmax(outputs, dim=1)\n",
    "    print(f\"  Output probabilities - Min: {probs.min():.4f}, Max: {probs.max():.4f}\")\n",
    "    print(f\"  Most confident prediction: {probs.max(dim=1)[0].mean():.4f}\")\n",
    "    \n",
    "    # Check accuracy on first batch\n",
    "    accuracy = (predictions == labels).float().mean()\n",
    "    print(f\"  Random accuracy on first batch: {accuracy:.4f}\")\n",
    "    print(f\"  Expected random accuracy: {1/num_classes:.4f}\")\n",
    "    \n",
    "    if accuracy < 0.05:  # Much worse than random\n",
    "        print(\"  ⚠️  WARNING: Model performing much worse than random!\")\n",
    "        print(\"  This suggests a serious issue with model or data.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Ready to start training. Watch for:\")\n",
    "print(\"1. Training accuracy should improve from random levels\")\n",
    "print(\"2. Validation accuracy should follow training (with some gap)\")\n",
    "print(\"3. Loss should decrease steadily\")\n",
    "print(\"4. If validation accuracy stays near random, there's an issue\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603bdf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINAL ACCURACY BOOST WITH BEST PRACTICES\n",
    "print(\"\\n=== FINAL PERFORMANCE OPTIMIZATION ===\")\n",
    "\n",
    "# Option 1: Train a single optimized model with all improvements\n",
    "print(\"Training optimized single model...\")\n",
    "optimized_model = MusicGenreLSTM(input_size, hidden_size, num_layers, num_classes, dropout).to(device)\n",
    "\n",
    "# Enhanced optimizer settings\n",
    "optimizer_opt = optim.AdamW(optimized_model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "scheduler_opt = optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer_opt, max_lr=0.003, epochs=25, steps_per_epoch=len(train_loader)\n",
    ")\n",
    "\n",
    "# Custom training function with OneCycleLR\n",
    "def train_optimized_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    best_model = None\n",
    "    patience_counter = 0\n",
    "    PATIENCE = 8\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            scheduler.step()  # Step after each batch for OneCycleLR\n",
    "            \n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Calculate metrics\n",
    "        epoch_train_loss = train_loss / len(train_loader.dataset)\n",
    "        epoch_val_loss = val_loss / len(val_loader.dataset)\n",
    "        epoch_train_acc = train_correct / train_total\n",
    "        epoch_val_acc = val_correct / val_total\n",
    "        \n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        # Store metrics\n",
    "        train_losses.append(epoch_train_loss)\n",
    "        val_losses.append(epoch_val_loss)\n",
    "        train_accs.append(epoch_train_acc)\n",
    "        val_accs.append(epoch_val_acc)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs} - '\n",
    "              f'Train Loss: {epoch_train_loss:.4f}, Train Acc: {epoch_train_acc:.4f}, '\n",
    "              f'Val Loss: {epoch_val_loss:.4f}, Val Acc: {epoch_val_acc:.4f}, LR: {current_lr:.6f}')\n",
    "        \n",
    "        # Save best model\n",
    "        if epoch_val_acc > best_val_acc:\n",
    "            best_val_acc = epoch_val_acc\n",
    "            best_model = model.state_dict().copy()\n",
    "            patience_counter = 0\n",
    "            print(f'*** New best validation accuracy: {best_val_acc:.4f} ***')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            \n",
    "        if patience_counter >= PATIENCE:\n",
    "            print(f'Early stopping at epoch {epoch+1}')\n",
    "            break\n",
    "    \n",
    "    # Load best model\n",
    "    model.load_state_dict(best_model)\n",
    "    print(f'Final optimized model validation accuracy: {best_val_acc:.4f}')\n",
    "    return model, train_losses, val_losses, train_accs, val_accs\n",
    "\n",
    "# Train the optimized model\n",
    "print(\"\\nTraining final optimized model...\")\n",
    "final_model, final_train_losses, final_val_losses, final_train_accs, final_val_accs = train_optimized_model(\n",
    "    optimized_model, train_loader, val_loader, criterion, optimizer_opt, scheduler_opt, num_epochs=25\n",
    ")\n",
    "\n",
    "print(\"\\n🎯 FINAL MODEL TRAINING COMPLETED!\")\n",
    "print(\"Ready for test evaluation...\")\n",
    "print(\"Expected improvement: 61% → 65-70% test accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112de52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINAL TEST EVALUATION\n",
    "print(\"\\n=== FINAL TEST EVALUATION ===\")\n",
    "\n",
    "# Evaluate the final optimized model\n",
    "def evaluate_final_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    y_proba = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            probabilities = torch.softmax(outputs, dim=1)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "            y_proba.extend(probabilities.cpu().numpy())\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = np.mean(np.array(y_true) == np.array(y_pred))\n",
    "    \n",
    "    return accuracy, y_true, y_pred, np.array(y_proba)\n",
    "\n",
    "# Test the final model\n",
    "final_accuracy, y_true_final, y_pred_final, y_proba_final = evaluate_final_model(final_model, test_loader, device)\n",
    "\n",
    "print(f\"\\n🎉 FINAL TEST ACCURACY: {final_accuracy:.4f} ({final_accuracy*100:.1f}%)\")\n",
    "\n",
    "# Compare with baseline\n",
    "baseline_accuracy = 0.61  # Previous best\n",
    "improvement = final_accuracy - baseline_accuracy\n",
    "print(f\"Improvement over baseline: {improvement:.4f} ({improvement*100:.1f} percentage points)\")\n",
    "\n",
    "if final_accuracy > 0.65:\n",
    "    print(\"🚀 EXCELLENT! Achieved target of >65% accuracy!\")\n",
    "elif final_accuracy > baseline_accuracy:\n",
    "    print(\"✅ GOOD! Model improved over baseline.\")\n",
    "else:\n",
    "    print(\"📊 Performance maintained at baseline level.\")\n",
    "\n",
    "# Quick class-wise performance\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"\\nClass-wise Performance:\")\n",
    "report = classification_report(y_true_final, y_pred_final, target_names=le.classes_, output_dict=True, zero_division=0)\n",
    "for class_name, metrics in report.items():\n",
    "    if isinstance(metrics, dict) and 'f1-score' in metrics:\n",
    "        print(f\"{class_name}: F1={metrics['f1-score']:.3f}\")\n",
    "\n",
    "print(f\"\\nMacro F1: {report['macro avg']['f1-score']:.4f}\")\n",
    "print(f\"Weighted F1: {report['weighted avg']['f1-score']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"🎯 MUSIC GENRE CLASSIFICATION OPTIMIZATION COMPLETE!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c917ed",
   "metadata": {},
   "source": [
    "## 🚀 Performance Optimization Summary\n",
    "\n",
    "### Improvements Applied:\n",
    "\n",
    "1. **Enhanced Model Architecture:**\n",
    "   - Bidirectional LSTM for better feature capture\n",
    "   - Optimized batch normalization and dropout\n",
    "   - Two-layer classifier for better decision boundaries\n",
    "\n",
    "2. **Advanced Training Techniques:**\n",
    "   - OneCycleLR scheduler for better convergence\n",
    "   - Label smoothing to prevent overconfidence\n",
    "   - Gradient clipping for training stability\n",
    "   - AdamW optimizer with weight decay\n",
    "\n",
    "3. **Data Enhancement:**\n",
    "   - Increased K-best features to 150\n",
    "   - Simple data augmentation with noise injection\n",
    "   - Improved sequence length for temporal modeling\n",
    "\n",
    "4. **Training Optimization:**\n",
    "   - Balanced batch size (256)\n",
    "   - Appropriate early stopping patience\n",
    "   - Best model selection based on validation accuracy\n",
    "\n",
    "### Expected Results:\n",
    "- **Baseline:** 61% test accuracy\n",
    "- **Target:** 65-70% test accuracy\n",
    "- **Key Improvement:** Better generalization without overfitting\n",
    "\n",
    "### Next Steps if Needed:\n",
    "- Ensemble methods (3-5 models)\n",
    "- Advanced augmentation techniques\n",
    "- Hyperparameter fine-tuning\n",
    "- Architecture search (CNN, Transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45549268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMMEDIATE TRAINING VERIFICATION\n",
    "print(\"\\n=== QUICK TRAINING VERIFICATION ===\")\n",
    "print(\"Testing if the enhanced oversampling actually improves learning...\")\n",
    "\n",
    "# Quick check of first few batches to see class distribution\n",
    "print(\"\\nChecking class distribution in first few training batches:\")\n",
    "class_counter = Counter()\n",
    "for i, (inputs, labels) in enumerate(train_loader):\n",
    "    for label in labels:\n",
    "        class_counter[label.item()] += 1\n",
    "    if i >= 2:  # Check first 3 batches\n",
    "        break\n",
    "\n",
    "print(\"Classes seen in first 3 batches:\")\n",
    "for class_idx, count in sorted(class_counter.items()):\n",
    "    if class_idx < len(le.classes_):\n",
    "        print(f\"  {le.classes_[class_idx]}: {count} samples\")\n",
    "\n",
    "total_seen = sum(class_counter.values())\n",
    "if len(class_counter) < len(le.classes_) * 0.7:  # Less than 70% of classes\n",
    "    print(f\"\\n⚠️  WARNING: Only {len(class_counter)} out of {len(le.classes_)} classes seen\")\n",
    "    print(\"This suggests severe class imbalance still exists!\")\n",
    "else:\n",
    "    print(f\"\\n✅ Good diversity: {len(class_counter)} out of {len(le.classes_)} classes seen\")\n",
    "\n",
    "print(f\"\\nReady to train with {len(y_train_tensor)} total training samples\")\n",
    "print(f\"Expected accuracy improvement from better balance: 63% → 66-68%\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydebian (3.11.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
