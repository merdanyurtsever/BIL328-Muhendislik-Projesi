{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bfa6a60",
   "metadata": {},
   "source": [
    "# Müzik Türü Sınıflandırma Projesi\n",
    "\n",
    "Bu notebook, FMA (Free Music Archive) veri setini kullanarak müzik türü sınıflandırma modeli geliştirmek için veri hazırlama ve dengeleme işlemlerini içermektedir.\n",
    "\n",
    "## Gerekli Kütüphanelerin İçe Aktarılması\n",
    "Aşağıdaki hücrede, projede kullanılacak temel Python kütüphaneleri import edilmektedir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2a41ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from imblearn.over_sampling import RandomOverSampler, BorderlineSMOTE\n",
    "from collections import Counter\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(style='whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4206449",
   "metadata": {},
   "source": [
    "## Yardımcı Fonksiyonlar\n",
    "\n",
    "### Sınıf Dağılımı Görselleştirme Fonksiyonu\n",
    "Aşağıdaki fonksiyon, veri setindeki sınıf dağılımlarını görselleştirmek için kullanılacaktır. Bu görselleştirme, veri dengesizliğini anlamamıza yardımcı olur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ae2a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_class_distribution(y, labels, title):\n",
    "    counts = pd.Series(y).value_counts().sort_index()\n",
    "    valid_indices = counts.index[counts.index < len(labels)]\n",
    "    counts = counts.loc[valid_indices]\n",
    "    names = labels[counts.index]\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    ax = sns.barplot(x=names, y=counts.values, hue=names, palette='viridis', legend=False)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Sınıf')\n",
    "    ax.set_ylabel('Sayı')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471baca3",
   "metadata": {},
   "source": [
    "## Veri Yükleme ve Ön İşleme\n",
    "\n",
    "Bu bölümdeki fonksiyon:\n",
    "- FMA metadata dosyalarını yükler\n",
    "- Gerekli sütunları seçer\n",
    "- Eksik verileri temizler\n",
    "- Etiketleri kodlar\n",
    "- Veriyi sayısal formata dönüştürür"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e25b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    tracks_path = 'fma_metadata/tracks.csv'\n",
    "    features_path = 'fma_metadata/features.csv'\n",
    "\n",
    "    if not os.path.exists(tracks_path) or not os.path.exists(features_path):\n",
    "        raise FileNotFoundError(f\"Gerekli veri dosyaları bulunamadı. '{tracks_path}' ve '{features_path}' dosyalarının mevcut olduğundan emin olun.\")\n",
    "\n",
    "    tracks = pd.read_csv(tracks_path, index_col=0, header=[0,1])\n",
    "    \n",
    "    features = pd.read_csv(features_path, index_col=0, header=[0,1])  # Çok seviyeli başlıkla oku\n",
    "    features = features.loc[:, features.columns.get_level_values(0) != 'statistics']  # 'statistics' sütunlarını kaldır\n",
    "    features = features.astype(np.float32)  # Sayısal olmayan sütunları kaldırdıktan sonra float'a dönüştür\n",
    "\n",
    "    features.index = features.index.astype(str)\n",
    "    tracks.index = tracks.index.astype(str)\n",
    "\n",
    "    genre_series = tracks[('track', 'genre_top')].dropna()\n",
    "    common_index = features.index.intersection(genre_series.index)\n",
    "\n",
    "    X = features.loc[common_index]\n",
    "    y_labels = genre_series.loc[common_index]\n",
    "\n",
    "    X = X.fillna(0).replace([np.inf, -np.inf], 0).astype(np.float32)\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    y = label_encoder.fit_transform(y_labels)\n",
    "\n",
    "    print('Veriler yüklendi ve önişlendi.')\n",
    "    return X, y, label_encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c705ac60",
   "metadata": {},
   "source": [
    "## Başlangıç Veri Analizi\n",
    "\n",
    "Verinin ilk yüklemesini yapıp, başlangıçtaki sınıf dağılımını inceleyelim. Bu analiz, veri dengesizliği problemini görselleştirmemize yardımcı olacak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97f61d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veriyi yükle ve önişle\n",
    "X, y, le = load_data()\n",
    "\n",
    "# Başlangıç dağılımını göster\n",
    "plot_class_distribution(y, le.classes_, 'Başlangıç Sınıf Dağılımı')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b6b7b9",
   "metadata": {},
   "source": [
    "## Veri Bölme ve Eğitim Seti Analizi\n",
    "\n",
    "Veriyi eğitim ve test setlerine ayırıp, eğitim setindeki sınıf dağılımını inceliyoruz. Stratified split kullanarak orijinal dağılımı koruyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ef4617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veriyi böl ve eğitim dağılımını göster\n",
    "# İlk bölme: Ana eğitim ve test setleri\n",
    "X_train_orig, X_test, y_train_orig, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# İkinci bölme: Ana eğitim setini resampling ve temiz doğrulama setlerine ayır\n",
    "X_train_for_resample, X_val_clean, y_train_for_resample, y_val_clean = train_test_split(\n",
    "    X_train_orig, y_train_orig, test_size=0.15, stratify=y_train_orig, random_state=42\n",
    ")\n",
    "\n",
    "print(f'İlk bölünme tamamlandı: X_train_orig {X_train_orig.shape}, X_test {X_test.shape}')\n",
    "print(f'İkinci bölünme tamamlandı: X_train_for_resample {X_train_for_resample.shape}, X_val_clean {X_val_clean.shape}')\n",
    "\n",
    "plot_class_distribution(y_train_for_resample, le.classes_, 'Resampling İçin Eğitim Seti Dağılımı')\n",
    "\n",
    "# Detaylı dağılımı yazdır\n",
    "unique, counts = np.unique(y_train_for_resample, return_counts=True)\n",
    "print(\"\\nResampling İçin Eğitim Seti Dağılımı (ham sayılar):\")\n",
    "for i, (u, c) in enumerate(zip(unique, counts)):\n",
    "    print(f\"Sınıf {u} ({le.classes_[i]}): {c} örnek\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48a9420",
   "metadata": {},
   "source": [
    "## Veri Dengeleme - Aşama 1\n",
    "\n",
    "İlk aşamada, çok az örneğe sahip sınıflar için RandomOverSampler kullanılıyor. Bu aşama, BorderlineSMOTE için yeterli örnek sayısına ulaşmamızı sağlar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d82e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adım 1: En az temsil edilen sınıflar için RandomOverSampler\n",
    "print('\\nAdım 1: Aşırı az temsil edilen sınıflar için RandomOverSampler uygulanıyor...')\n",
    "min_samples_threshold = 50  # BorderlineSMOTE için gereken minimum örnek sayısı\n",
    "ros = RandomOverSampler(sampling_strategy={3: min_samples_threshold}, random_state=42)\n",
    "X_partial, y_partial = ros.fit_resample(X_train_for_resample, y_train_for_resample)\n",
    "\n",
    "# Ara sonuçları göster\n",
    "unique_partial, counts_partial = np.unique(y_partial, return_counts=True)\n",
    "print(\"\\nRandomOverSampler sonrası dağılım (ham sayılar):\")\n",
    "for i, (u, c) in enumerate(zip(unique_partial, counts_partial)):\n",
    "    print(f\"Sınıf {u} ({le.classes_[i]}): {c} örnek\")\n",
    "\n",
    "plot_class_distribution(y_partial, le.classes_, 'RandomOverSampler Sonrası')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b9d611",
   "metadata": {},
   "source": [
    "## Veri Dengeleme - Aşama 2\n",
    "\n",
    "İkinci aşamada, daha sofistike bir yaklaşım olan BorderlineSMOTE kullanılarak kalan sınıflar dengeleniyor. Bu yöntem, sadece rastgele kopyalama yerine sentetik örnekler oluşturur.\n",
    "\n",
    "Not: Bu aşama, veri setinin yapısına bağlı olarak başarısız olabilir. Bu durumda, ilk aşamadaki sonuçlar kullanılacaktır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0e95e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adım 2: Kalan sınıflar için BorderlineSMOTE\n",
    "print('\\nAdım 2: Kalan sınıflar için BorderlineSMOTE uygulanıyor...')\n",
    "borderline_smote = BorderlineSMOTE(random_state=42)\n",
    "\n",
    "try:\n",
    "    X_res, y_res = borderline_smote.fit_resample(X_partial, y_partial)\n",
    "    print(f'Kombine örnekleme tamamlandı: X_res {X_res.shape}, y_res {y_res.shape}')\n",
    "    \n",
    "    # Son dağılımı yazdır ve göster\n",
    "    unique_res, counts_res = np.unique(y_res, return_counts=True)\n",
    "    print(\"\\nSon Dağılım (ham sayılar):\")\n",
    "    for i, (u, c) in enumerate(zip(unique_res, counts_res)):\n",
    "        print(f\"Sınıf {u} ({le.classes_[i]}): {c} örnek\")\n",
    "    \n",
    "    plot_class_distribution(y_res, le.classes_, 'Son Dengelenmiş Dağılım')\n",
    "\n",
    "except Exception as e:\n",
    "    print(f'BorderlineSMOTE örnekleme başarısız oldu: {e} - kısmi örneklenmiş veri kullanılıyor')\n",
    "    X_res, y_res = X_partial, y_partial\n",
    "    plot_class_distribution(y_res, le.classes_, 'Kısmi Örnekleme (BorderlineSMOTE başarısız)')\n",
    "\n",
    "print(\"\\nİşlem hattı tamamlandı. Yeniden örneklenmiş eğitim verisi (X_res, y_res) ve test verisi (X_test, y_test) hazır.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291b507b",
   "metadata": {},
   "source": [
    "## Özellik Seçimi (K-Best Feature Selection)\n",
    "\n",
    "Model performansını artırmak ve aşırı öğrenmeyi (overfitting) azaltmak için K-Best özellik seçimi algoritmasını uygulayacağız. Bu algoritma, her özelliğin hedef değişkenle olan istatistiksel ilişkisini ölçer ve en anlamlı K özelliği seçer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c6196b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Best özellik seçimi uygulaması\n",
    "print('\\nK-Best özellik seçimi uygulanıyor...')\n",
    "\n",
    "k = 250  # Seçilecek özellik sayısı\n",
    "print(f\"Toplam özellik sayısı: {X_res.shape[1]}, Seçilecek özellik sayısı: {k}\")\n",
    "\n",
    "# SelectKBest ile özellik seçimi - Sadece resampled data üzerinde fit et\n",
    "selector = SelectKBest(score_func=f_classif, k=k)\n",
    "X_res_selected = selector.fit_transform(X_res, y_res)\n",
    "\n",
    "# Fitted selector ile validation ve test setlerini transform et\n",
    "X_val_clean_selected = selector.transform(X_val_clean)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "# Hangi özelliklerin seçildiğini gösteren görselleştirme\n",
    "selected_mask = selector.get_support()\n",
    "scores = selector.scores_\n",
    "feature_indices = np.arange(len(selected_mask))\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(feature_indices, scores, alpha=0.3, color='g')\n",
    "plt.bar(feature_indices[selected_mask], scores[selected_mask], color='g')\n",
    "plt.title('Özellik Skorları ve Seçilen Özellikler')\n",
    "plt.xlabel('Özellik İndeksi')\n",
    "plt.ylabel('F-değeri (F-value)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Özellik seçimi tamamlandı. Seçilen özelliklerin boyutu: {X_res_selected.shape}\")\n",
    "print(f\"Validation set boyutu: {X_val_clean_selected.shape}\")\n",
    "print(f\"Test set boyutu: {X_test_selected.shape}\")\n",
    "\n",
    "# Orijinal veriyi güncellenmiş veri ile değiştirelim\n",
    "X_res = X_res_selected\n",
    "X_val_clean = X_val_clean_selected\n",
    "X_test = X_test_selected\n",
    "\n",
    "# Veri Ölçeklendirme (StandardScaler) - Sadece resampled data üzerinde fit et\n",
    "print('\\nVeri ölçeklendirme uygulanıyor...')\n",
    "scaler = StandardScaler()\n",
    "X_res_scaled = scaler.fit_transform(X_res)\n",
    "X_val_clean_scaled = scaler.transform(X_val_clean)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Veri ölçeklendirme tamamlandı.\")\n",
    "print(f\"Ölçeklenmiş resampled eğitim verisi boyutu: {X_res_scaled.shape}\")\n",
    "print(f\"Ölçeklenmiş validation verisi boyutu: {X_val_clean_scaled.shape}\")\n",
    "print(f\"Ölçeklenmiş test verisi boyutu: {X_test_scaled.shape}\")\n",
    "\n",
    "# Veriyi güncellenmiş ölçeklenmiş veriler ile değiştir\n",
    "X_res = X_res_scaled\n",
    "X_val_clean = X_val_clean_scaled\n",
    "X_test = X_test_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69962f4f",
   "metadata": {},
   "source": [
    "*-----------------------------------------------------------------------------------*\n",
    "# PyTorch LSTM MODEL EĞİTİMİ\n",
    "*-----------------------------------------------------------------------------------*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340b3123",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPyTorch LSTM Model Eğitimi Başlıyor...\")\n",
    "\n",
    "# Veri yükleme, önişleme, bölme ve dengeleme adımlarının tamamlandığı varsayılır.\n",
    "# Bu noktada aşağıdaki değişkenlerin mevcut olması beklenir:\n",
    "# X_res, y_res (Dengelenmiş eğitim verisi)\n",
    "# X_val, y_val (Doğrulama verisi)\n",
    "# X_test, y_test (Test verisi)\n",
    "# le (LabelEncoder nesnesi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9a8a07",
   "metadata": {},
   "source": [
    "## Gelişmiş Özellik Mühendisliği ve Model Optimizasyonu (İsteğe Bağlı)\n",
    "\n",
    "Bu bölümde, model performansını artırmak için gelişmiş özellik mühendisliği tekniklerini ve model optimizasyonlarını güvenli bir şekilde uygulayabiliriz. Bu teknikler veri sızıntısını önlemek için dikkatli bir şekilde tasarlanmıştır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2a356a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# İsteğe bağlı: Güvenli Gelişmiş Özellik Mühendisliği\n",
    "# Bu kısmı yalnızca mevcut pipeline'ın performansını artırmak istiyorsanız çalıştırın\n",
    "\n",
    "def enhanced_feature_engineering_pipeline(X_train, X_val, X_test, apply_pca=True, apply_poly=False, pca_variance=0.95, max_poly_features=10):\n",
    "    \"\"\"\n",
    "    Güvenli gelişmiş özellik mühendisliği pipeline'ı\n",
    "    - Veri sızıntısını önler\n",
    "    - Sadece eğitim verisi üzerinde fit edilir\n",
    "    - Doğrulama ve test setleri transform edilir\n",
    "    \"\"\"\n",
    "    from sklearn.decomposition import PCA\n",
    "    from sklearn.preprocessing import PolynomialFeatures\n",
    "    \n",
    "    # Orijinal veriyi backup'la\n",
    "    X_train_backup = X_train.copy()\n",
    "    X_val_backup = X_val.copy()\n",
    "    X_test_backup = X_test.copy()\n",
    "    \n",
    "    enhanced_features_train = [X_train]\n",
    "    enhanced_features_val = [X_val]\n",
    "    enhanced_features_test = [X_test]\n",
    "    \n",
    "    try:\n",
    "        # 1. PCA for dimensionality reduction\n",
    "        if apply_pca:\n",
    "            print(f\"PCA uygulanıyor (variance: {pca_variance})...\")\n",
    "            pca = PCA(n_components=pca_variance)\n",
    "            X_train_pca = pca.fit_transform(X_train)\n",
    "            X_val_pca = pca.transform(X_val)\n",
    "            X_test_pca = pca.transform(X_test)\n",
    "            \n",
    "            # Limit PCA features to prevent overfitting\n",
    "            max_pca_features = min(50, X_train_pca.shape[1])\n",
    "            enhanced_features_train.append(X_train_pca[:, :max_pca_features])\n",
    "            enhanced_features_val.append(X_val_pca[:, :max_pca_features])\n",
    "            enhanced_features_test.append(X_test_pca[:, :max_pca_features])\n",
    "            \n",
    "            print(f\"PCA tamamlandı. {X_train_pca.shape[1]} bileşenden {max_pca_features} tanesi kullanıldı.\")\n",
    "        \n",
    "        # 2. Polynomial features (very conservative)\n",
    "        if apply_poly and max_poly_features > 0:\n",
    "            print(f\"Polinom özellikleri uygulanıyor (max {max_poly_features} özellik)...\")\n",
    "            n_features_for_poly = min(max_poly_features, X_train.shape[1])\n",
    "            poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "            \n",
    "            X_train_poly = poly.fit_transform(X_train[:, :n_features_for_poly])\n",
    "            X_val_poly = poly.transform(X_val[:, :n_features_for_poly])\n",
    "            X_test_poly = poly.transform(X_test[:, :n_features_for_poly])\n",
    "            \n",
    "            # Limit polynomial features\n",
    "            max_poly_out = min(20, X_train_poly.shape[1])\n",
    "            enhanced_features_train.append(X_train_poly[:, :max_poly_out])\n",
    "            enhanced_features_val.append(X_val_poly[:, :max_poly_out])\n",
    "            enhanced_features_test.append(X_test_poly[:, :max_poly_out])\n",
    "            \n",
    "            print(f\"Polinom özellikleri tamamlandı. {X_train_poly.shape[1]} özellikten {max_poly_out} tanesi kullanıldı.\")\n",
    "        \n",
    "        # 3. Combine all features\n",
    "        X_train_enhanced = np.hstack(enhanced_features_train)\n",
    "        X_val_enhanced = np.hstack(enhanced_features_val)\n",
    "        X_test_enhanced = np.hstack(enhanced_features_test)\n",
    "        \n",
    "        # 4. Apply scaling to enhanced features\n",
    "        scaler_enhanced = StandardScaler()\n",
    "        X_train_final = scaler_enhanced.fit_transform(X_train_enhanced)\n",
    "        X_val_final = scaler_enhanced.transform(X_val_enhanced)\n",
    "        X_test_final = scaler_enhanced.transform(X_test_enhanced)\n",
    "        \n",
    "        print(f\"Gelişmiş özellik mühendisliği başarılı!\")\n",
    "        print(f\"Özellik boyutları: {X_train.shape[1]} -> {X_train_final.shape[1]}\")\n",
    "        \n",
    "        return X_train_final, X_val_final, X_test_final, True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Gelişmiş özellik mühendisliği başarısız: {e}\")\n",
    "        print(\"Orijinal veriler kullanılıyor.\")\n",
    "        return X_train_backup, X_val_backup, X_test_backup, False\n",
    "\n",
    "# Gelişmiş özellik mühendisliği ayarları\n",
    "APPLY_ENHANCED_FEATURES = False  # Bu değeri True yaparak etkinleştirin\n",
    "APPLY_PCA = True\n",
    "APPLY_POLYNOMIAL = False  # Dikkatli olun, bu çok fazla özellik yaratabilir\n",
    "PCA_VARIANCE = 0.95\n",
    "MAX_POLY_FEATURES = 5  # Çok küçük tutun\n",
    "\n",
    "if APPLY_ENHANCED_FEATURES:\n",
    "    print(\"Gelişmiş özellik mühendisliği uygulanıyor...\")\n",
    "    \n",
    "    # Mevcut verileri enhanced features ile değiştir\n",
    "    X_res_enhanced, X_val_clean_enhanced, X_test_enhanced, success = enhanced_feature_engineering_pipeline(\n",
    "        X_res, X_val_clean, X_test, \n",
    "        apply_pca=APPLY_PCA, \n",
    "        apply_poly=APPLY_POLYNOMIAL,\n",
    "        pca_variance=PCA_VARIANCE,\n",
    "        max_poly_features=MAX_POLY_FEATURES\n",
    "    )\n",
    "    \n",
    "    if success:\n",
    "        X_res = X_res_enhanced\n",
    "        X_val_clean = X_val_clean_enhanced\n",
    "        X_test = X_test_enhanced\n",
    "        print(\"Gelişmiş özellikler başarıyla uygulandı.\")\n",
    "    else:\n",
    "        print(\"Orijinal özellikler korundu.\")\n",
    "else:\n",
    "    print(\"Gelişmiş özellik mühendisliği devre dışı. Mevcut pipeline kullanılıyor.\")\n",
    "\n",
    "print(f\"\\nFinal veri boyutları:\")\n",
    "print(f\"Training (X_res): {X_res.shape}\")\n",
    "print(f\"Validation (X_val_clean): {X_val_clean.shape}\")\n",
    "print(f\"Test (X_test): {X_test.shape}\")\n",
    "\n",
    "# Model alternatiflerini test etme fonksiyonu\n",
    "def compare_model_architectures():\n",
    "    \"\"\"\n",
    "    Farklı model mimarilerini karşılaştırma (isteğe bağlı)\n",
    "    \"\"\"\n",
    "    print(\"\\n=== MODEL MİMARİSİ KARŞILAŞTIRMASI ===\")\n",
    "    print(\"Mevcut LSTM modeli yanında şu alternatifleri deneyebilirsiniz:\")\n",
    "    print(\"1. Bidirectional LSTM\")\n",
    "    print(\"2. GRU (Gated Recurrent Unit)\")\n",
    "    print(\"3. 1D CNN + LSTM hibrit\")\n",
    "    print(\"4. Transformer tabanlı model\")\n",
    "    print(\"5. Ensemble modeller\")\n",
    "    \n",
    "    print(\"\\nMevcut hiperparametrelerle deneme önerileri:\")\n",
    "    print(\"- Hidden size: [64, 128, 256]\")\n",
    "    print(\"- Num layers: [1, 2, 3]\")\n",
    "    print(\"- Dropout: [0.2, 0.3, 0.5]\")\n",
    "    print(\"- Learning rate: [0.001, 0.01, 0.0001]\")\n",
    "\n",
    "compare_model_architectures()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f746e0b",
   "metadata": {},
   "source": [
    "## LSTM Modeli için Veri Hazırlığı\n",
    "\n",
    "PyTorch LSTM modeli için, veriyi uygun formata dönüştürmemiz gerekir. LSTM modeller sıralı veri bekler, bu nedenle öznitelik vektörünü zamansal bir diziye dönüştüreceğiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa7d165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch tensörlerine dönüştürme ve veri setlerini hazırlama\n",
    "def create_sequence_data(X, y, sequence_length=10):\n",
    "    \"\"\"\n",
    "    Öznitelik vektörünü sıralı verilere dönüştürür.\n",
    "    FMA veri seti sıralı yapıda değil, bu nedenle yapay bir sıra oluşturuyoruz.\n",
    "    \"\"\"\n",
    "    # Veri boyutlarını kontrol et\n",
    "    n_samples, n_features = X.shape\n",
    "    \n",
    "    # Veriyi yeniden şekillendirme\n",
    "    features_per_timestep = n_features // sequence_length\n",
    "    \n",
    "    if features_per_timestep == 0:\n",
    "        features_per_timestep = 1\n",
    "        sequence_length = min(sequence_length, n_features)\n",
    "    \n",
    "    # Son timestep'e sığmayan özellikleri ele alma\n",
    "    remainder = n_features - (sequence_length * features_per_timestep)\n",
    "    \n",
    "    # Yeniden şekillendirilmiş veri için array oluşturma\n",
    "    X_seq = np.zeros((n_samples, sequence_length, features_per_timestep))\n",
    "    \n",
    "    # Veriyi yeniden şekillendirme\n",
    "    for i in range(n_samples):\n",
    "        for t in range(sequence_length):\n",
    "            start_idx = t * features_per_timestep\n",
    "            end_idx = min(start_idx + features_per_timestep, n_features)\n",
    "            \n",
    "            if start_idx < n_features:\n",
    "                X_seq[i, t, :end_idx-start_idx] = X[i, start_idx:end_idx]\n",
    "    \n",
    "    # PyTorch tensörlerine dönüştürme\n",
    "    X_tensor = torch.FloatTensor(X_seq)\n",
    "    y_tensor = torch.LongTensor(y)\n",
    "    \n",
    "    return X_tensor, y_tensor\n",
    "\n",
    "# Sıralı veri için hiperparametre\n",
    "sequence_length = 5\n",
    "\n",
    "# Ölçeklenmiş verileri sıralı forma dönüştürme - Yeni pipeline değişkenlerini kullan\n",
    "X_train_seq, y_train_tensor = create_sequence_data(X_res, y_res, sequence_length)\n",
    "X_val_seq, y_val_tensor = create_sequence_data(X_val_clean, y_val_clean, sequence_length)\n",
    "X_test_seq, y_test_tensor = create_sequence_data(X_test, y_test, sequence_length)\n",
    "\n",
    "print(f\"Eğitim veri boyutu: {X_train_seq.shape}\")\n",
    "print(f\"Doğrulama veri boyutu: {X_val_seq.shape}\")\n",
    "print(f\"Test veri boyutu: {X_test_seq.shape}\")\n",
    "\n",
    "# PyTorch DataLoader oluşturma\n",
    "batch_size = 512\n",
    "train_dataset = TensorDataset(X_train_seq, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_seq, y_val_tensor)\n",
    "test_dataset = TensorDataset(X_test_seq, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719d6bcd",
   "metadata": {},
   "source": [
    "## LSTM Model Tanımı ve Eğitimi\n",
    "\n",
    "Aşağıda müzik türü sınıflandırması için bir LSTM (Long Short-Term Memory) ağı tanımlıyoruz. LSTM'ler, müzik gibi sıralı verilerde başarılı olan bir derin öğrenme mimarisidir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6ce84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM model sınıfını tanımlama\n",
    "class MusicGenreLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, dropout=0.3):\n",
    "        super(MusicGenreLSTM, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # LSTM katmanları\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size, \n",
    "            hidden_size=hidden_size, \n",
    "            num_layers=num_layers, \n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0\n",
    "        )\n",
    "        \n",
    "        # Batch normalization\n",
    "        self.batch_norm = nn.BatchNorm1d(hidden_size)\n",
    "        \n",
    "        # Dropout katmanı\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Tam bağlantılı katmanlar\n",
    "        self.fc1 = nn.Linear(hidden_size, 128)  # İlk tam bağlantılı katman\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        \n",
    "        # Aktivasyon fonksiyonları\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # LSTM katmanından geçirme\n",
    "        # x şekli: (batch_size, sequence_length, input_size)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        \n",
    "        # Son zaman adımının çıktısını al\n",
    "        # lstm_out şekli: (batch_size, sequence_length, hidden_size)\n",
    "        lstm_out = lstm_out[:, -1, :]\n",
    "        \n",
    "        # Batch normalization\n",
    "        batch_norm_out = self.batch_norm(lstm_out)\n",
    "        \n",
    "        # İlk tam bağlantılı katman\n",
    "        fc1_out = self.fc1(batch_norm_out)\n",
    "        fc1_out = self.relu(fc1_out)\n",
    "        fc1_out = self.dropout(fc1_out)\n",
    "        \n",
    "        # İkinci tam bağlantılı katman (çıkış katmanı)\n",
    "        out = self.fc2(fc1_out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "# Model parametreleri\n",
    "input_size = X_train_seq.shape[2]  # Bir zaman adımındaki özellik sayısı\n",
    "hidden_size = 128  # LSTM gizli katman boyutu\n",
    "num_layers = 2  # LSTM katman sayısı\n",
    "num_classes = len(le.classes_)  # Sınıf sayısı\n",
    "dropout = 0.3\n",
    "\n",
    "# GPU kullanılabilir mi kontrol et\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Kullanılan cihaz: {device}\")\n",
    "\n",
    "# Model oluşturma\n",
    "model = MusicGenreLSTM(input_size, hidden_size, num_layers, num_classes, dropout).to(device)\n",
    "print(model)\n",
    "\n",
    "# Kayıp fonksiyonu ve optimize edici tanımlama\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "\n",
    "# Eğitim fonksiyonu\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=50, early_stopping_patience=5, min_improvement_threshold=0.001):\n",
    "    # Ölçüm değerlerini saklayacak listeler\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "    \n",
    "    # En iyi doğrulama kaybını ve modeli saklama\n",
    "    # min_improvement_threshold: Doğrulama kaybındaki minimum iyileşme eşiği, \n",
    "    # bunun altındaki iyileşmeler anlamlı kabul edilmez ve erken durdurma sayacı sıfırlanmaz.\n",
    "    best_val_loss = float('inf')\n",
    "    best_model = None\n",
    "    \n",
    "    # Erken durdurma için sayaç ve sabır parametresi\n",
    "    early_stopping_counter = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Eğitim modu\n",
    "        model.train()\n",
    "        \n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Gradyanları sıfırla\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # İleri geçiş\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Geri yayılım ve optimize etme\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # İstatistikleri güncelle\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Doğrulama modu\n",
    "        model.eval()\n",
    "        \n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                \n",
    "                # İleri geçiş\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                # İstatistikleri güncelle\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Epoch sonuçlarını hesapla\n",
    "        epoch_train_loss = train_loss / len(train_loader.dataset)\n",
    "        epoch_val_loss = val_loss / len(val_loader.dataset)\n",
    "        epoch_train_acc = train_correct / train_total\n",
    "        epoch_val_acc = val_correct / val_total\n",
    "        \n",
    "        # Öğrenme oranını ayarla\n",
    "        scheduler.step(epoch_val_loss)\n",
    "        \n",
    "        # Sonuçları sakla\n",
    "        train_losses.append(epoch_train_loss)\n",
    "        val_losses.append(epoch_val_loss)\n",
    "        train_accs.append(epoch_train_acc)\n",
    "        val_accs.append(epoch_val_acc)\n",
    "        \n",
    "        # Eğitim durumunu yazdır\n",
    "        print(f'Epoch {epoch+1}/{num_epochs} - '\n",
    "              f'Train Loss: {epoch_train_loss:.4f}, Train Acc: {epoch_train_acc:.4f}, '\n",
    "              f'Val Loss: {epoch_val_loss:.4f}, Val Acc: {epoch_val_acc:.4f}')\n",
    "        \n",
    "        # En iyi modeli sakla ve erken durdurma durumunu kontrol et\n",
    "        # Doğrulama kaybındaki iyileşme miktarını hesapla\n",
    "        improvement = best_val_loss - epoch_val_loss\n",
    "        \n",
    "        if epoch_val_loss < best_val_loss:\n",
    "            # Eğer iyileşme miktarı eşik değerinden fazlaysa sayacı sıfırla\n",
    "            if improvement > min_improvement_threshold:\n",
    "                early_stopping_counter = 0  # Counter sıfırla\n",
    "                print(f'Validation loss improved by {improvement:.6f}, which is above threshold ({min_improvement_threshold:.6f})')\n",
    "            else:\n",
    "                # İyileşme var ama eşik değerinin altında, bu durumda counter'ı artırıyoruz\n",
    "                early_stopping_counter += 1\n",
    "                print(f'Validation loss improved by only {improvement:.6f}, which is below threshold ({min_improvement_threshold:.6f})')\n",
    "            \n",
    "            # En iyi modeli ve validation loss değerini her durumda güncelle\n",
    "            best_val_loss = epoch_val_loss\n",
    "            best_model = model.state_dict()\n",
    "        else:\n",
    "            early_stopping_counter += 1  # Counter artır\n",
    "            \n",
    "        # Erken durdurma kontrolü\n",
    "        if early_stopping_counter >= early_stopping_patience:\n",
    "            print(f'Erken durdurma: Validation loss {early_stopping_patience} epoch boyunca yeterince iyileşmedi (minimum eşik: {min_improvement_threshold:.6f}).')\n",
    "            break\n",
    "    \n",
    "    # En iyi model ağırlıklarını yükle\n",
    "    model.load_state_dict(best_model)\n",
    "    \n",
    "    return model, train_losses, val_losses, train_accs, val_accs\n",
    "\n",
    "# Modeli eğit\n",
    "print(\"Model eğitimi başlıyor...\")\n",
    "num_epochs = 50\n",
    "early_stopping_patience = 3  # Model belirli bir eşik değerinden fazla iyileşmezse, bu sayıda epoch sonra eğitimi durdur\n",
    "\n",
    "try:\n",
    "    # Doğrulama kaybında 0.02 altındaki iyileşmeleri önemsiz olarak kabul et\n",
    "    min_improvement_threshold = 0.02  \n",
    "    \n",
    "    model, train_losses, val_losses, train_accs, val_accs = train_model(\n",
    "        model, train_loader, val_loader, criterion, optimizer, scheduler, \n",
    "        num_epochs=num_epochs, early_stopping_patience=early_stopping_patience,\n",
    "        min_improvement_threshold=min_improvement_threshold\n",
    "    )\n",
    "    print(\"Model eğitimi tamamlandı!\")\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Eğitim kullanıcı tarafından durduruldu.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f720d377",
   "metadata": {},
   "source": [
    "## Model Değerlendirmesi ve Görselleştirme\n",
    "\n",
    "Bu bölümde eğitilmiş modeli test veri seti üzerinde değerlendirip, sonuçları görselleştireceğiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5361a1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eğitim sonuçlarını görselleştirme\n",
    "def plot_training_history(train_losses, val_losses, train_accs, val_accs):\n",
    "    plt.figure(figsize=(14, 5))\n",
    "    \n",
    "    # Kayıp grafiği\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Eğitim', marker='o')\n",
    "    plt.plot(val_losses, label='Doğrulama', marker='*')\n",
    "    plt.title('Model Kaybı')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Kayıp (Cross-Entropy)')\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    \n",
    "    # Doğruluk grafiği\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_accs, label='Eğitim', marker='o')\n",
    "    plt.plot(val_accs, label='Doğrulama', marker='*')\n",
    "    plt.title('Model Doğruluğu')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Doğruluk')\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Eğitim sonuçlarını görselleştir\n",
    "try:\n",
    "    plot_training_history(train_losses, val_losses, train_accs, val_accs)\n",
    "except NameError:\n",
    "    print(\"Eğitim geçmişi bulunamadı. Önce modeli eğitin.\")\n",
    "\n",
    "# Test veri seti üzerinde değerlendirme\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    \n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "    \n",
    "    # Doğruluk hesapla\n",
    "    accuracy = np.mean(np.array(y_true) == np.array(y_pred))\n",
    "    \n",
    "    # Sonuçları yazdır\n",
    "    print(f\"Test Doğruluğu: {accuracy:.4f}\")\n",
    "    \n",
    "    # Sınıflandırma raporu\n",
    "    print(\"\\nSınıflandırma Raporu:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=le.classes_))\n",
    "    \n",
    "    # Karmaşıklık matrisi\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "    plt.title('Karmaşıklık Matrisi')\n",
    "    plt.xlabel('Tahmin Edilen Etiketler')\n",
    "    plt.ylabel('Gerçek Etiketler')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return y_true, y_pred\n",
    "\n",
    "# Test veri seti üzerinde değerlendir\n",
    "try:\n",
    "    y_true, y_pred = evaluate_model(model, test_loader, device)\n",
    "except NameError:\n",
    "    print(\"Model bulunamadı. Önce modeli eğitin.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a7e87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score, accuracy_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def get_model_probabilities(model, test_loader, device):\n",
    "    \"\"\"\n",
    "    Get prediction probabilities from the trained model\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_proba = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            probabilities = F.softmax(outputs, dim=1)\n",
    "            \n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_proba.extend(probabilities.cpu().numpy())\n",
    "    \n",
    "    return np.array(y_true), np.array(y_proba)\n",
    "\n",
    "def comprehensive_evaluation(model, test_loader, device, class_names):\n",
    "    \"\"\"\n",
    "    Provide detailed evaluation metrics for the trained model\n",
    "    \"\"\"\n",
    "    # Get true labels and prediction probabilities\n",
    "    y_true, y_proba = get_model_probabilities(model, test_loader, device)\n",
    "    \n",
    "    # Get predictions\n",
    "    y_pred = np.argmax(y_proba, axis=1)\n",
    "    \n",
    "    # Basic metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    # Per-class metrics\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average=None, labels=range(len(class_names))\n",
    "    )\n",
    "    \n",
    "    # Macro and weighted averages\n",
    "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average='macro'\n",
    "    )\n",
    "    precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average='weighted'\n",
    "    )\n",
    "    \n",
    "    # AUC-ROC for multiclass\n",
    "    y_true_binarized = label_binarize(y_true, classes=range(len(class_names)))\n",
    "    auc_scores = []\n",
    "    for i in range(len(class_names)):\n",
    "        if len(np.unique(y_true_binarized[:, i])) > 1:  # Check if class exists\n",
    "            auc = roc_auc_score(y_true_binarized[:, i], y_proba[:, i])\n",
    "            auc_scores.append(auc)\n",
    "    \n",
    "    # Create detailed report\n",
    "    results = {\n",
    "        'accuracy': accuracy,\n",
    "        'macro_precision': precision_macro,\n",
    "        'macro_recall': recall_macro,\n",
    "        'macro_f1': f1_macro,\n",
    "        'weighted_precision': precision_weighted,\n",
    "        'weighted_recall': recall_weighted,\n",
    "        'weighted_f1': f1_weighted,\n",
    "        'mean_auc': np.mean(auc_scores) if auc_scores else 0,\n",
    "        'per_class_metrics': {\n",
    "            class_names[i]: {\n",
    "                'precision': precision[i],\n",
    "                'recall': recall[i],\n",
    "                'f1': f1[i],\n",
    "                'support': support[i]\n",
    "            } for i in range(len(class_names))\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Use the comprehensive evaluation function\n",
    "try:\n",
    "    if 'model' in locals() and 'test_loader' in locals():\n",
    "        print(\"\\nDetaylı model değerlendirmesi...\")\n",
    "        detailed_results = comprehensive_evaluation(model, test_loader, device, le.classes_)\n",
    "        \n",
    "        print(f\"\\nDetaylı Sonuçlar:\")\n",
    "        print(f\"Accuracy: {detailed_results['accuracy']:.4f}\")\n",
    "        print(f\"Macro F1: {detailed_results['macro_f1']:.4f}\")\n",
    "        print(f\"Weighted F1: {detailed_results['weighted_f1']:.4f}\")\n",
    "        print(f\"Mean AUC: {detailed_results['mean_auc']:.4f}\")\n",
    "        \n",
    "        print(\"\\nSınıf bazında detaylar:\")\n",
    "        for class_name, metrics in detailed_results['per_class_metrics'].items():\n",
    "            print(f\"{class_name}: F1={metrics['f1']:.3f}, Precision={metrics['precision']:.3f}, Recall={metrics['recall']:.3f}\")\n",
    "    else:\n",
    "        print(\"Model henüz eğitilmemiş. Önce modeli eğitin.\")\n",
    "except NameError:\n",
    "    print(\"Model bulunamadı. Önce modeli eğitin.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f88f77",
   "metadata": {},
   "source": [
    "## Model Değerlendirmesi ve İleriye Dönük Çalışmalar\n",
    "\n",
    "Müzik türü sınıflandırma modelimiz veriyi dengeledikten sonra eğitilmiştir. Sonuçlar değerlendirilirken şunlar göz önünde bulundurulmalıdır:\n",
    "\n",
    "1. **Veri Kalitesi**: FMA veri setindeki özellikler, ses dosyalarından çıkarılmış özelliklerdir. Daha iyi sonuçlar için ham ses verileri üzerinde spektrogram analizi yapılabilir.\n",
    "\n",
    "2. **Model Mimarisi**: LSTM modeli, sıralı verilerde başarılı olmasına rağmen, müzik türü tanıma için CNN (Convolutional Neural Network) veya CNN-LSTM hibrit modeller de kullanılabilir.\n",
    "\n",
    "3. **Hiperparametreler**: Farklı hiperparametreler (örn. öğrenme oranı, katman sayısı, nöron sayısı) ile model performansı artırılabilir.\n",
    "\n",
    "4. **Veri Dengeleme**: Kullandığımız veri dengeleme yöntemleri, eğitim setindeki sınıf dağılımını eşitlemeye yardımcı olur, ancak sentetik veri oluşturma riskleri de taşır.\n",
    "\n",
    "5. **Özellik Seçimi**: K-Best algoritması ile seçilen özellikler, modelin daha iyi genelleme yapmasına ve aşırı öğrenmesinin azalmasına yardımcı olabilir. Farklı K değerleri denenerek optimum özellik sayısı bulunabilir.\n",
    "\n",
    "İleriye dönük çalışmalarda, daha karmaşık modeller, farklı özellik çıkarma teknikleri ve daha büyük veri setleri kullanılarak performans artırılabilir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d18bee",
   "metadata": {},
   "source": [
    "## Model Optimizasyonu ve Sorun Giderme\n",
    "\n",
    "Bu bölüm, model performansını artırmak için çeşitli optimizasyon teknikleri ve sorun giderme yöntemlerini içerir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c4d430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Performans Analizi ve İyileştirme Önerileri\n",
    "\n",
    "def analyze_model_performance():\n",
    "    \"\"\"\n",
    "    Model performansını analiz et ve iyileştirme önerileri sun\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if 'detailed_results' in locals() or 'detailed_results' in globals():\n",
    "            results = detailed_results\n",
    "            \n",
    "            print(\"\\n=== MODEL PERFORMANS ANALİZİ ===\")\n",
    "            print(f\"Genel Doğruluk: {results['accuracy']:.4f}\")\n",
    "            print(f\"Macro F1 Skoru: {results['macro_f1']:.4f}\")\n",
    "            print(f\"Weighted F1 Skoru: {results['weighted_f1']:.4f}\")\n",
    "            print(f\"Ortalama AUC: {results['mean_auc']:.4f}\")\n",
    "            \n",
    "            # Performans değerlendirmesi ve öneriler\n",
    "            if results['accuracy'] < 0.6:\n",
    "                print(\"\\n⚠️  DÜŞÜK PERFORMANS TESPİT EDİLDİ\")\n",
    "                print(\"Öneriler:\")\n",
    "                print(\"1. Daha fazla veri toplama\")\n",
    "                print(\"2. Farklı model mimarisi deneme (CNN, Transformer)\")\n",
    "                print(\"3. Hiperparametre optimizasyonu\")\n",
    "                print(\"4. Veri ön işleme tekniklerini gözden geçirme\")\n",
    "                \n",
    "            elif results['accuracy'] < 0.75:\n",
    "                print(\"\\n📊 ORTA SEVİYE PERFORMANS\")\n",
    "                print(\"İyileştirme önerileri:\")\n",
    "                print(\"1. Özellik mühendisliği uygulama\")\n",
    "                print(\"2. Model ensemble teknikleri\")\n",
    "                print(\"3. Daha sofistike veri dengeleme\")\n",
    "                print(\"4. Regularization teknikleri\")\n",
    "                \n",
    "            else:\n",
    "                print(\"\\n✅ İYİ PERFORMANS\")\n",
    "                print(\"Model başarılı bir şekilde çalışıyor.\")\n",
    "                \n",
    "            # Sınıf bazında performans analizi\n",
    "            print(\"\\n=== SINIF BAZINDA PERFORMANS ===\")\n",
    "            poor_classes = []\n",
    "            for class_name, metrics in results['per_class_metrics'].items():\n",
    "                if metrics['f1'] < 0.5:\n",
    "                    poor_classes.append(class_name)\n",
    "                    \n",
    "            if poor_classes:\n",
    "                print(f\"Düşük performanslı sınıflar: {', '.join(poor_classes)}\")\n",
    "                print(\"Bu sınıflar için:\")\n",
    "                print(\"- Daha fazla veri toplama\")\n",
    "                print(\"- Sınıf ağırlıklandırma\")\n",
    "                print(\"- Focal loss kullanma\")\n",
    "                \n",
    "        else:\n",
    "            print(\"Model değerlendirmesi henüz yapılmamış.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Performans analizi sırasında hata: {e}\")\n",
    "\n",
    "def get_improvement_suggestions():\n",
    "    \"\"\"\n",
    "    Gelişmiş iyileştirme önerileri\n",
    "    \"\"\"\n",
    "    suggestions = {\n",
    "        \"Veri İyileştirmeleri\": [\n",
    "            \"Veri temizleme ve outlier detection\",\n",
    "            \"Feature scaling yöntemlerini karşılaştırma (RobustScaler, MinMaxScaler)\",\n",
    "            \"Veri artırma teknikleri (audio augmentation)\"\n",
    "        ],\n",
    "        \"Model İyileştirmeleri\": [\n",
    "            \"Bidirectional LSTM kullanma\",\n",
    "            \"Attention mechanism ekleme\",\n",
    "            \"Residual connections\",\n",
    "            \"Batch normalization optimizasyonu\"\n",
    "        ],\n",
    "        \"Eğitim İyileştirmeleri\": [\n",
    "            \"Learning rate scheduling\",\n",
    "            \"Gradient clipping\",\n",
    "            \"Warm-up strategies\",\n",
    "            \"Cyclical learning rates\"\n",
    "        ],\n",
    "        \"Ensemble Yöntemleri\": [\n",
    "            \"Farklı model mimarilerini birleştirme\",\n",
    "            \"Voting classifiers\",\n",
    "            \"Stacking\",\n",
    "            \"Bagging\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    print(\"\\n=== GELİŞMİŞ İYİLEŞTİRME ÖNERİLERİ ===\")\n",
    "    for category, items in suggestions.items():\n",
    "        print(f\"\\n{category}:\")\n",
    "        for item in items:\n",
    "            print(f\"  • {item}\")\n",
    "\n",
    "# Performans analizini çalıştır\n",
    "analyze_model_performance()\n",
    "get_improvement_suggestions()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL EĞİTİMİ VE DEĞERLENDİRMESİ TAMAMLANDI\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f66fac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "def pytorch_model_evaluation(model, val_loader, device):\n",
    "    \"\"\"\n",
    "    Evaluate PyTorch model on validation set and return accuracy.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    return correct / total\n",
    "\n",
    "def cross_validate_lstm(X, y, model_params, cv_folds=3, num_epochs=10):\n",
    "    \"\"\"\n",
    "    K-fold cross validation for PyTorch LSTM model\n",
    "    \"\"\"\n",
    "    skf = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "    cv_scores = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        print(f\"Training fold {fold + 1}/{cv_folds}\")\n",
    "        \n",
    "        X_fold_train, X_fold_val = X[train_idx], X[val_idx]\n",
    "        y_fold_train, y_fold_val = y[train_idx], y[val_idx]\n",
    "        \n",
    "        # Create sequence data for this fold\n",
    "        X_train_seq, y_train_tensor = create_sequence_data(X_fold_train, y_fold_train, sequence_length=5)\n",
    "        X_val_seq, y_val_tensor = create_sequence_data(X_fold_val, y_fold_val, sequence_length=5)\n",
    "        \n",
    "        # Create data loaders\n",
    "        train_dataset = TensorDataset(X_train_seq, y_train_tensor)\n",
    "        val_dataset = TensorDataset(X_val_seq, y_val_tensor)\n",
    "        \n",
    "        fold_train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "        fold_val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False)\n",
    "        \n",
    "        # Create and train model for this fold\n",
    "        fold_model = MusicGenreLSTM(**model_params).to(device)\n",
    "        fold_criterion = nn.CrossEntropyLoss()\n",
    "        fold_optimizer = optim.Adam(fold_model.parameters(), lr=0.001)\n",
    "        \n",
    "        # Train for fewer epochs in CV\n",
    "        for epoch in range(num_epochs):\n",
    "            fold_model.train()\n",
    "            for inputs, labels in fold_train_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                fold_optimizer.zero_grad()\n",
    "                outputs = fold_model(inputs)\n",
    "                loss = fold_criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                fold_optimizer.step()\n",
    "        \n",
    "        # Evaluate on validation set\n",
    "        accuracy = pytorch_model_evaluation(fold_model, fold_val_loader, device)\n",
    "        cv_scores.append(accuracy)\n",
    "        print(f\"Fold {fold + 1} accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    return np.mean(cv_scores), np.std(cv_scores)\n",
    "\n",
    "# Example usage for cross-validation (optional)\n",
    "if False:  # Set to True to run cross-validation\n",
    "    print(\"\\nPerforming cross-validation...\")\n",
    "    model_params = {\n",
    "        'input_size': X_train_seq.shape[2],\n",
    "        'hidden_size': 128,\n",
    "        'num_layers': 2,\n",
    "        'num_classes': len(le.classes_),\n",
    "        'dropout': 0.3\n",
    "    }\n",
    "    \n",
    "    cv_mean, cv_std = cross_validate_lstm(X_res, y_res, model_params)\n",
    "    print(f\"Cross-validation results: {cv_mean:.4f} (+/- {cv_std:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adafbaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "import itertools\n",
    "\n",
    "def train_and_evaluate_lstm(hidden_size, num_layers, dropout, learning_rate, X_train, y_train, X_val, y_val):\n",
    "    \"\"\"\n",
    "    Train and evaluate LSTM model with given hyperparameters.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create sequence data\n",
    "        X_train_seq, y_train_tensor = create_sequence_data(X_train, y_train, sequence_length=5)\n",
    "        X_val_seq, y_val_tensor = create_sequence_data(X_val, y_val, sequence_length=5)\n",
    "        \n",
    "        # Create data loaders\n",
    "        train_dataset = TensorDataset(X_train_seq, y_train_tensor)\n",
    "        val_dataset = TensorDataset(X_val_seq, y_val_tensor)\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False)\n",
    "        \n",
    "        # Create model\n",
    "        model_params = {\n",
    "            'input_size': X_train_seq.shape[2],\n",
    "            'hidden_size': hidden_size,\n",
    "            'num_layers': num_layers,\n",
    "            'num_classes': len(le.classes_),\n",
    "            'dropout': dropout\n",
    "        }\n",
    "        \n",
    "        tuning_model = MusicGenreLSTM(**model_params).to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(tuning_model.parameters(), lr=learning_rate)\n",
    "        \n",
    "        # Train for a limited number of epochs\n",
    "        num_epochs = 5\n",
    "        for epoch in range(num_epochs):\n",
    "            tuning_model.train()\n",
    "            for inputs, labels in train_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = tuning_model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "        # Evaluate\n",
    "        accuracy = pytorch_model_evaluation(tuning_model, val_loader, device)\n",
    "        return accuracy\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in hyperparameter tuning: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "def tune_hyperparameters_lstm(X_train, y_train, X_val, y_val):\n",
    "    \"\"\"\n",
    "    Grid search for optimal LSTM hyperparameters\n",
    "    \"\"\"\n",
    "    # Define parameter grid (reduced for faster execution)\n",
    "    param_grid = {\n",
    "        'hidden_size': [64, 128],\n",
    "        'num_layers': [2, 3],\n",
    "        'dropout': [0.3, 0.5],\n",
    "        'learning_rate': [0.001, 0.01]\n",
    "    }\n",
    "    \n",
    "    best_params = {}\n",
    "    best_score = 0\n",
    "    \n",
    "    print(\"Starting hyperparameter tuning...\")\n",
    "    \n",
    "    # Generate all combinations\n",
    "    keys = list(param_grid.keys())\n",
    "    values = list(param_grid.values())\n",
    "    \n",
    "    for i, combination in enumerate(itertools.product(*values)):\n",
    "        params = dict(zip(keys, combination))\n",
    "        print(f\"Testing combination {i+1}: {params}\")\n",
    "        \n",
    "        score = train_and_evaluate_lstm(\n",
    "            params['hidden_size'], \n",
    "            params['num_layers'], \n",
    "            params['dropout'],\n",
    "            params['learning_rate'],\n",
    "            X_train, y_train, X_val, y_val\n",
    "        )\n",
    "        \n",
    "        print(f\"Score: {score:.4f}\")\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_params = params.copy()\n",
    "    \n",
    "    return best_params, best_score\n",
    "\n",
    "# Example usage for hyperparameter tuning (optional)\n",
    "if False:  # Set to True to run hyperparameter tuning\n",
    "    print(\"\\nPerforming hyperparameter tuning...\")\n",
    "    best_params, best_score = tune_hyperparameters_lstm(X_res, y_res, X_val_clean, y_val_clean)\n",
    "    print(f\"\\nBest parameters: {best_params}\")\n",
    "    print(f\"Best score: {best_score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydebian (3.11.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
