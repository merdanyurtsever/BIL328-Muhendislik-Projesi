{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba68792d",
   "metadata": {},
   "source": [
    "# Müzik Türü Sınıflandırma Projesi:\n",
    "\n",
    "Bu notebook, FMA (Free Music Archive) veri setini kullanarak müzik türü sınıflandırma modeli geliştirmek için veri hazırlama ve dengeleme işlemlerini içermektedir.\n",
    "\n",
    "## Gerekli Kütüphanelerin İçe Aktarılması:\n",
    "\n",
    "Aşağıdaki hücrede, projede kullanılacak temel Python kütüphaneleri import edilmektedir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40af102",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from imblearn.over_sampling import RandomOverSampler, BorderlineSMOTE\n",
    "from collections import Counter\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(style='whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226d4b29",
   "metadata": {},
   "source": [
    "# Yardımcı Fonksiyonlar\n",
    "## Sınıf Dağılımı Görselleştirme Fonksiyonu\n",
    "Aşağıdaki fonksiyon, veri setindeki sınıf dağılımlarını görselleştirmek için kullanılacaktır. Bu görselleştirme, veri dengesizliğini anlamamıza yardımcı olur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c88248",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_class_distribution(y, labels, title):\n",
    "    counts = pd.Series(y).value_counts().sort_index()\n",
    "    valid_indices = counts.index[counts.index < len(labels)]\n",
    "    counts = counts.loc[valid_indices]\n",
    "    names = labels[counts.index]\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    ax = sns.barplot(x=names, y=counts.values, hue=names, palette='viridis', legend=False)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Sınıf')\n",
    "    ax.set_ylabel('Sayı')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fb5f4b",
   "metadata": {},
   "source": [
    "# Veri Yükleme ve Ön İşleme\n",
    "Bu bölümdeki fonksiyon:\n",
    "\n",
    "FMA metadata dosyalarını yükler\n",
    "Gerekli sütunları seçer\n",
    "Eksik verileri temizler\n",
    "Etiketleri kodlar\n",
    "Veriyi sayısal formata dönüştürür"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa01832",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    tracks_path = 'fma_metadata/tracks.csv'\n",
    "    features_path = 'fma_metadata/features.csv'\n",
    "\n",
    "    if not os.path.exists(tracks_path) or not os.path.exists(features_path):\n",
    "        raise FileNotFoundError(f\"Gerekli veri dosyaları bulunamadı. '{tracks_path}' ve '{features_path}' dosyalarının mevcut olduğundan emin olun.\")\n",
    "\n",
    "    tracks = pd.read_csv(tracks_path, index_col=0, header=[0,1])\n",
    "    \n",
    "    features = pd.read_csv(features_path, index_col=0, header=[0,1])  # Çok seviyeli başlıkla oku\n",
    "    features = features.loc[:, features.columns.get_level_values(0) != 'statistics']  # 'statistics' sütunlarını kaldır\n",
    "    features = features.astype(np.float32)  # Sayısal olmayan sütunları kaldırdıktan sonra float'a dönüştür\n",
    "\n",
    "    features.index = features.index.astype(str)\n",
    "    tracks.index = tracks.index.astype(str)\n",
    "\n",
    "    genre_series = tracks[('track', 'genre_top')].dropna()\n",
    "    common_index = features.index.intersection(genre_series.index)\n",
    "\n",
    "    X = features.loc[common_index]\n",
    "    y_labels = genre_series.loc[common_index]\n",
    "\n",
    "    X = X.fillna(0).replace([np.inf, -np.inf], 0).astype(np.float32)\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    y = label_encoder.fit_transform(y_labels)\n",
    "\n",
    "    print('Veriler yüklendi ve önişlendi.')\n",
    "    return X, y, label_encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fa339b",
   "metadata": {},
   "source": [
    "# Başlangıç Veri Analizi\n",
    "Verinin ilk yüklemesini yapıp, başlangıçtaki sınıf dağılımını inceleyelim. Bu analiz, veri dengesizliği problemini görselleştirmemize yardımcı olacak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05193f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veriyi yükle ve önişle\n",
    "X, y, le = load_data()\n",
    "\n",
    "# Başlangıç dağılımını göster\n",
    "plot_class_distribution(y, le.classes_, 'Başlangıç Sınıf Dağılımı')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69df28eb",
   "metadata": {},
   "source": [
    "# Veri Bölme ve Eğitim Seti Analizi\n",
    "Veriyi eğitim ve test setlerine ayırıp, eğitim setindeki sınıf dağılımını inceliyoruz. Stratified split kullanarak orijinal dağılımı koruyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9677606b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veriyi böl ve eğitim dağılımını göster\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "plot_class_distribution(y_train, le.classes_, 'Eğitim Seti Dağılımı')\n",
    "print(f'Eğitim/test bölünmesi tamamlandı: X_train {X_train.shape}, X_test {X_test.shape}')\n",
    "\n",
    "# Detaylı dağılımı yazdır\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "print(\"\\nEğitim Seti Dağılımı (ham sayılar):\")\n",
    "for i, (u, c) in enumerate(zip(unique, counts)):\n",
    "    print(f\"Sınıf {u} ({le.classes_[i]}): {c} örnek\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b6834d",
   "metadata": {},
   "source": [
    "# Veri Dengeleme - Aşama 1\n",
    "İlk aşamada, çok az örneğe sahip sınıflar için RandomOverSampler kullanılıyor. Bu aşama, BorderlineSMOTE için yeterli örnek sayısına ulaşmamızı sağlar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8a22ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adım 1: En az temsil edilen sınıflar için RandomOverSampler\n",
    "print('\\nAdım 1: Aşırı az temsil edilen sınıflar için RandomOverSampler uygulanıyor...')\n",
    "min_samples_threshold = 20  # BorderlineSMOTE için gereken minimum örnek sayısı\n",
    "ros = RandomOverSampler(sampling_strategy={3: min_samples_threshold}, random_state=42)\n",
    "X_partial, y_partial = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# Ara sonuçları göster\n",
    "unique_partial, counts_partial = np.unique(y_partial, return_counts=True)\n",
    "print(\"\\nRandomOverSampler sonrası dağılım (ham sayılar):\")\n",
    "for i, (u, c) in enumerate(zip(unique_partial, counts_partial)):\n",
    "    print(f\"Sınıf {u} ({le.classes_[i]}): {c} örnek\")\n",
    "\n",
    "plot_class_distribution(y_partial, le.classes_, 'RandomOverSampler Sonrası')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e09752",
   "metadata": {},
   "source": [
    "# Veri Dengeleme - Aşama 2\n",
    "İkinci aşamada, daha sofistike bir yaklaşım olan BorderlineSMOTE kullanılarak kalan sınıflar dengeleniyor. Bu yöntem, sadece rastgele kopyalama yerine sentetik örnekler oluşturur.\n",
    "\n",
    "Not: Bu aşama, veri setinin yapısına bağlı olarak başarısız olabilir. Bu durumda, ilk aşamadaki sonuçlar kullanılacaktır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a24646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adım 2: Kalan sınıflar için BorderlineSMOTE\n",
    "print('\\nAdım 2: Kalan sınıflar için BorderlineSMOTE uygulanıyor...')\n",
    "borderline_smote = BorderlineSMOTE(random_state=42)\n",
    "\n",
    "try:\n",
    "    X_res, y_res = borderline_smote.fit_resample(X_partial, y_partial)\n",
    "    print(f'Kombine örnekleme tamamlandı: X_res {X_res.shape}, y_res {y_res.shape}')\n",
    "    \n",
    "    # Son dağılımı yazdır ve göster\n",
    "    unique_res, counts_res = np.unique(y_res, return_counts=True)\n",
    "    print(\"\\nSon Dağılım (ham sayılar):\")\n",
    "    for i, (u, c) in enumerate(zip(unique_res, counts_res)):\n",
    "        print(f\"Sınıf {u} ({le.classes_[i]}): {c} örnek\")\n",
    "    \n",
    "    plot_class_distribution(y_res, le.classes_, 'Son Dengelenmiş Dağılım')\n",
    "\n",
    "except Exception as e:\n",
    "    print(f'BorderlineSMOTE örnekleme başarısız oldu: {e} - kısmi örneklenmiş veri kullanılıyor')\n",
    "    X_res, y_res = X_partial, y_partial\n",
    "    plot_class_distribution(y_res, le.classes_, 'Kısmi Örnekleme (BorderlineSMOTE başarısız)')\n",
    "\n",
    "print(\"\\nİşlem hattı tamamlandı. Yeniden örneklenmiş eğitim verisi (X_res, y_res) ve test verisi (X_test, y_test) hazır.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5628ff20",
   "metadata": {},
   "source": [
    "# Özellik Seçimi (K-Best Feature Selection)\n",
    "Model performansını artırmak ve aşırı öğrenmeyi (overfitting) azaltmak için K-Best özellik seçimi algoritmasını uygulayacağız. Bu algoritma, her özelliğin hedef değişkenle olan istatistiksel ilişkisini ölçer ve en anlamlı K özelliği seçer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db7e8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Best özellik seçimi uygulaması\n",
    "print('\\nK-Best özellik seçimi uygulanıyor...')\n",
    "\n",
    "k = 250  # Seçilecek özellik sayısı\n",
    "print(f\"Toplam özellik sayısı: {X_res.shape[1]}, Seçilecek özellik sayısı: {k}\")\n",
    "\n",
    "# SelectKBest ile özellik seçimi\n",
    "selector = SelectKBest(score_func=f_classif, k=k)\n",
    "X_res_selected = selector.fit_transform(X_res, y_res)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "# Hangi özelliklerin seçildiğini gösteren görselleştirme\n",
    "selected_mask = selector.get_support()\n",
    "scores = selector.scores_\n",
    "feature_indices = np.arange(len(selected_mask))\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(feature_indices, scores, alpha=0.3, color='g')\n",
    "plt.bar(feature_indices[selected_mask], scores[selected_mask], color='g')\n",
    "plt.title('Özellik Skorları ve Seçilen Özellikler')\n",
    "plt.xlabel('Özellik İndeksi')\n",
    "plt.ylabel('F-değeri (F-value)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Özellik seçimi tamamlandı. Seçilen özelliklerin boyutu: {X_res_selected.shape}\")\n",
    "\n",
    "# Orijinal veriyi güncellenmiş veri ile değiştirelim\n",
    "X_res = X_res_selected\n",
    "X_test = X_test_selected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91aecbc1",
   "metadata": {},
   "source": [
    "# PyTorch LSTM MODEL EĞİTİMİ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed38cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dengelenmiş veri setinden doğrulama seti ayır\n",
    "X_train_bal, X_val, y_train_bal, y_val = train_test_split(\n",
    "    X_res, y_res, test_size=0.1, stratify=y_res, random_state=42\n",
    ")\n",
    "\n",
    "# Veri Ölçeklendirme (StandardScaler)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_bal)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Veri ölçeklendirme tamamlandı.\")\n",
    "print(f\"Ölçeklenmiş eğitim verisi boyutu: {X_train_scaled.shape}\")\n",
    "print(f\"Ölçeklenmiş doğrulama verisi boyutu: {X_val_scaled.shape}\")\n",
    "print(f\"Ölçeklenmiş test verisi boyutu: {X_test_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7d2a55",
   "metadata": {},
   "source": [
    "# LSTM Modeli için Veri Hazırlığı\n",
    "PyTorch LSTM modeli için, veriyi uygun formata dönüştürmemiz gerekir. LSTM modeller sıralı veri bekler, bu nedenle öznitelik vektörünü zamansal bir diziye dönüştüreceğiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7637d1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch tensörlerine dönüştürme ve veri setlerini hazırlama\n",
    "def create_sequence_data(X, y, sequence_length=10):\n",
    "    \"\"\"\n",
    "    Öznitelik vektörünü sıralı verilere dönüştürür.\n",
    "    FMA veri seti sıralı yapıda değil, bu nedenle yapay bir sıra oluşturuyoruz.\n",
    "    \"\"\"\n",
    "    # Veri boyutlarını kontrol et\n",
    "    n_samples, n_features = X.shape\n",
    "    \n",
    "    # Veriyi yeniden şekillendirme\n",
    "    features_per_timestep = n_features // sequence_length\n",
    "    \n",
    "    if features_per_timestep == 0:\n",
    "        features_per_timestep = 1\n",
    "        sequence_length = min(sequence_length, n_features)\n",
    "    \n",
    "    # Son timestep'e sığmayan özellikleri ele alma\n",
    "    remainder = n_features - (sequence_length * features_per_timestep)\n",
    "    \n",
    "    # Yeniden şekillendirilmiş veri için array oluşturma\n",
    "    X_seq = np.zeros((n_samples, sequence_length, features_per_timestep))\n",
    "    \n",
    "    # Veriyi yeniden şekillendirme\n",
    "    for i in range(n_samples):\n",
    "        for t in range(sequence_length):\n",
    "            start_idx = t * features_per_timestep\n",
    "            end_idx = min(start_idx + features_per_timestep, n_features)\n",
    "            \n",
    "            if start_idx < n_features:\n",
    "                X_seq[i, t, :end_idx-start_idx] = X[i, start_idx:end_idx]\n",
    "    \n",
    "    # PyTorch tensörlerine dönüştürme\n",
    "    X_tensor = torch.FloatTensor(X_seq)\n",
    "    y_tensor = torch.LongTensor(y)\n",
    "    \n",
    "    return X_tensor, y_tensor\n",
    "\n",
    "# Sıralı veri için hiperparametre\n",
    "sequence_length = 5\n",
    "\n",
    "# Ölçeklenmiş verileri sıralı forma dönüştürme\n",
    "X_train_seq, y_train_tensor = create_sequence_data(X_train_scaled, y_train_bal, sequence_length)\n",
    "X_val_seq, y_val_tensor = create_sequence_data(X_val_scaled, y_val, sequence_length)\n",
    "X_test_seq, y_test_tensor = create_sequence_data(X_test_scaled, y_test, sequence_length)\n",
    "\n",
    "print(f\"Eğitim veri boyutu: {X_train_seq.shape}\")\n",
    "print(f\"Doğrulama veri boyutu: {X_val_seq.shape}\")\n",
    "print(f\"Test veri boyutu: {X_test_seq.shape}\")\n",
    "\n",
    "# PyTorch DataLoader oluşturma\n",
    "batch_size = 512\n",
    "train_dataset = TensorDataset(X_train_seq, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_seq, y_val_tensor)\n",
    "test_dataset = TensorDataset(X_test_seq, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062aadbb",
   "metadata": {},
   "source": [
    "# LSTM Model Tanımı ve Eğitimi\n",
    "Aşağıda müzik türü sınıflandırması için bir LSTM (Long Short-Term Memory) ağı tanımlıyoruz. LSTM'ler, müzik gibi sıralı verilerde başarılı olan bir derin öğrenme mimarisidir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a708d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM model sınıfını tanımlama\n",
    "class MusicGenreLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, dropout=0.3):\n",
    "        super(MusicGenreLSTM, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # LSTM katmanları\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size, \n",
    "            hidden_size=hidden_size, \n",
    "            num_layers=num_layers, \n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0\n",
    "        )\n",
    "        \n",
    "        # Batch normalization\n",
    "        self.batch_norm = nn.BatchNorm1d(hidden_size)\n",
    "        \n",
    "        # Dropout katmanı\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Tam bağlantılı katmanlar\n",
    "        self.fc1 = nn.Linear(hidden_size, 128)  # İlk tam bağlantılı katman\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        \n",
    "        # Aktivasyon fonksiyonları\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # LSTM katmanından geçirme\n",
    "        # x şekli: (batch_size, sequence_length, input_size)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        \n",
    "        # Son zaman adımının çıktısını al\n",
    "        # lstm_out şekli: (batch_size, sequence_length, hidden_size)\n",
    "        lstm_out = lstm_out[:, -1, :]\n",
    "        \n",
    "        # Batch normalization\n",
    "        batch_norm_out = self.batch_norm(lstm_out)\n",
    "        \n",
    "        # İlk tam bağlantılı katman\n",
    "        fc1_out = self.fc1(batch_norm_out)\n",
    "        fc1_out = self.relu(fc1_out)\n",
    "        fc1_out = self.dropout(fc1_out)\n",
    "        \n",
    "        # İkinci tam bağlantılı katman (çıkış katmanı)\n",
    "        out = self.fc2(fc1_out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "# Model parametreleri\n",
    "input_size = X_train_seq.shape[2]  # Bir zaman adımındaki özellik sayısı\n",
    "hidden_size = 128  # LSTM gizli katman boyutu\n",
    "num_layers = 2  # LSTM katman sayısı\n",
    "num_classes = len(le.classes_)  # Sınıf sayısı\n",
    "dropout = 0.3\n",
    "\n",
    "# GPU kullanılabilir mi kontrol et\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Kullanılan cihaz: {device}\")\n",
    "\n",
    "# Model oluşturma\n",
    "model = MusicGenreLSTM(input_size, hidden_size, num_layers, num_classes, dropout).to(device)\n",
    "print(model)\n",
    "\n",
    "# Kayıp fonksiyonu ve optimize edici tanımlama\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "\n",
    "# Eğitim fonksiyonu\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=50, early_stopping_patience=5, min_improvement_threshold=0.001):\n",
    "    # Ölçüm değerlerini saklayacak listeler\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "    \n",
    "    # En iyi doğrulama kaybını ve modeli saklama\n",
    "    # min_improvement_threshold: Doğrulama kaybındaki minimum iyileşme eşiği, \n",
    "    # bunun altındaki iyileşmeler anlamlı kabul edilmez ve erken durdurma sayacı sıfırlanmaz.\n",
    "    best_val_loss = float('inf')\n",
    "    best_model = None\n",
    "    \n",
    "    # Erken durdurma için sayaç ve sabır parametresi\n",
    "    early_stopping_counter = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Eğitim modu\n",
    "        model.train()\n",
    "        \n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Gradyanları sıfırla\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # İleri geçiş\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Geri yayılım ve optimize etme\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # İstatistikleri güncelle\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Doğrulama modu\n",
    "        model.eval()\n",
    "        \n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                \n",
    "                # İleri geçiş\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                # İstatistikleri güncelle\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Epoch sonuçlarını hesapla\n",
    "        epoch_train_loss = train_loss / len(train_loader.dataset)\n",
    "        epoch_val_loss = val_loss / len(val_loader.dataset)\n",
    "        epoch_train_acc = train_correct / train_total\n",
    "        epoch_val_acc = val_correct / val_total\n",
    "        \n",
    "        # Öğrenme oranını ayarla\n",
    "        scheduler.step(epoch_val_loss)\n",
    "        \n",
    "        # Sonuçları sakla\n",
    "        train_losses.append(epoch_train_loss)\n",
    "        val_losses.append(epoch_val_loss)\n",
    "        train_accs.append(epoch_train_acc)\n",
    "        val_accs.append(epoch_val_acc)\n",
    "        \n",
    "        # Eğitim durumunu yazdır\n",
    "        print(f'Epoch {epoch+1}/{num_epochs} - '\n",
    "              f'Train Loss: {epoch_train_loss:.4f}, Train Acc: {epoch_train_acc:.4f}, '\n",
    "              f'Val Loss: {epoch_val_loss:.4f}, Val Acc: {epoch_val_acc:.4f}')\n",
    "        \n",
    "        # En iyi modeli sakla ve erken durdurma durumunu kontrol et\n",
    "        # Doğrulama kaybındaki iyileşme miktarını hesapla\n",
    "        improvement = best_val_loss - epoch_val_loss\n",
    "        \n",
    "        if epoch_val_loss < best_val_loss:\n",
    "            # Eğer iyileşme miktarı eşik değerinden fazlaysa sayacı sıfırla\n",
    "            if improvement > min_improvement_threshold:\n",
    "                early_stopping_counter = 0  # Counter sıfırla\n",
    "                print(f'Validation loss improved by {improvement:.6f}, which is above threshold ({min_improvement_threshold:.6f})')\n",
    "            else:\n",
    "                # İyileşme var ama eşik değerinin altında, bu durumda counter'ı artırıyoruz\n",
    "                early_stopping_counter += 1\n",
    "                print(f'Validation loss improved by only {improvement:.6f}, which is below threshold ({min_improvement_threshold:.6f})')\n",
    "            \n",
    "            # En iyi modeli ve validation loss değerini her durumda güncelle\n",
    "            best_val_loss = epoch_val_loss\n",
    "            best_model = model.state_dict()\n",
    "        else:\n",
    "            early_stopping_counter += 1  # Counter artır\n",
    "            \n",
    "        # Erken durdurma kontrolü\n",
    "        if early_stopping_counter >= early_stopping_patience:\n",
    "            print(f'Erken durdurma: Validation loss {early_stopping_patience} epoch boyunca yeterince iyileşmedi (minimum eşik: {min_improvement_threshold:.6f}).')\n",
    "            break\n",
    "    \n",
    "    # En iyi model ağırlıklarını yükle\n",
    "    model.load_state_dict(best_model)\n",
    "    \n",
    "    return model, train_losses, val_losses, train_accs, val_accs\n",
    "\n",
    "# Modeli eğit\n",
    "print(\"Model eğitimi başlıyor...\")\n",
    "num_epochs = 50\n",
    "early_stopping_patience = 3  # Model belirli bir eşik değerinden fazla iyileşmezse, bu sayıda epoch sonra eğitimi durdur\n",
    "\n",
    "try:\n",
    "    # Doğrulama kaybında 0.02 altındaki iyileşmeleri önemsiz olarak kabul et\n",
    "    min_improvement_threshold = 0.02  \n",
    "    \n",
    "    model, train_losses, val_losses, train_accs, val_accs = train_model(\n",
    "        model, train_loader, val_loader, criterion, optimizer, scheduler, \n",
    "        num_epochs=num_epochs, early_stopping_patience=early_stopping_patience,\n",
    "        min_improvement_threshold=min_improvement_threshold\n",
    "    )\n",
    "    print(\"Model eğitimi tamamlandı!\")\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Eğitim kullanıcı tarafından durduruldu.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207afc45",
   "metadata": {},
   "source": [
    "# Model Değerlendirmesi ve Görselleştirme\n",
    "Bu bölümde eğitilmiş modeli test veri seti üzerinde değerlendirip, sonuçları görselleştireceğiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5108decf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eğitim sonuçlarını görselleştirme\n",
    "def plot_training_history(train_losses, val_losses, train_accs, val_accs):\n",
    "    plt.figure(figsize=(14, 5))\n",
    "    \n",
    "    # Kayıp grafiği\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Eğitim', marker='o')\n",
    "    plt.plot(val_losses, label='Doğrulama', marker='*')\n",
    "    plt.title('Model Kaybı')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Kayıp (Cross-Entropy)')\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    \n",
    "    # Doğruluk grafiği\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_accs, label='Eğitim', marker='o')\n",
    "    plt.plot(val_accs, label='Doğrulama', marker='*')\n",
    "    plt.title('Model Doğruluğu')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Doğruluk')\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Eğitim sonuçlarını görselleştir\n",
    "try:\n",
    "    plot_training_history(train_losses, val_losses, train_accs, val_accs)\n",
    "except NameError:\n",
    "    print(\"Eğitim geçmişi bulunamadı. Önce modeli eğitin.\")\n",
    "\n",
    "# Test veri seti üzerinde değerlendirme\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    \n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "    \n",
    "    # Doğruluk hesapla\n",
    "    accuracy = np.mean(np.array(y_true) == np.array(y_pred))\n",
    "    \n",
    "    # Sonuçları yazdır\n",
    "    print(f\"Test Doğruluğu: {accuracy:.4f}\")\n",
    "    \n",
    "    # Sınıflandırma raporu\n",
    "    print(\"\\nSınıflandırma Raporu:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=le.classes_))\n",
    "    \n",
    "    # Karmaşıklık matrisi\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "    plt.title('Karmaşıklık Matrisi')\n",
    "    plt.xlabel('Tahmin Edilen Etiketler')\n",
    "    plt.ylabel('Gerçek Etiketler')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return y_true, y_pred\n",
    "\n",
    "# Test veri seti üzerinde değerlendir\n",
    "try:\n",
    "    y_true, y_pred = evaluate_model(model, test_loader, device)\n",
    "except NameError:\n",
    "    print(\"Model bulunamadı. Önce modeli eğitin.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5894637c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve Analysis for Multiclass Classification\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from itertools import cycle\n",
    "\n",
    "def plot_multiclass_roc_curve(model, test_loader, device, label_encoder, title=\"ROC Curves\"):\n",
    "    \"\"\"Plot ROC curves for multiclass classification\"\"\"\n",
    "    model.eval()\n",
    "    all_predictions_proba = []\n",
    "    all_true_labels = []\n",
    "    \n",
    "    # Get prediction probabilities\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            # Apply softmax to get probabilities\n",
    "            proba = torch.softmax(outputs, dim=1)\n",
    "            all_predictions_proba.extend(proba.cpu().numpy())\n",
    "            all_true_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    y_true = np.array(all_true_labels)\n",
    "    y_proba = np.array(all_predictions_proba)\n",
    "    n_classes = len(label_encoder.classes_)\n",
    "    \n",
    "    # Binarize the labels for multiclass ROC\n",
    "    y_true_bin = label_binarize(y_true, classes=range(n_classes))\n",
    "    \n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    \n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_proba[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    \n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_true_bin.ravel(), y_proba.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "    \n",
    "    # Plot ROC curves\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Plot micro-average ROC curve\n",
    "    plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "             label=f'Micro-average ROC (AUC = {roc_auc[\"micro\"]:.3f})',\n",
    "             color='deeppink', linestyle=':', linewidth=4)\n",
    "    \n",
    "    # Plot ROC curve for each class\n",
    "    colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'red', 'green', 'purple', 'brown', 'pink'])\n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        plt.plot(fpr[i], tpr[i], color=color, linewidth=2,\n",
    "                 label=f'{label_encoder.classes_[i]} (AUC = {roc_auc[i]:.3f})')\n",
    "    \n",
    "    # Plot random classifier line\n",
    "    plt.plot([0, 1], [0, 1], 'k--', linewidth=2, label='Random Classifier')\n",
    "    \n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate', fontsize=12)\n",
    "    plt.ylabel('True Positive Rate', fontsize=12)\n",
    "    plt.title(f'{title} - Multiclass ROC Curves', fontsize=14, fontweight='bold')\n",
    "    plt.legend(loc=\"lower right\", fontsize=10)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print AUC summary\n",
    "    print(f\"\\n📊 ROC AUC Scores:\")\n",
    "    print(f\"{'Genre':<15} {'AUC Score':<10}\")\n",
    "    print(f\"{'='*25}\")\n",
    "    for i, genre in enumerate(label_encoder.classes_):\n",
    "        print(f\"{genre:<15} {roc_auc[i]:<10.3f}\")\n",
    "    print(f\"{'='*25}\")\n",
    "    print(f\"{'Micro-Average':<15} {roc_auc['micro']:<10.3f}\")\n",
    "    \n",
    "    return roc_auc\n",
    "\n",
    "# Plot ROC curves for the LSTM model\n",
    "print(\"\\n🎭 Generating ROC Curves for Multiclass Classification...\")\n",
    "roc_scores = plot_multiclass_roc_curve(model, test_loader, device, le, \n",
    "                                      \"LSTM Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec05adf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, f1_score\n",
    "\n",
    "def plot_f1_scores_by_genre(y_true, y_pred, class_names, title=\"F1 Scores by Genre\"):\n",
    "    \"\"\"Plot F1 scores for each genre with detailed visualization\"\"\"\n",
    "    \n",
    "    # Calculate F1 scores for each class\n",
    "    precision, recall, f1_scores, support = precision_recall_fscore_support(y_true, y_pred, average=None)\n",
    "    \n",
    "    # Calculate macro and weighted averages\n",
    "    f1_macro = f1_score(y_true, y_pred, average='macro')\n",
    "    f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
    "    \n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    # Create bar plot\n",
    "    x_pos = np.arange(len(class_names))\n",
    "    bars = plt.bar(x_pos, f1_scores, alpha=0.8, \n",
    "                   color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', \n",
    "                         '#8c564b', '#e377c2', '#7f7f7f'][:len(class_names)])\n",
    "    \n",
    "    # Customize the plot\n",
    "    plt.xlabel('Music Genres', fontsize=12, fontweight='bold')\n",
    "    plt.ylabel('F1 Score', fontsize=12, fontweight='bold')\n",
    "    plt.title(f'{title}\\nMacro Avg: {f1_macro:.3f} | Weighted Avg: {f1_weighted:.3f}', \n",
    "              fontsize=14, fontweight='bold')\n",
    "    plt.xticks(x_pos, class_names, rotation=45, ha='right')\n",
    "    plt.ylim(0, 1.0)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, (bar, score, support_count) in enumerate(zip(bars, f1_scores, support)):\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                f'{score:.3f}\\n(n={support_count})',\n",
    "                ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    # Add horizontal lines for averages\n",
    "    plt.axhline(y=f1_macro, color='red', linestyle='--', alpha=0.7, \n",
    "                label=f'Macro Average: {f1_macro:.3f}')\n",
    "    plt.axhline(y=f1_weighted, color='orange', linestyle='--', alpha=0.7, \n",
    "                label=f'Weighted Average: {f1_weighted:.3f}')\n",
    "    \n",
    "    # Add legend and grid\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.grid(True, alpha=0.3, axis='y')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print detailed F1 score analysis\n",
    "    print(f\"\\n📊 F1 Score Analysis by Genre:\")\n",
    "    print(f\"{'Genre':<15} {'F1 Score':<10} {'Precision':<10} {'Recall':<10} {'Support':<10}\")\n",
    "    print(f\"{'='*65}\")\n",
    "    \n",
    "    for i, genre in enumerate(class_names):\n",
    "        print(f\"{genre:<15} {f1_scores[i]:<10.3f} {precision[i]:<10.3f} {recall[i]:<10.3f} {support[i]:<10}\")\n",
    "    \n",
    "    print(f\"{'='*65}\")\n",
    "    print(f\"{'Macro Avg':<15} {f1_macro:<10.3f} {np.mean(precision):<10.3f} {np.mean(recall):<10.3f} {np.sum(support):<10}\")\n",
    "    print(f\"{'Weighted Avg':<15} {f1_weighted:<10.3f} {np.average(precision, weights=support):<10.3f} {np.average(recall, weights=support):<10.3f} {np.sum(support):<10}\")\n",
    "    \n",
    "    # Identify best and worst performing genres\n",
    "    best_genre_idx = np.argmax(f1_scores)\n",
    "    worst_genre_idx = np.argmin(f1_scores)\n",
    "    \n",
    "    print(f\"\\n🏆 Best Performing Genre: {class_names[best_genre_idx]} (F1: {f1_scores[best_genre_idx]:.3f})\")\n",
    "    print(f\"🔍 Needs Improvement: {class_names[worst_genre_idx]} (F1: {f1_scores[worst_genre_idx]:.3f})\")\n",
    "    \n",
    "    # Performance categories\n",
    "    excellent_genres = [class_names[i] for i, score in enumerate(f1_scores) if score >= 0.8]\n",
    "    good_genres = [class_names[i] for i, score in enumerate(f1_scores) if 0.6 <= score < 0.8]\n",
    "    poor_genres = [class_names[i] for i, score in enumerate(f1_scores) if score < 0.6]\n",
    "    \n",
    "    print(f\"\\n📈 Performance Categories:\")\n",
    "    if excellent_genres:\n",
    "        print(f\"   🟢 Excellent (≥0.8): {', '.join(excellent_genres)}\")\n",
    "    if good_genres:\n",
    "        print(f\"   🟡 Good (0.6-0.8): {', '.join(good_genres)}\")\n",
    "    if poor_genres:\n",
    "        print(f\"   🔴 Needs Work (<0.6): {', '.join(poor_genres)}\")\n",
    "    \n",
    "    return f1_scores, f1_macro, f1_weighted\n",
    "\n",
    "# Plot F1 scores for the LSTM model\n",
    "print(\"\\n📊 Generating F1 Score Analysis for Each Genre...\")\n",
    "f1_individual, f1_macro_score, f1_weighted_score = plot_f1_scores_by_genre(\n",
    "    y_true, y_pred, le.classes_, \n",
    "    \"LSTM Model - F1 Scores by Genre\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydebian (3.11.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
