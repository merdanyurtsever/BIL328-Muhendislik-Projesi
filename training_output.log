🎵 Müzik Türü Sınıflandırma Projesi Başlatılıyor...
Kullanılan cihaz: cuda

📂 Adım 1: Veri yükleme...
Veriler yüklendi ve önişlendi.
Veri yüklendi: 49598 örnek, 518 özellik
Sınıf sayısı: 16
Sınıflar: ['Blues', 'Classical', 'Country', 'Easy Listening', 'Electronic', 'Experimental', 'Folk', 'Hip-Hop', 'Instrumental', 'International', 'Jazz', 'Old-Time / Historic', 'Pop', 'Rock', 'Soul-RnB', 'Spoken']

🔄 Adım 2: Veri setini bölme...
Eğitim seti: 29758 örnek
Doğrulama seti: 9920 örnek
Test seti: 9920 örnek

⚖️ Adım 3: Veri dengeleme...
Adım 1: Aşırı az temsil edilen sınıflar için RandomOverSampler uygulanıyor...
RandomOverSampler sonrası dağılım (ham sayılar):
Sınıf 0: 66 örnek
Sınıf 1: 738 örnek
Sınıf 2: 116 örnek
Sınıf 3: 20 örnek
Sınıf 4: 5623 örnek
Sınıf 5: 6365 örnek
Sınıf 6: 1682 örnek
Sınıf 7: 2131 örnek
Sınıf 8: 1247 örnek
Sınıf 9: 833 örnek
Sınıf 10: 343 örnek
Sınıf 11: 332 örnek
Sınıf 12: 1399 örnek
Sınıf 13: 8509 örnek
Sınıf 14: 105 örnek
Sınıf 15: 254 örnek
Adım 2: Kalan sınıflar için BorderlineSMOTE uygulanıyor...
Kombine örnekleme tamamlandı: X_res (136144, 518), y_res (136144,)
Son Dağılım (ham sayılar):
Sınıf 0: 8509 örnek
Sınıf 1: 8509 örnek
Sınıf 2: 8509 örnek
Sınıf 3: 8509 örnek
Sınıf 4: 8509 örnek
Sınıf 5: 8509 örnek
Sınıf 6: 8509 örnek
Sınıf 7: 8509 örnek
Sınıf 8: 8509 örnek
Sınıf 9: 8509 örnek
Sınıf 10: 8509 örnek
Sınıf 11: 8509 örnek
Sınıf 12: 8509 örnek
Sınıf 13: 8509 örnek
Sınıf 14: 8509 örnek
Sınıf 15: 8509 örnek

🎯 Adım 5: Özellik seçimi...
K-Best özellik seçimi uygulanıyor...
Toplam özellik sayısı: 518, Seçilecek özellik sayısı: 250
Özellik seçimi tamamlandı. Seçilen özelliklerin boyutu: (136144, 250)

🎵 Adım 6: Gelişmiş temporal özellik mühendisliği...
   🔄 Eğitim verisi için temporal özellikler oluşturuluyor...
🎵 Gelişmiş temporal özellik mühendisliği başlatılıyor...
   📊 İşleniyor: chroma_cens (temporal boyut: 12)
      ✓ Shape: (136144, 12, 7) (samples, seq_len=12, features=7)
      ✓ Found 18 feature columns
   📊 İşleniyor: chroma_cqt (temporal boyut: 12)
      ✓ Shape: (136144, 12, 7) (samples, seq_len=12, features=7)
      ✓ Found 9 feature columns
   📊 İşleniyor: chroma_stft (temporal boyut: 12)
      ✓ Shape: (136144, 12, 7) (samples, seq_len=12, features=7)
      ✓ Found 38 feature columns
   📊 İşleniyor: mfcc (temporal boyut: 20)
      ✓ Shape: (136144, 20, 7) (samples, seq_len=20, features=7)
      ✓ Found 103 feature columns
   📊 İşleniyor: spectral_contrast (temporal boyut: 7)
      ✓ Shape: (136144, 7, 7) (samples, seq_len=7, features=7)
      ✓ Found 37 feature columns
   📊 İşleniyor: tonnetz (temporal boyut: 6)
      ✓ Shape: (136144, 6, 7) (samples, seq_len=6, features=7)
      ✓ Found 20 feature columns
   📊 Skaler özellikler: 25 özellik
      ✓ Features: ['rmse_max', 'rmse_mean', 'rmse_median', 'rmse_skew', 'rmse_std']...
✅ Temporal özellik mühendisliği tamamlandı!
   🎯 Temporal özellik türleri: 6
   🎯 Toplam temporal özellik: 483
   🎯 Skaler özellikler: 25
   🔄 Doğrulama verisi için temporal özellikler oluşturuluyor...
🎵 Gelişmiş temporal özellik mühendisliği başlatılıyor...
   📊 İşleniyor: chroma_cens (temporal boyut: 12)
      ✓ Shape: (9920, 12, 7) (samples, seq_len=12, features=7)
      ✓ Found 18 feature columns
   📊 İşleniyor: chroma_cqt (temporal boyut: 12)
      ✓ Shape: (9920, 12, 7) (samples, seq_len=12, features=7)
      ✓ Found 9 feature columns
   📊 İşleniyor: chroma_stft (temporal boyut: 12)
      ✓ Shape: (9920, 12, 7) (samples, seq_len=12, features=7)
      ✓ Found 38 feature columns
   📊 İşleniyor: mfcc (temporal boyut: 20)
      ✓ Shape: (9920, 20, 7) (samples, seq_len=20, features=7)
      ✓ Found 103 feature columns
   📊 İşleniyor: spectral_contrast (temporal boyut: 7)
      ✓ Shape: (9920, 7, 7) (samples, seq_len=7, features=7)
      ✓ Found 37 feature columns
   📊 İşleniyor: tonnetz (temporal boyut: 6)
      ✓ Shape: (9920, 6, 7) (samples, seq_len=6, features=7)
      ✓ Found 20 feature columns
   📊 Skaler özellikler: 25 özellik
      ✓ Features: ['rmse_max', 'rmse_mean', 'rmse_median', 'rmse_skew', 'rmse_std']...
✅ Temporal özellik mühendisliği tamamlandı!
   🎯 Temporal özellik türleri: 6
   🎯 Toplam temporal özellik: 483
   🎯 Skaler özellikler: 25
   🔄 Test verisi için temporal özellikler oluşturuluyor...
🎵 Gelişmiş temporal özellik mühendisliği başlatılıyor...
   📊 İşleniyor: chroma_cens (temporal boyut: 12)
      ✓ Shape: (9920, 12, 7) (samples, seq_len=12, features=7)
      ✓ Found 18 feature columns
   📊 İşleniyor: chroma_cqt (temporal boyut: 12)
      ✓ Shape: (9920, 12, 7) (samples, seq_len=12, features=7)
      ✓ Found 9 feature columns
   📊 İşleniyor: chroma_stft (temporal boyut: 12)
      ✓ Shape: (9920, 12, 7) (samples, seq_len=12, features=7)
      ✓ Found 38 feature columns
   📊 İşleniyor: mfcc (temporal boyut: 20)
      ✓ Shape: (9920, 20, 7) (samples, seq_len=20, features=7)
      ✓ Found 103 feature columns
   📊 İşleniyor: spectral_contrast (temporal boyut: 7)
      ✓ Shape: (9920, 7, 7) (samples, seq_len=7, features=7)
      ✓ Found 37 feature columns
   📊 İşleniyor: tonnetz (temporal boyut: 6)
      ✓ Shape: (9920, 6, 7) (samples, seq_len=6, features=7)
      ✓ Found 20 feature columns
   📊 Skaler özellikler: 25 özellik
      ✓ Features: ['rmse_max', 'rmse_mean', 'rmse_median', 'rmse_skew', 'rmse_std']...
✅ Temporal özellik mühendisliği tamamlandı!
   🎯 Temporal özellik türleri: 6
   🎯 Toplam temporal özellik: 483
   🎯 Skaler özellikler: 25
✅ Temporal özellik mühendisliği tamamlandı!
   🎯 Temporal özellik türleri: 6
   🎯 Toplam temporal özellik: 483

🧠 Adım 7: Gelişmiş LSTM model oluşturma...
Model parametreleri:
  - Temporal feature types: 6
  - Hidden size: 128
  - Num layers: 2
  - Num classes: 16
  - Dropout: 0.3
  - Total parameters: 1,483,152

🏋️ Adım 8: Gelişmiş model eğitimi başlatılıyor...
🔧 Using FIXED temporal model training...
📱 Using device: cuda
🚀 Fixed temporal model training started...
📊 Train batches: 531, Val batches: 39

📅 Epoch 1/50
    Batch 0/531, Loss: 2.7885
    Batch 50/531, Loss: 1.7299
    Batch 100/531, Loss: 1.3613
    Batch 150/531, Loss: 1.2055
    Batch 200/531, Loss: 1.2391
    Batch 250/531, Loss: 1.1613
    Batch 300/531, Loss: 1.0299
    Batch 350/531, Loss: 1.0077
    Batch 400/531, Loss: 1.0335
    Batch 450/531, Loss: 0.9499
    Batch 500/531, Loss: 0.7691
✅ Training complete - Avg Loss: 1.1865
✅ Validation complete - Loss: 1.9012, Accuracy: 37.84%
🎯 New best validation loss: 1.9012 (improvement: inf)

📅 Epoch 2/50
    Batch 0/531, Loss: 0.8765
    Batch 50/531, Loss: 0.9696
    Batch 100/531, Loss: 0.7954
    Batch 150/531, Loss: 0.7735
    Batch 200/531, Loss: 0.8887
    Batch 250/531, Loss: 0.7806
    Batch 300/531, Loss: 0.7597
    Batch 350/531, Loss: 0.8912
    Batch 400/531, Loss: 0.7936
    Batch 450/531, Loss: 0.7556
    Batch 500/531, Loss: 0.9467
✅ Training complete - Avg Loss: 0.8008
✅ Validation complete - Loss: 1.9119, Accuracy: 36.94%
⏰ No improvement for 1 epochs

📅 Epoch 3/50
    Batch 0/531, Loss: 0.8383
    Batch 50/531, Loss: 0.6564
    Batch 100/531, Loss: 0.8174
    Batch 150/531, Loss: 0.5940
    Batch 200/531, Loss: 0.8572
    Batch 250/531, Loss: 0.7999
    Batch 300/531, Loss: 0.7989
    Batch 350/531, Loss: 0.7292
    Batch 400/531, Loss: 0.6808
    Batch 450/531, Loss: 0.6616
    Batch 500/531, Loss: 0.7978
✅ Training complete - Avg Loss: 0.6954
✅ Validation complete - Loss: 1.3321, Accuracy: 58.08%
🎯 New best validation loss: 1.3321 (improvement: 0.5691)

📅 Epoch 4/50
    Batch 0/531, Loss: 0.6190
    Batch 50/531, Loss: 0.5932
    Batch 100/531, Loss: 0.7131
    Batch 150/531, Loss: 0.6115
    Batch 200/531, Loss: 0.7211
    Batch 250/531, Loss: 0.6270
    Batch 300/531, Loss: 0.5274
    Batch 350/531, Loss: 0.6355
    Batch 400/531, Loss: 0.5489
    Batch 450/531, Loss: 0.7030
    Batch 500/531, Loss: 0.5972
✅ Training complete - Avg Loss: 0.6335
✅ Validation complete - Loss: 1.4964, Accuracy: 54.36%
⏰ No improvement for 1 epochs

📅 Epoch 5/50
    Batch 0/531, Loss: 0.5401
    Batch 50/531, Loss: 0.6063
    Batch 100/531, Loss: 0.6149
    Batch 150/531, Loss: 0.5832
    Batch 200/531, Loss: 0.6365
    Batch 250/531, Loss: 0.6038
    Batch 300/531, Loss: 0.5634
    Batch 350/531, Loss: 0.4216
    Batch 400/531, Loss: 0.5801
    Batch 450/531, Loss: 0.5822
    Batch 500/531, Loss: 0.6525
✅ Training complete - Avg Loss: 0.5912
✅ Validation complete - Loss: 1.3405, Accuracy: 56.25%
⏰ No improvement for 2 epochs

📅 Epoch 6/50
    Batch 0/531, Loss: 0.6211
    Batch 50/531, Loss: 0.6208
    Batch 100/531, Loss: 0.4732
    Batch 150/531, Loss: 0.5940
    Batch 200/531, Loss: 0.6375
    Batch 250/531, Loss: 0.5748
    Batch 300/531, Loss: 0.5245
    Batch 350/531, Loss: 0.6173
    Batch 400/531, Loss: 0.5456
    Batch 450/531, Loss: 0.5756
    Batch 500/531, Loss: 0.5308
✅ Training complete - Avg Loss: 0.5570
✅ Validation complete - Loss: 1.2896, Accuracy: 58.47%
🎯 New best validation loss: 1.2896 (improvement: 0.0425)

📅 Epoch 7/50
    Batch 0/531, Loss: 0.5838
    Batch 50/531, Loss: 0.4619
    Batch 100/531, Loss: 0.6265
    Batch 150/531, Loss: 0.4677
    Batch 200/531, Loss: 0.5916
    Batch 250/531, Loss: 0.3908
    Batch 300/531, Loss: 0.7068
    Batch 350/531, Loss: 0.6381
    Batch 400/531, Loss: 0.4406
    Batch 450/531, Loss: 0.5105
    Batch 500/531, Loss: 0.4149
✅ Training complete - Avg Loss: 0.5310
✅ Validation complete - Loss: 1.2591, Accuracy: 59.88%
🎯 New best validation loss: 1.2591 (improvement: 0.0305)

📅 Epoch 8/50
    Batch 0/531, Loss: 0.5135
    Batch 50/531, Loss: 0.5513
    Batch 100/531, Loss: 0.5350
    Batch 150/531, Loss: 0.4920
    Batch 200/531, Loss: 0.4934
    Batch 250/531, Loss: 0.4247
    Batch 300/531, Loss: 0.5153
    Batch 350/531, Loss: 0.5985
    Batch 400/531, Loss: 0.3775
    Batch 450/531, Loss: 0.5556
    Batch 500/531, Loss: 0.4745
✅ Training complete - Avg Loss: 0.5056
✅ Validation complete - Loss: 1.3504, Accuracy: 56.31%
⏰ No improvement for 1 epochs

📅 Epoch 9/50
    Batch 0/531, Loss: 0.4773
    Batch 50/531, Loss: 0.5633
    Batch 100/531, Loss: 0.5217
    Batch 150/531, Loss: 0.6557
    Batch 200/531, Loss: 0.5577
    Batch 250/531, Loss: 0.4722
    Batch 300/531, Loss: 0.4644
    Batch 350/531, Loss: 0.4417
    Batch 400/531, Loss: 0.4351
    Batch 450/531, Loss: 0.4816
    Batch 500/531, Loss: 0.4233
✅ Training complete - Avg Loss: 0.4889
✅ Validation complete - Loss: 1.3078, Accuracy: 58.20%
⏰ No improvement for 2 epochs

📅 Epoch 10/50
    Batch 0/531, Loss: 0.4795
    Batch 50/531, Loss: 0.3831
    Batch 100/531, Loss: 0.3978
    Batch 150/531, Loss: 0.3787
    Batch 200/531, Loss: 0.4826
    Batch 250/531, Loss: 0.3777
    Batch 300/531, Loss: 0.5059
    Batch 350/531, Loss: 0.4020
    Batch 400/531, Loss: 0.4270
    Batch 450/531, Loss: 0.4053
    Batch 500/531, Loss: 0.4773
✅ Training complete - Avg Loss: 0.4715
✅ Validation complete - Loss: 1.2993, Accuracy: 58.28%
⏰ No improvement for 3 epochs

📅 Epoch 11/50
    Batch 0/531, Loss: 0.4163
    Batch 50/531, Loss: 0.4783
    Batch 100/531, Loss: 0.4025
    Batch 150/531, Loss: 0.4301
    Batch 200/531, Loss: 0.4943
    Batch 250/531, Loss: 0.4038
    Batch 300/531, Loss: 0.3869
    Batch 350/531, Loss: 0.4623
    Batch 400/531, Loss: 0.4408
    Batch 450/531, Loss: 0.4032
    Batch 500/531, Loss: 0.5430
✅ Training complete - Avg Loss: 0.4547
✅ Validation complete - Loss: 1.2937, Accuracy: 59.40%
📉 Learning rate reduced: 0.001000 → 0.000500
⏰ No improvement for 4 epochs

📅 Epoch 12/50
    Batch 0/531, Loss: 0.4128
    Batch 50/531, Loss: 0.3365
    Batch 100/531, Loss: 0.5090
    Batch 150/531, Loss: 0.4760
    Batch 200/531, Loss: 0.3958
    Batch 250/531, Loss: 0.3641
    Batch 300/531, Loss: 0.3996
    Batch 350/531, Loss: 0.3572
    Batch 400/531, Loss: 0.4371
    Batch 450/531, Loss: 0.3306
    Batch 500/531, Loss: 0.3778
✅ Training complete - Avg Loss: 0.4043
✅ Validation complete - Loss: 1.2744, Accuracy: 60.16%
⏰ No improvement for 5 epochs

📅 Epoch 13/50
    Batch 0/531, Loss: 0.4325
    Batch 50/531, Loss: 0.2833
    Batch 100/531, Loss: 0.2634
    Batch 150/531, Loss: 0.3348
    Batch 200/531, Loss: 0.4355
    Batch 250/531, Loss: 0.4205
    Batch 300/531, Loss: 0.2926
    Batch 350/531, Loss: 0.4384
    Batch 400/531, Loss: 0.3478
    Batch 450/531, Loss: 0.4012
    Batch 500/531, Loss: 0.3932
✅ Training complete - Avg Loss: 0.3818
✅ Validation complete - Loss: 1.2066, Accuracy: 62.51%
🎯 New best validation loss: 1.2066 (improvement: 0.0524)

📅 Epoch 14/50
    Batch 0/531, Loss: 0.3299
    Batch 50/531, Loss: 0.3290
    Batch 100/531, Loss: 0.4115
    Batch 150/531, Loss: 0.4164
    Batch 200/531, Loss: 0.4186
    Batch 250/531, Loss: 0.3594
    Batch 300/531, Loss: 0.3457
    Batch 350/531, Loss: 0.3905
    Batch 400/531, Loss: 0.3750
    Batch 450/531, Loss: 0.4204
    Batch 500/531, Loss: 0.3860
✅ Training complete - Avg Loss: 0.3728
✅ Validation complete - Loss: 1.2842, Accuracy: 61.11%
⏰ No improvement for 1 epochs

📅 Epoch 15/50
    Batch 0/531, Loss: 0.4452
    Batch 50/531, Loss: 0.3858
    Batch 100/531, Loss: 0.3153
    Batch 150/531, Loss: 0.3590
    Batch 200/531, Loss: 0.3089
    Batch 250/531, Loss: 0.3490
    Batch 300/531, Loss: 0.3540
    Batch 350/531, Loss: 0.5216
    Batch 400/531, Loss: 0.3201
    Batch 450/531, Loss: 0.3653
    Batch 500/531, Loss: 0.4356
✅ Training complete - Avg Loss: 0.3626
✅ Validation complete - Loss: 1.2779, Accuracy: 61.10%
⏰ No improvement for 2 epochs

📅 Epoch 16/50
    Batch 0/531, Loss: 0.3677
    Batch 50/531, Loss: 0.3299
    Batch 100/531, Loss: 0.2699
    Batch 150/531, Loss: 0.3743
    Batch 200/531, Loss: 0.3556
    Batch 250/531, Loss: 0.4189
    Batch 300/531, Loss: 0.3664
    Batch 350/531, Loss: 0.3574
    Batch 400/531, Loss: 0.3676
    Batch 450/531, Loss: 0.3400
    Batch 500/531, Loss: 0.2875
✅ Training complete - Avg Loss: 0.3538
✅ Validation complete - Loss: 1.2013, Accuracy: 63.92%
🎯 New best validation loss: 1.2013 (improvement: 0.0054)

📅 Epoch 17/50
    Batch 0/531, Loss: 0.3233
    Batch 50/531, Loss: 0.2494
    Batch 100/531, Loss: 0.2958
    Batch 150/531, Loss: 0.4821
    Batch 200/531, Loss: 0.3027
    Batch 250/531, Loss: 0.3577
    Batch 300/531, Loss: 0.3986
    Batch 350/531, Loss: 0.2077
    Batch 400/531, Loss: 0.2273
    Batch 450/531, Loss: 0.3520
    Batch 500/531, Loss: 0.3690
✅ Training complete - Avg Loss: 0.3446
✅ Validation complete - Loss: 1.2441, Accuracy: 63.46%
⏰ No improvement for 1 epochs

📅 Epoch 18/50
    Batch 0/531, Loss: 0.2820
    Batch 50/531, Loss: 0.3416
    Batch 100/531, Loss: 0.3433
    Batch 150/531, Loss: 0.2745
    Batch 200/531, Loss: 0.4193
    Batch 250/531, Loss: 0.3909
    Batch 300/531, Loss: 0.2980
    Batch 350/531, Loss: 0.3473
    Batch 400/531, Loss: 0.2777
    Batch 450/531, Loss: 0.3927
    Batch 500/531, Loss: 0.2906
✅ Training complete - Avg Loss: 0.3401
✅ Validation complete - Loss: 1.2736, Accuracy: 62.59%
⏰ No improvement for 2 epochs

📅 Epoch 19/50
    Batch 0/531, Loss: 0.4139
    Batch 50/531, Loss: 0.3000
    Batch 100/531, Loss: 0.2690
    Batch 150/531, Loss: 0.4036
    Batch 200/531, Loss: 0.2330
    Batch 250/531, Loss: 0.3401
    Batch 300/531, Loss: 0.3374
    Batch 350/531, Loss: 0.3184
    Batch 400/531, Loss: 0.2687
    Batch 450/531, Loss: 0.3056
    Batch 500/531, Loss: 0.2937
✅ Training complete - Avg Loss: 0.3349
✅ Validation complete - Loss: 1.2266, Accuracy: 64.02%
⏰ No improvement for 3 epochs

📅 Epoch 20/50
    Batch 0/531, Loss: 0.2943
    Batch 50/531, Loss: 0.3207
    Batch 100/531, Loss: 0.2975
    Batch 150/531, Loss: 0.3239
    Batch 200/531, Loss: 0.3142
    Batch 250/531, Loss: 0.2519
    Batch 300/531, Loss: 0.3290
Traceback (most recent call last):
  File "/home/debian/Muh_Projesi/Main.py", line 995, in main
    trained_model, train_losses, val_losses, train_accs, val_accs = train_temporal_model_fixed(
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: not enough values to unpack (expected 5, got 2)
    Batch 350/531, Loss: 0.3646
    Batch 400/531, Loss: 0.2712
    Batch 450/531, Loss: 0.3304
    Batch 500/531, Loss: 0.4299
✅ Training complete - Avg Loss: 0.3271
✅ Validation complete - Loss: 1.2570, Accuracy: 62.95%
📉 Learning rate reduced: 0.000500 → 0.000250
⏰ No improvement for 4 epochs

📅 Epoch 21/50
    Batch 0/531, Loss: 0.3023
    Batch 50/531, Loss: 0.3456
    Batch 100/531, Loss: 0.3309
    Batch 150/531, Loss: 0.3097
    Batch 200/531, Loss: 0.3022
    Batch 250/531, Loss: 0.3859
    Batch 300/531, Loss: 0.4112
    Batch 350/531, Loss: 0.3386
    Batch 400/531, Loss: 0.3540
    Batch 450/531, Loss: 0.2347
    Batch 500/531, Loss: 0.2730
✅ Training complete - Avg Loss: 0.3012
✅ Validation complete - Loss: 1.2669, Accuracy: 63.24%
⏰ No improvement for 5 epochs

📅 Epoch 22/50
    Batch 0/531, Loss: 0.3207
    Batch 50/531, Loss: 0.2694
    Batch 100/531, Loss: 0.3092
    Batch 150/531, Loss: 0.2412
    Batch 200/531, Loss: 0.3373
    Batch 250/531, Loss: 0.2841
    Batch 300/531, Loss: 0.1801
    Batch 350/531, Loss: 0.3323
    Batch 400/531, Loss: 0.2536
    Batch 450/531, Loss: 0.3377
    Batch 500/531, Loss: 0.3119
✅ Training complete - Avg Loss: 0.2937
✅ Validation complete - Loss: 1.2404, Accuracy: 63.96%
⏰ No improvement for 6 epochs

📅 Epoch 23/50
    Batch 0/531, Loss: 0.1915
    Batch 50/531, Loss: 0.2839
    Batch 100/531, Loss: 0.2614
    Batch 150/531, Loss: 0.2649
    Batch 200/531, Loss: 0.1870
    Batch 250/531, Loss: 0.2375
    Batch 300/531, Loss: 0.3452
    Batch 350/531, Loss: 0.2185
    Batch 400/531, Loss: 0.2776
    Batch 450/531, Loss: 0.2596
    Batch 500/531, Loss: 0.3450
✅ Training complete - Avg Loss: 0.2857
✅ Validation complete - Loss: 1.2297, Accuracy: 64.14%
⏰ No improvement for 7 epochs
🛑 Early stopping triggered at epoch 23
✅ Best model loaded (val_loss: 1.2013)
❌ Hata oluştu: not enough values to unpack (expected 5, got 2)
