ğŸµ MÃ¼zik TÃ¼rÃ¼ SÄ±nÄ±flandÄ±rma Projesi BaÅŸlatÄ±lÄ±yor...
KullanÄ±lan cihaz: cuda

ğŸ“‚ AdÄ±m 1: Veri yÃ¼kleme...
Veriler yÃ¼klendi ve Ã¶niÅŸlendi.
Veri yÃ¼klendi: 49598 Ã¶rnek, 518 Ã¶zellik
SÄ±nÄ±f sayÄ±sÄ±: 16
SÄ±nÄ±flar: ['Blues', 'Classical', 'Country', 'Easy Listening', 'Electronic', 'Experimental', 'Folk', 'Hip-Hop', 'Instrumental', 'International', 'Jazz', 'Old-Time / Historic', 'Pop', 'Rock', 'Soul-RnB', 'Spoken']

ğŸ”„ AdÄ±m 2: Veri setini bÃ¶lme...
EÄŸitim seti: 29758 Ã¶rnek
DoÄŸrulama seti: 9920 Ã¶rnek
Test seti: 9920 Ã¶rnek

âš–ï¸ AdÄ±m 3: Veri dengeleme...
AdÄ±m 1: AÅŸÄ±rÄ± az temsil edilen sÄ±nÄ±flar iÃ§in RandomOverSampler uygulanÄ±yor...
RandomOverSampler sonrasÄ± daÄŸÄ±lÄ±m (ham sayÄ±lar):
SÄ±nÄ±f 0: 66 Ã¶rnek
SÄ±nÄ±f 1: 738 Ã¶rnek
SÄ±nÄ±f 2: 116 Ã¶rnek
SÄ±nÄ±f 3: 20 Ã¶rnek
SÄ±nÄ±f 4: 5623 Ã¶rnek
SÄ±nÄ±f 5: 6365 Ã¶rnek
SÄ±nÄ±f 6: 1682 Ã¶rnek
SÄ±nÄ±f 7: 2131 Ã¶rnek
SÄ±nÄ±f 8: 1247 Ã¶rnek
SÄ±nÄ±f 9: 833 Ã¶rnek
SÄ±nÄ±f 10: 343 Ã¶rnek
SÄ±nÄ±f 11: 332 Ã¶rnek
SÄ±nÄ±f 12: 1399 Ã¶rnek
SÄ±nÄ±f 13: 8509 Ã¶rnek
SÄ±nÄ±f 14: 105 Ã¶rnek
SÄ±nÄ±f 15: 254 Ã¶rnek
AdÄ±m 2: Kalan sÄ±nÄ±flar iÃ§in BorderlineSMOTE uygulanÄ±yor...
Kombine Ã¶rnekleme tamamlandÄ±: X_res (136144, 518), y_res (136144,)
Son DaÄŸÄ±lÄ±m (ham sayÄ±lar):
SÄ±nÄ±f 0: 8509 Ã¶rnek
SÄ±nÄ±f 1: 8509 Ã¶rnek
SÄ±nÄ±f 2: 8509 Ã¶rnek
SÄ±nÄ±f 3: 8509 Ã¶rnek
SÄ±nÄ±f 4: 8509 Ã¶rnek
SÄ±nÄ±f 5: 8509 Ã¶rnek
SÄ±nÄ±f 6: 8509 Ã¶rnek
SÄ±nÄ±f 7: 8509 Ã¶rnek
SÄ±nÄ±f 8: 8509 Ã¶rnek
SÄ±nÄ±f 9: 8509 Ã¶rnek
SÄ±nÄ±f 10: 8509 Ã¶rnek
SÄ±nÄ±f 11: 8509 Ã¶rnek
SÄ±nÄ±f 12: 8509 Ã¶rnek
SÄ±nÄ±f 13: 8509 Ã¶rnek
SÄ±nÄ±f 14: 8509 Ã¶rnek
SÄ±nÄ±f 15: 8509 Ã¶rnek

ğŸ¯ AdÄ±m 5: Ã–zellik seÃ§imi...
K-Best Ã¶zellik seÃ§imi uygulanÄ±yor...
Toplam Ã¶zellik sayÄ±sÄ±: 518, SeÃ§ilecek Ã¶zellik sayÄ±sÄ±: 250
Ã–zellik seÃ§imi tamamlandÄ±. SeÃ§ilen Ã¶zelliklerin boyutu: (136144, 250)

ğŸµ AdÄ±m 6: GeliÅŸmiÅŸ temporal Ã¶zellik mÃ¼hendisliÄŸi...
   ğŸ”„ EÄŸitim verisi iÃ§in temporal Ã¶zellikler oluÅŸturuluyor...
ğŸµ GeliÅŸmiÅŸ temporal Ã¶zellik mÃ¼hendisliÄŸi baÅŸlatÄ±lÄ±yor...
   ğŸ“Š Ä°ÅŸleniyor: chroma_cens (temporal boyut: 12)
      âœ“ Shape: (136144, 12, 7) (samples, seq_len=12, features=7)
      âœ“ Found 18 feature columns
   ğŸ“Š Ä°ÅŸleniyor: chroma_cqt (temporal boyut: 12)
      âœ“ Shape: (136144, 12, 7) (samples, seq_len=12, features=7)
      âœ“ Found 9 feature columns
   ğŸ“Š Ä°ÅŸleniyor: chroma_stft (temporal boyut: 12)
      âœ“ Shape: (136144, 12, 7) (samples, seq_len=12, features=7)
      âœ“ Found 38 feature columns
   ğŸ“Š Ä°ÅŸleniyor: mfcc (temporal boyut: 20)
      âœ“ Shape: (136144, 20, 7) (samples, seq_len=20, features=7)
      âœ“ Found 103 feature columns
   ğŸ“Š Ä°ÅŸleniyor: spectral_contrast (temporal boyut: 7)
      âœ“ Shape: (136144, 7, 7) (samples, seq_len=7, features=7)
      âœ“ Found 37 feature columns
   ğŸ“Š Ä°ÅŸleniyor: tonnetz (temporal boyut: 6)
      âœ“ Shape: (136144, 6, 7) (samples, seq_len=6, features=7)
      âœ“ Found 20 feature columns
   ğŸ“Š Skaler Ã¶zellikler: 25 Ã¶zellik
      âœ“ Features: ['rmse_max', 'rmse_mean', 'rmse_median', 'rmse_skew', 'rmse_std']...
âœ… Temporal Ã¶zellik mÃ¼hendisliÄŸi tamamlandÄ±!
   ğŸ¯ Temporal Ã¶zellik tÃ¼rleri: 6
   ğŸ¯ Toplam temporal Ã¶zellik: 483
   ğŸ¯ Skaler Ã¶zellikler: 25
   ğŸ”„ DoÄŸrulama verisi iÃ§in temporal Ã¶zellikler oluÅŸturuluyor...
ğŸµ GeliÅŸmiÅŸ temporal Ã¶zellik mÃ¼hendisliÄŸi baÅŸlatÄ±lÄ±yor...
   ğŸ“Š Ä°ÅŸleniyor: chroma_cens (temporal boyut: 12)
      âœ“ Shape: (9920, 12, 7) (samples, seq_len=12, features=7)
      âœ“ Found 18 feature columns
   ğŸ“Š Ä°ÅŸleniyor: chroma_cqt (temporal boyut: 12)
      âœ“ Shape: (9920, 12, 7) (samples, seq_len=12, features=7)
      âœ“ Found 9 feature columns
   ğŸ“Š Ä°ÅŸleniyor: chroma_stft (temporal boyut: 12)
      âœ“ Shape: (9920, 12, 7) (samples, seq_len=12, features=7)
      âœ“ Found 38 feature columns
   ğŸ“Š Ä°ÅŸleniyor: mfcc (temporal boyut: 20)
      âœ“ Shape: (9920, 20, 7) (samples, seq_len=20, features=7)
      âœ“ Found 103 feature columns
   ğŸ“Š Ä°ÅŸleniyor: spectral_contrast (temporal boyut: 7)
      âœ“ Shape: (9920, 7, 7) (samples, seq_len=7, features=7)
      âœ“ Found 37 feature columns
   ğŸ“Š Ä°ÅŸleniyor: tonnetz (temporal boyut: 6)
      âœ“ Shape: (9920, 6, 7) (samples, seq_len=6, features=7)
      âœ“ Found 20 feature columns
   ğŸ“Š Skaler Ã¶zellikler: 25 Ã¶zellik
      âœ“ Features: ['rmse_max', 'rmse_mean', 'rmse_median', 'rmse_skew', 'rmse_std']...
âœ… Temporal Ã¶zellik mÃ¼hendisliÄŸi tamamlandÄ±!
   ğŸ¯ Temporal Ã¶zellik tÃ¼rleri: 6
   ğŸ¯ Toplam temporal Ã¶zellik: 483
   ğŸ¯ Skaler Ã¶zellikler: 25
   ğŸ”„ Test verisi iÃ§in temporal Ã¶zellikler oluÅŸturuluyor...
ğŸµ GeliÅŸmiÅŸ temporal Ã¶zellik mÃ¼hendisliÄŸi baÅŸlatÄ±lÄ±yor...
   ğŸ“Š Ä°ÅŸleniyor: chroma_cens (temporal boyut: 12)
      âœ“ Shape: (9920, 12, 7) (samples, seq_len=12, features=7)
      âœ“ Found 18 feature columns
   ğŸ“Š Ä°ÅŸleniyor: chroma_cqt (temporal boyut: 12)
      âœ“ Shape: (9920, 12, 7) (samples, seq_len=12, features=7)
      âœ“ Found 9 feature columns
   ğŸ“Š Ä°ÅŸleniyor: chroma_stft (temporal boyut: 12)
      âœ“ Shape: (9920, 12, 7) (samples, seq_len=12, features=7)
      âœ“ Found 38 feature columns
   ğŸ“Š Ä°ÅŸleniyor: mfcc (temporal boyut: 20)
      âœ“ Shape: (9920, 20, 7) (samples, seq_len=20, features=7)
      âœ“ Found 103 feature columns
   ğŸ“Š Ä°ÅŸleniyor: spectral_contrast (temporal boyut: 7)
      âœ“ Shape: (9920, 7, 7) (samples, seq_len=7, features=7)
      âœ“ Found 37 feature columns
   ğŸ“Š Ä°ÅŸleniyor: tonnetz (temporal boyut: 6)
      âœ“ Shape: (9920, 6, 7) (samples, seq_len=6, features=7)
      âœ“ Found 20 feature columns
   ğŸ“Š Skaler Ã¶zellikler: 25 Ã¶zellik
      âœ“ Features: ['rmse_max', 'rmse_mean', 'rmse_median', 'rmse_skew', 'rmse_std']...
âœ… Temporal Ã¶zellik mÃ¼hendisliÄŸi tamamlandÄ±!
   ğŸ¯ Temporal Ã¶zellik tÃ¼rleri: 6
   ğŸ¯ Toplam temporal Ã¶zellik: 483
   ğŸ¯ Skaler Ã¶zellikler: 25
âœ… Temporal Ã¶zellik mÃ¼hendisliÄŸi tamamlandÄ±!
   ğŸ¯ Temporal Ã¶zellik tÃ¼rleri: 6
   ğŸ¯ Toplam temporal Ã¶zellik: 483

ğŸ§  AdÄ±m 7: GeliÅŸmiÅŸ LSTM model oluÅŸturma...
Model parametreleri:
  - Temporal feature types: 6
  - Hidden size: 128
  - Num layers: 2
  - Num classes: 16
  - Dropout: 0.3
  - Total parameters: 1,483,152

ğŸ‹ï¸ AdÄ±m 8: GeliÅŸmiÅŸ model eÄŸitimi baÅŸlatÄ±lÄ±yor...
ğŸ”§ Using FIXED temporal model training...
ğŸ“± Using device: cuda
ğŸš€ Fixed temporal model training started...
ğŸ“Š Train batches: 531, Val batches: 39

ğŸ“… Epoch 1/50
    Batch 0/531, Loss: 2.7885
    Batch 50/531, Loss: 1.7299
    Batch 100/531, Loss: 1.3613
    Batch 150/531, Loss: 1.2055
    Batch 200/531, Loss: 1.2391
    Batch 250/531, Loss: 1.1613
    Batch 300/531, Loss: 1.0299
    Batch 350/531, Loss: 1.0077
    Batch 400/531, Loss: 1.0335
    Batch 450/531, Loss: 0.9499
    Batch 500/531, Loss: 0.7691
âœ… Training complete - Avg Loss: 1.1865
âœ… Validation complete - Loss: 1.9012, Accuracy: 37.84%
ğŸ¯ New best validation loss: 1.9012 (improvement: inf)

ğŸ“… Epoch 2/50
    Batch 0/531, Loss: 0.8765
    Batch 50/531, Loss: 0.9696
    Batch 100/531, Loss: 0.7954
    Batch 150/531, Loss: 0.7735
    Batch 200/531, Loss: 0.8887
    Batch 250/531, Loss: 0.7806
    Batch 300/531, Loss: 0.7597
    Batch 350/531, Loss: 0.8912
    Batch 400/531, Loss: 0.7936
    Batch 450/531, Loss: 0.7556
    Batch 500/531, Loss: 0.9467
âœ… Training complete - Avg Loss: 0.8008
âœ… Validation complete - Loss: 1.9119, Accuracy: 36.94%
â° No improvement for 1 epochs

ğŸ“… Epoch 3/50
    Batch 0/531, Loss: 0.8383
    Batch 50/531, Loss: 0.6564
    Batch 100/531, Loss: 0.8174
    Batch 150/531, Loss: 0.5940
    Batch 200/531, Loss: 0.8572
    Batch 250/531, Loss: 0.7999
    Batch 300/531, Loss: 0.7989
    Batch 350/531, Loss: 0.7292
    Batch 400/531, Loss: 0.6808
    Batch 450/531, Loss: 0.6616
    Batch 500/531, Loss: 0.7978
âœ… Training complete - Avg Loss: 0.6954
âœ… Validation complete - Loss: 1.3321, Accuracy: 58.08%
ğŸ¯ New best validation loss: 1.3321 (improvement: 0.5691)

ğŸ“… Epoch 4/50
    Batch 0/531, Loss: 0.6190
    Batch 50/531, Loss: 0.5932
    Batch 100/531, Loss: 0.7131
    Batch 150/531, Loss: 0.6115
    Batch 200/531, Loss: 0.7211
    Batch 250/531, Loss: 0.6270
    Batch 300/531, Loss: 0.5274
    Batch 350/531, Loss: 0.6355
    Batch 400/531, Loss: 0.5489
    Batch 450/531, Loss: 0.7030
    Batch 500/531, Loss: 0.5972
âœ… Training complete - Avg Loss: 0.6335
âœ… Validation complete - Loss: 1.4964, Accuracy: 54.36%
â° No improvement for 1 epochs

ğŸ“… Epoch 5/50
    Batch 0/531, Loss: 0.5401
    Batch 50/531, Loss: 0.6063
    Batch 100/531, Loss: 0.6149
    Batch 150/531, Loss: 0.5832
    Batch 200/531, Loss: 0.6365
    Batch 250/531, Loss: 0.6038
    Batch 300/531, Loss: 0.5634
    Batch 350/531, Loss: 0.4216
    Batch 400/531, Loss: 0.5801
    Batch 450/531, Loss: 0.5822
    Batch 500/531, Loss: 0.6525
âœ… Training complete - Avg Loss: 0.5912
âœ… Validation complete - Loss: 1.3405, Accuracy: 56.25%
â° No improvement for 2 epochs

ğŸ“… Epoch 6/50
    Batch 0/531, Loss: 0.6211
    Batch 50/531, Loss: 0.6208
    Batch 100/531, Loss: 0.4732
    Batch 150/531, Loss: 0.5940
    Batch 200/531, Loss: 0.6375
    Batch 250/531, Loss: 0.5748
    Batch 300/531, Loss: 0.5245
    Batch 350/531, Loss: 0.6173
    Batch 400/531, Loss: 0.5456
    Batch 450/531, Loss: 0.5756
    Batch 500/531, Loss: 0.5308
âœ… Training complete - Avg Loss: 0.5570
âœ… Validation complete - Loss: 1.2896, Accuracy: 58.47%
ğŸ¯ New best validation loss: 1.2896 (improvement: 0.0425)

ğŸ“… Epoch 7/50
    Batch 0/531, Loss: 0.5838
    Batch 50/531, Loss: 0.4619
    Batch 100/531, Loss: 0.6265
    Batch 150/531, Loss: 0.4677
    Batch 200/531, Loss: 0.5916
    Batch 250/531, Loss: 0.3908
    Batch 300/531, Loss: 0.7068
    Batch 350/531, Loss: 0.6381
    Batch 400/531, Loss: 0.4406
    Batch 450/531, Loss: 0.5105
    Batch 500/531, Loss: 0.4149
âœ… Training complete - Avg Loss: 0.5310
âœ… Validation complete - Loss: 1.2591, Accuracy: 59.88%
ğŸ¯ New best validation loss: 1.2591 (improvement: 0.0305)

ğŸ“… Epoch 8/50
    Batch 0/531, Loss: 0.5135
    Batch 50/531, Loss: 0.5513
    Batch 100/531, Loss: 0.5350
    Batch 150/531, Loss: 0.4920
    Batch 200/531, Loss: 0.4934
    Batch 250/531, Loss: 0.4247
    Batch 300/531, Loss: 0.5153
    Batch 350/531, Loss: 0.5985
    Batch 400/531, Loss: 0.3775
    Batch 450/531, Loss: 0.5556
    Batch 500/531, Loss: 0.4745
âœ… Training complete - Avg Loss: 0.5056
âœ… Validation complete - Loss: 1.3504, Accuracy: 56.31%
â° No improvement for 1 epochs

ğŸ“… Epoch 9/50
    Batch 0/531, Loss: 0.4773
    Batch 50/531, Loss: 0.5633
    Batch 100/531, Loss: 0.5217
    Batch 150/531, Loss: 0.6557
    Batch 200/531, Loss: 0.5577
    Batch 250/531, Loss: 0.4722
    Batch 300/531, Loss: 0.4644
    Batch 350/531, Loss: 0.4417
    Batch 400/531, Loss: 0.4351
    Batch 450/531, Loss: 0.4816
    Batch 500/531, Loss: 0.4233
âœ… Training complete - Avg Loss: 0.4889
âœ… Validation complete - Loss: 1.3078, Accuracy: 58.20%
â° No improvement for 2 epochs

ğŸ“… Epoch 10/50
    Batch 0/531, Loss: 0.4795
    Batch 50/531, Loss: 0.3831
    Batch 100/531, Loss: 0.3978
    Batch 150/531, Loss: 0.3787
    Batch 200/531, Loss: 0.4826
    Batch 250/531, Loss: 0.3777
    Batch 300/531, Loss: 0.5059
    Batch 350/531, Loss: 0.4020
    Batch 400/531, Loss: 0.4270
    Batch 450/531, Loss: 0.4053
    Batch 500/531, Loss: 0.4773
âœ… Training complete - Avg Loss: 0.4715
âœ… Validation complete - Loss: 1.2993, Accuracy: 58.28%
â° No improvement for 3 epochs

ğŸ“… Epoch 11/50
    Batch 0/531, Loss: 0.4163
    Batch 50/531, Loss: 0.4783
    Batch 100/531, Loss: 0.4025
    Batch 150/531, Loss: 0.4301
    Batch 200/531, Loss: 0.4943
    Batch 250/531, Loss: 0.4038
    Batch 300/531, Loss: 0.3869
    Batch 350/531, Loss: 0.4623
    Batch 400/531, Loss: 0.4408
    Batch 450/531, Loss: 0.4032
    Batch 500/531, Loss: 0.5430
âœ… Training complete - Avg Loss: 0.4547
âœ… Validation complete - Loss: 1.2937, Accuracy: 59.40%
ğŸ“‰ Learning rate reduced: 0.001000 â†’ 0.000500
â° No improvement for 4 epochs

ğŸ“… Epoch 12/50
    Batch 0/531, Loss: 0.4128
    Batch 50/531, Loss: 0.3365
    Batch 100/531, Loss: 0.5090
    Batch 150/531, Loss: 0.4760
    Batch 200/531, Loss: 0.3958
    Batch 250/531, Loss: 0.3641
    Batch 300/531, Loss: 0.3996
    Batch 350/531, Loss: 0.3572
    Batch 400/531, Loss: 0.4371
    Batch 450/531, Loss: 0.3306
    Batch 500/531, Loss: 0.3778
âœ… Training complete - Avg Loss: 0.4043
âœ… Validation complete - Loss: 1.2744, Accuracy: 60.16%
â° No improvement for 5 epochs

ğŸ“… Epoch 13/50
    Batch 0/531, Loss: 0.4325
    Batch 50/531, Loss: 0.2833
    Batch 100/531, Loss: 0.2634
    Batch 150/531, Loss: 0.3348
    Batch 200/531, Loss: 0.4355
    Batch 250/531, Loss: 0.4205
    Batch 300/531, Loss: 0.2926
    Batch 350/531, Loss: 0.4384
    Batch 400/531, Loss: 0.3478
    Batch 450/531, Loss: 0.4012
    Batch 500/531, Loss: 0.3932
âœ… Training complete - Avg Loss: 0.3818
âœ… Validation complete - Loss: 1.2066, Accuracy: 62.51%
ğŸ¯ New best validation loss: 1.2066 (improvement: 0.0524)

ğŸ“… Epoch 14/50
    Batch 0/531, Loss: 0.3299
    Batch 50/531, Loss: 0.3290
    Batch 100/531, Loss: 0.4115
    Batch 150/531, Loss: 0.4164
    Batch 200/531, Loss: 0.4186
    Batch 250/531, Loss: 0.3594
    Batch 300/531, Loss: 0.3457
    Batch 350/531, Loss: 0.3905
    Batch 400/531, Loss: 0.3750
    Batch 450/531, Loss: 0.4204
    Batch 500/531, Loss: 0.3860
âœ… Training complete - Avg Loss: 0.3728
âœ… Validation complete - Loss: 1.2842, Accuracy: 61.11%
â° No improvement for 1 epochs

ğŸ“… Epoch 15/50
    Batch 0/531, Loss: 0.4452
    Batch 50/531, Loss: 0.3858
    Batch 100/531, Loss: 0.3153
    Batch 150/531, Loss: 0.3590
    Batch 200/531, Loss: 0.3089
    Batch 250/531, Loss: 0.3490
    Batch 300/531, Loss: 0.3540
    Batch 350/531, Loss: 0.5216
    Batch 400/531, Loss: 0.3201
    Batch 450/531, Loss: 0.3653
    Batch 500/531, Loss: 0.4356
âœ… Training complete - Avg Loss: 0.3626
âœ… Validation complete - Loss: 1.2779, Accuracy: 61.10%
â° No improvement for 2 epochs

ğŸ“… Epoch 16/50
    Batch 0/531, Loss: 0.3677
    Batch 50/531, Loss: 0.3299
    Batch 100/531, Loss: 0.2699
    Batch 150/531, Loss: 0.3743
    Batch 200/531, Loss: 0.3556
    Batch 250/531, Loss: 0.4189
    Batch 300/531, Loss: 0.3664
    Batch 350/531, Loss: 0.3574
    Batch 400/531, Loss: 0.3676
    Batch 450/531, Loss: 0.3400
    Batch 500/531, Loss: 0.2875
âœ… Training complete - Avg Loss: 0.3538
âœ… Validation complete - Loss: 1.2013, Accuracy: 63.92%
ğŸ¯ New best validation loss: 1.2013 (improvement: 0.0054)

ğŸ“… Epoch 17/50
    Batch 0/531, Loss: 0.3233
    Batch 50/531, Loss: 0.2494
    Batch 100/531, Loss: 0.2958
    Batch 150/531, Loss: 0.4821
    Batch 200/531, Loss: 0.3027
    Batch 250/531, Loss: 0.3577
    Batch 300/531, Loss: 0.3986
    Batch 350/531, Loss: 0.2077
    Batch 400/531, Loss: 0.2273
    Batch 450/531, Loss: 0.3520
    Batch 500/531, Loss: 0.3690
âœ… Training complete - Avg Loss: 0.3446
âœ… Validation complete - Loss: 1.2441, Accuracy: 63.46%
â° No improvement for 1 epochs

ğŸ“… Epoch 18/50
    Batch 0/531, Loss: 0.2820
    Batch 50/531, Loss: 0.3416
    Batch 100/531, Loss: 0.3433
    Batch 150/531, Loss: 0.2745
    Batch 200/531, Loss: 0.4193
    Batch 250/531, Loss: 0.3909
    Batch 300/531, Loss: 0.2980
    Batch 350/531, Loss: 0.3473
    Batch 400/531, Loss: 0.2777
    Batch 450/531, Loss: 0.3927
    Batch 500/531, Loss: 0.2906
âœ… Training complete - Avg Loss: 0.3401
âœ… Validation complete - Loss: 1.2736, Accuracy: 62.59%
â° No improvement for 2 epochs

ğŸ“… Epoch 19/50
    Batch 0/531, Loss: 0.4139
    Batch 50/531, Loss: 0.3000
    Batch 100/531, Loss: 0.2690
    Batch 150/531, Loss: 0.4036
    Batch 200/531, Loss: 0.2330
    Batch 250/531, Loss: 0.3401
    Batch 300/531, Loss: 0.3374
    Batch 350/531, Loss: 0.3184
    Batch 400/531, Loss: 0.2687
    Batch 450/531, Loss: 0.3056
    Batch 500/531, Loss: 0.2937
âœ… Training complete - Avg Loss: 0.3349
âœ… Validation complete - Loss: 1.2266, Accuracy: 64.02%
â° No improvement for 3 epochs

ğŸ“… Epoch 20/50
    Batch 0/531, Loss: 0.2943
    Batch 50/531, Loss: 0.3207
    Batch 100/531, Loss: 0.2975
    Batch 150/531, Loss: 0.3239
    Batch 200/531, Loss: 0.3142
    Batch 250/531, Loss: 0.2519
    Batch 300/531, Loss: 0.3290
Traceback (most recent call last):
  File "/home/debian/Muh_Projesi/Main.py", line 995, in main
    trained_model, train_losses, val_losses, train_accs, val_accs = train_temporal_model_fixed(
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: not enough values to unpack (expected 5, got 2)
    Batch 350/531, Loss: 0.3646
    Batch 400/531, Loss: 0.2712
    Batch 450/531, Loss: 0.3304
    Batch 500/531, Loss: 0.4299
âœ… Training complete - Avg Loss: 0.3271
âœ… Validation complete - Loss: 1.2570, Accuracy: 62.95%
ğŸ“‰ Learning rate reduced: 0.000500 â†’ 0.000250
â° No improvement for 4 epochs

ğŸ“… Epoch 21/50
    Batch 0/531, Loss: 0.3023
    Batch 50/531, Loss: 0.3456
    Batch 100/531, Loss: 0.3309
    Batch 150/531, Loss: 0.3097
    Batch 200/531, Loss: 0.3022
    Batch 250/531, Loss: 0.3859
    Batch 300/531, Loss: 0.4112
    Batch 350/531, Loss: 0.3386
    Batch 400/531, Loss: 0.3540
    Batch 450/531, Loss: 0.2347
    Batch 500/531, Loss: 0.2730
âœ… Training complete - Avg Loss: 0.3012
âœ… Validation complete - Loss: 1.2669, Accuracy: 63.24%
â° No improvement for 5 epochs

ğŸ“… Epoch 22/50
    Batch 0/531, Loss: 0.3207
    Batch 50/531, Loss: 0.2694
    Batch 100/531, Loss: 0.3092
    Batch 150/531, Loss: 0.2412
    Batch 200/531, Loss: 0.3373
    Batch 250/531, Loss: 0.2841
    Batch 300/531, Loss: 0.1801
    Batch 350/531, Loss: 0.3323
    Batch 400/531, Loss: 0.2536
    Batch 450/531, Loss: 0.3377
    Batch 500/531, Loss: 0.3119
âœ… Training complete - Avg Loss: 0.2937
âœ… Validation complete - Loss: 1.2404, Accuracy: 63.96%
â° No improvement for 6 epochs

ğŸ“… Epoch 23/50
    Batch 0/531, Loss: 0.1915
    Batch 50/531, Loss: 0.2839
    Batch 100/531, Loss: 0.2614
    Batch 150/531, Loss: 0.2649
    Batch 200/531, Loss: 0.1870
    Batch 250/531, Loss: 0.2375
    Batch 300/531, Loss: 0.3452
    Batch 350/531, Loss: 0.2185
    Batch 400/531, Loss: 0.2776
    Batch 450/531, Loss: 0.2596
    Batch 500/531, Loss: 0.3450
âœ… Training complete - Avg Loss: 0.2857
âœ… Validation complete - Loss: 1.2297, Accuracy: 64.14%
â° No improvement for 7 epochs
ğŸ›‘ Early stopping triggered at epoch 23
âœ… Best model loaded (val_loss: 1.2013)
âŒ Hata oluÅŸtu: not enough values to unpack (expected 5, got 2)
